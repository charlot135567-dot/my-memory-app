import streamlit as st
import pandas as pd
import requests
import re
import os
import base64
import io

# --- 1. é é¢åŸºç¤é…ç½® ---
st.set_page_config(page_title="Memory Logic 2026", layout="wide", page_icon="ğŸ¶")

# --- 2. åˆå§‹åŒ– Session State ---
def init_session():
    if 'quiz_data' not in st.session_state:
        st.session_state.quiz_data = {"Text_CN": "å‡¡äº‹éƒ½æœ‰å®šæœŸï¼Œå¤©ä¸‹è¬å‹™éƒ½æœ‰å®šæ™‚ã€‚", "Text_EN": "To everything there is a season."}
    if 'verse_data' not in st.session_state:
        st.session_state.verse_data = {"Chinese": "å‡¡äº‹éƒ½æœ‰å®šæœŸï¼Œå¤©ä¸‹è¬å‹™éƒ½æœ‰å®šæ™‚ã€‚", "Reference": "å‚³é“æ›¸ 3:1", "Keyword": "å®šæ™‚"}
    if 'word_data' not in st.session_state:
        st.session_state.word_data = {"Vocab": "Study", "Definition": "å­¸ç¿’", "Grammar": "ä¿æŒå­¸ç¿’ï¼Œæ¯å¤©é€²æ­¥ï¼"}
    if 'phrase_data' not in st.session_state:
        st.session_state.phrase_data = {"Phrase": "Keep it up", "Definition": "ç¹¼çºŒåŠ æ²¹"}
    if 'final_df' not in st.session_state:
        st.session_state.final_df = pd.DataFrame(columns=["Reference", "English", "Chinese", "Key word", "Grammar", "Japanese", "Korean", "Thai"])
    if 'score' not in st.session_state: st.session_state.score = 0

init_session()

THEME = {"bg": "#FFF9E3", "box": "#FFFFFF", "accent": "#FFCDD2", "text": "#4A4A4A", "sub": "#F06292", "keyword": "#E91E63"}

# --- 3. æ ¸å¿ƒå·¥å…·é¡åˆ¥ ---
class BibleAutomator:
    def __init__(self):
        # é€™æ˜¯æ­£ç¢ºçš„å¯«æ³•
        self.api_base = "https://bible-api.com/" 
        self.analysis_keywords = ['Subject', 'Verb', 'è£œå…¨å¾Œ', 'ä¾‹å¥', 'è­¯ç‚º', 'æŒ‡ä»£', 'èªæ°£', 'çœç•¥', 'ä¸»è¬‚', 'Agreement']
        self.lang_map = {"CN": "cuv", "EN": "web", "JA": "jpn", "KO": "kor", "TH": "tha"}
        
    def fetch_real_bible(self, ref, lang_key):
        """æŠ“å–çœŸå¯¦è–ç¶“ç‰ˆæœ¬ (2026 æ¨è–¦ç‰ˆæœ¬)"""
        trans = self.lang_map.get(lang_key, "web")
        try:
            ref_clean = ref.replace(" ", "+")
            r = requests.get(f"{self.api_base}{ref_clean}?translation={trans}", timeout=7)
            if r.status_code == 200:
                return r.json().get('text', '').strip()
        except: pass
        return f"[ç„¡æ³•ç²å– {lang_key} ç‰ˆæœ¬]"

    def extract_keywords(self, text):
        """é¸å– 6 å­—æ¯ä»¥ä¸Šä¸­é«˜ç´šå–®å­—"""
        if not text: return ""
        stop_words = {'through', 'between', 'against', 'before', 'because', 'everything', 'handiwork'}
        words = re.findall(r'\b[A-Za-z]{6,}\b', text.lower())
        keywords = [w for w in words if w not in stop_words]
        return ", ".join(list(dict.fromkeys(keywords))[:2])

    def parse_manual(self, raw_text):
        """å°‡æ‰‹å‹•ç­†è¨˜æ‹†è§£ä¸¦è‡ªå‹•åˆ†é¡è‡³æ¬„ä½"""
        book_match = re.search(r'([\u4e00-\u9fa5]+)(\d+)(ç¯‡|ç« )?', raw_text)
        book_name = book_match.group(1) if book_match else ""
        
        # ä¾ç…§åº§æ¨™åˆ†å‰²å¡Š
        blocks = re.split(r'\n(?=\d{1,3}:\d{1,3})', raw_text)
        final_list = []
        
        for block in blocks:
            lines = [l.strip() for l in block.split('\n') if l.strip()]
            if not lines: continue
            
            ref_match = re.match(r'^(\d+:\d+)', lines[0])
            if not ref_match: continue
            
            ref_val = f"{book_name}{ref_match.group(1)}"
            entry = {"Reference": ref_val, "Chinese": "", "English": "", "Key word": "", "Grammar": ""}
            
            grammar_lines = []
            english_accumulator = []
            
            for line in lines:
                # 1. è­˜åˆ¥ä¸­æ–‡
                if re.search(r'[\u4e00-\u9fa5]', line) and not any(k in line for k in self.analysis_keywords) and not entry["Chinese"]:
                    entry["Chinese"] = re.sub(r'^\d+:\d+\s*', '', line)
                # 2. è­˜åˆ¥è‹±æ–‡ (æ”¹é€²ç‰ˆï¼šæ”¯æ´è·¨è¡Œ)
                elif re.match(r'^[A-Za-z0-9\s.,;!\?\'\"()\-\:]+$', line) and not any(k in line for k in self.analysis_keywords):
                    cleaned_eng = re.sub(r'^\d+:\d+\s*|^\d+\s*', '', line)
                    if cleaned_eng: english_accumulator.append(cleaned_eng)
                # 3. è­˜åˆ¥æ–‡æ³•èªªæ˜
                else:
                    grammar_lines.append(line)
            
            entry["English"] = " ".join(english_accumulator)
            entry["Grammar"] = "\n".join(grammar_lines)
            entry["Key word"] = self.extract_keywords(entry["English"])
            
            # è‡ªå‹•æŠ“å–å¤šåœ‹èªè¨€
            with st.spinner(f"æ­£åœ¨åŒæ­¥ {ref_val} å¤šåœ‹è­¯æœ¬..."):
                entry["Japanese"] = self.fetch_real_bible(ref_val, "JA")
                entry["Korean"] = self.fetch_real_bible(ref_val, "KO")
                entry["Thai"] = self.fetch_real_bible(ref_val, "TH")
            
            final_list.append(entry)
        return pd.DataFrame(final_list)

# --- 4. åœ–ç‰‡èˆ‡æ¨£å¼è™•ç† ---
@st.cache_data(ttl=600)
def get_img_base64(file_path):
    if os.path.exists(file_path):
        try:
            with open(file_path, "rb") as f:
                return f"data:image/jpeg;base64,{base64.b64encode(f.read()).decode()}"
        except: return None
    return None

st.markdown(f"""
    <style>
    .stApp {{ background-color: {THEME['bg']}; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; }}
    .feature-box {{
        background: {THEME['box']}; border-radius: 15px; padding: 20px;
        border: 2px solid {THEME['accent']}; box-shadow: 4px 4px 0px {THEME['accent']};
        margin-bottom: 15px;
        color: {THEME['text']};
    }}
    .img-container img {{ border-radius: 12px; width: 100%; box-shadow: 2px 2px 8px rgba(0,0,0,0.1); }}
    </style>
    """, unsafe_allow_html=True)

# --- 5. UI æ¨™ç±¤é  ---
tab_home, tab_play, tab_tool = st.tabs(["ğŸ  æˆ‘çš„æ›¸æ¡Œ", "ğŸ¯ éš¨è¨˜æŒ‘æˆ°", "ğŸ§ª è‡ªå‹•åˆ†é¡å·¥å…·"])

with tab_home:
    v1, w1, p1 = st.session_state.verse_data, st.session_state.word_data, st.session_state.phrase_data
    col_main, col_side = st.columns([2, 1])
    
    with col_main:
        st.markdown(f'<div class="feature-box"><h3>ğŸ’¡ ä»Šæ—¥é‡‘å¥</h3><p style="font-size:20px; font-weight:500;">{v1["Chinese"]}</p><div style="text-align:right; font-style:italic;">â€” {v1["Reference"]}</div></div>', unsafe_allow_html=True)
        c1, c2 = st.columns(2)
        with c1:
            st.markdown(f'<div class="feature-box"><small>ğŸ”¤ å–®å­—</small><br><b style="font-size:22px; color:{THEME["keyword"]};">{w1["Vocab"]}</b><br>{w1["Definition"]}</div>', unsafe_allow_html=True)
        with c2:
            st.markdown(f'<div class="feature-box"><small>ğŸ”— ç‰‡èª</small><br><b style="font-size:22px; color:{THEME["sub"]};">{p1["Phrase"]}</b><br>{p1["Definition"]}</div>', unsafe_allow_html=True)
        st.markdown(f'<div class="feature-box" style="background-color:#F0F7FF;"><small>ğŸ“ æ–‡æ³•é»æ’¥</small><br>{w1["Grammar"]}</div>', unsafe_allow_html=True)
    
    with col_side:
        img_b64 = get_img_base64("f364bd220887627.67cae1bd07457.jpg")
        if img_b64: st.markdown(f'<div class="img-container"><img src="{img_b64}"></div>', unsafe_allow_html=True)

with tab_play:
    st.subheader("ğŸ¯ ç¿»è­¯ç·´ç¿’")
    curr = st.session_state.quiz_data
    col_q, col_img = st.columns([2, 1])
    with col_q:
        st.info(f"è«‹å˜—è©¦ç¿»è­¯é€™å¥è©±ï¼š\n\n**{curr['Text_CN']}**")
        if st.button("âœ¨ é¡¯ç¤ºæ­£ç¢ºç­”æ¡ˆ"):
            st.success(f"åƒè€ƒç­”æ¡ˆï¼š{curr['Text_EN']}")
            st.balloons()
    with col_img:
        img_play = get_img_base64("68254faebaafed9dafb41918f74c202e.jpg")
        if img_play: st.markdown(f'<div class="img-container"><img src="{img_play}"></div>', unsafe_allow_html=True)

with tab_tool:
    st.markdown("### ğŸ§ª è–ç¶“å­¸ç¿’åˆ†é¡å™¨ (2026 ç‰ˆ)")
    mode = st.radio("æ¨¡å¼é¸æ“‡", ["æ‰‹å‹•è§£æå¤§é‡ç­†è¨˜", "æŒ‡å®šç« ç¯€å…¨è‡ªå‹•æŠ“å–"], horizontal=True)
    auto = BibleAutomator()
    
    if mode == "æ‰‹å‹•è§£æå¤§é‡ç­†è¨˜":
        raw_text = st.text_area("è«‹åœ¨æ­¤è²¼ä¸Šæ‚¨çš„ç­†è¨˜ (åŒ…å«åº§æ¨™ã€ç¶“æ–‡èˆ‡è§£æ)ï¼š", height=300, 
                               placeholder="ä¾‹ï¼šè©©ç¯‡19ç¯‡\n19:1 è«¸å¤©è¿°èªª...\n19:1 The heavens...\nGrammar: Subject is...")
        if st.button("ğŸš€ åŸ·è¡Œåˆ†é¡åŒ¯å‡º"):
            if raw_text:
                st.session_state.final_df = auto.parse_manual(raw_text)
                st.success(f"æˆåŠŸè§£æ {len(st.session_state.final_df)} ç¯€ç¶“æ–‡ï¼")
                st.dataframe(st.session_state.final_df, use_container_width=True)
    
    else:
        ref_input = st.text_input("è¼¸å…¥è¦æª¢ç´¢çš„ç« ç¯€ (ä¾‹å¦‚: Psalms 19:1-4)", "Psalms 19:1")
        if st.button("ğŸ” AI å…¨è‡ªå‹•æª¢ç´¢"):
            with st.spinner("æ­£åœ¨é€£ç·šå…¨çƒè–ç¶“è³‡æ–™åº«..."):
                res = {
                    "Reference": ref_input,
                    "English": auto.fetch_real_bible(ref_input, "EN"),
                    "Chinese": auto.fetch_real_bible(ref_input, "CN"),
                    "Japanese": auto.fetch_real_bible(ref_input, "JA"),
                    "Korean": auto.fetch_real_bible(ref_input, "KO"),
                    "Thai": auto.fetch_real_bible(ref_input, "TH")
                }
                res["Key word"] = auto.extract_keywords(res["English"])
                res["Grammar"] = "AI è‡ªå‹•æŠ“å–å»ºè­°ï¼šè«‹åƒè€ƒä¸Šä¸‹æ–‡é€²è¡Œæ–‡æ³•å°ä»—åˆ†æã€‚"
                st.session_state.final_df = pd.DataFrame([res])
                st.dataframe(st.session_state.final_df, use_container_width=True)

    if not st.session_state.final_df.empty:
        csv_data = st.session_state.final_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ åŒ¯å‡ºç‚º Verse/Words/Phrases è¡¨æ ¼ (CSV)", csv_data, "Bible_Study_Data.csv", "text/csv")
