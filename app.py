import streamlit as st
import pandas as pd
import requests
import io
import re
import os
import time
import base64
from urllib.parse import quote

# --- 1. é é¢åŸºç¤é…ç½® ---
st.set_page_config(page_title="Memory Logic 2026", layout="wide", page_icon="ğŸ¶")

# --- 2. åˆå§‹åŒ– Session State ---
if 'quiz_data' not in st.session_state:
    st.session_state.quiz_data = {"Text_CN": "å‡¡äº‹éƒ½æœ‰å®šæœŸï¼Œå¤©ä¸‹è¬å‹™éƒ½æœ‰å®šæ™‚ã€‚", "Text_EN": "To everything there is a season."}
if 'verse_data' not in st.session_state:
    st.session_state.verse_data = {"Chinese": "å‡¡äº‹éƒ½æœ‰å®šæœŸï¼Œå¤©ä¸‹è¬å‹™éƒ½æœ‰å®šæ™‚ã€‚", "Reference": "å‚³é“æ›¸ 3:1", "Keyword": "å®šæ™‚"}
if 'word_data' not in st.session_state:
    st.session_state.word_data = {"Vocab": "Study", "Definition": "å­¸ç¿’", "Grammar": "ä¿æŒå­¸ç¿’ï¼Œæ¯å¤©é€²æ­¥ï¼"}
if 'phrase_data' not in st.session_state:
    st.session_state.phrase_data = {"Phrase": "Keep it up", "Definition": "ç¹¼çºŒåŠ æ²¹"}
if 'score' not in st.session_state: st.session_state.score = 0
if 'lives' not in st.session_state: st.session_state.lives = 3

THEME = {"bg": "#FFF9E3", "box": "#FFFFFF", "accent": "#FFCDD2", "text": "#4A4A4A", "sub": "#F06292", "keyword": "#E91E63"}

# --- 3. æ ¸å¿ƒå·¥å…·é¡åˆ¥ ---
class BibleAutomator:
    def __init__(self):
        self.api_base = "bible-api.com"
        self.analysis_keywords = ['Subject', 'Verb', 'è£œå…¨å¾Œ', 'ä¾‹å¥', 'è­¯ç‚º', 'æŒ‡ä»£', 'èªæ°£', 'çœç•¥', 'ä¸»è¬‚']
        # 2026 æ”¯æ´ç‰ˆæœ¬ä»£ç¢¼
        self.lang_map = {"CN": "cuv", "EN": "web", "JA": "jpn", "KO": "kor", "TH": "tha"}

    def fetch_real_bible(self, ref, lang_key):
        """çœŸå¯¦é€é API æŠ“å–å„åœ‹ç‰ˆæœ¬ç¶“æ–‡"""
        trans = self.lang_map.get(lang_key, "web")
        try:
            r = requests.get(f"{self.api_base}{ref}?translation={trans}", timeout=10)
            if r.status_code == 200:
                return r.json().get('text', '').strip()
        except: pass
        return f"[ç„¡æ³•ç²å– {lang_key} ç‰ˆæœ¬]"

    def parse_manual(self, raw_text):
        """è§£ææ‰‹å‹•è²¼ä¸Šçš„è¤‡é›œè§£ææ–‡å­—"""
        book_match = re.search(r'([\u4e00-\u9fa5]+)(\d+)ç¯‡', raw_text)
        book_name = book_match.group(1) if book_match else ""
        blocks = re.split(r'\n(?=\d{1,3}:\d{1,3})', raw_text)
        
        final_list = []
        for block in blocks:
            lines = [l.strip() for l in block.split('\n') if l.strip()]
            if not lines: continue
            ref_match = re.match(r'^(\d+:\d+)', lines[0])
            if not ref_match: continue
            
            ref_val = f"{book_name}{ref_match.group(1)}"
            entry = {
                "Reference": ref_val, "English": "", "Chinese": "", "Key word": "",
                "Grammar": "", "Japanese": self.fetch_real_bible(ref_val, "JA"),
                "Korean": self.fetch_real_bible(ref_val, "KO"), "Thai": self.fetch_real_bible(ref_val, "TH")
            }
            grammar_lines = []
            for line in lines:
                if any(k in line for k in self.analysis_keywords): grammar_lines.append(line)
                elif re.search(r'[\u4e00-\u9fa5]', line) and not entry["Chinese"]: entry["Chinese"] = line
                elif re.match(r'^[A-Za-z\d\s\p{P}]+$', line) and not entry["English"]:
                    entry["English"] = re.sub(r'^\d+\s', '', line)
            
            entry["Grammar"] = "\n".join(grammar_lines)
            # é—œéµå­—ï¼šé¸å–é•·åº¦ > 5 çš„å–®å­—æ¨¡æ“¬ä¸­é«˜ç´šç¨‹åº¦
            words = list(set([w.strip(',.') for w in entry["English"].split() if len(w) > 5]))
            entry["Key word"] = ", ".join(words[:3])
            final_list.append(entry)
        return pd.DataFrame(final_list)

@st.cache_data(ttl=300)
def fetch_data(gid):
    SHEET_ID = "1eiinJgMYXkCwIbU25P7lfsyNhO8MtD-m15wyUv3YgjQ"
    url = f"docs.google.com{SHEET_ID}/export?format=csv&gid={gid}"
    try:
        r = requests.get(url, timeout=5)
        if r.status_code == 200: return pd.read_csv(io.StringIO(r.text)).fillna("")
    except: pass
    return pd.DataFrame()

def get_img_as_base64(file):
    if os.path.exists(file):
        with open(file, "rb") as f:
            data = base64.b64encode(f.read()).decode()
            return f"data:image/jpeg;base64,{data}"
    return None

# --- 4. CSS æ¨£å¼ ---
st.markdown(f"""
    <style>
    html, body, [data-testid="stAppViewContainer"] {{ background-color: {THEME['bg']}; font-family: 'Comic Neue', cursive; }}
    .feature-box {{
        background-color: {THEME['box']} !important; border-radius: 18px !important; padding: 18px !important;
        border: 2.5px solid {THEME['accent']} !important; box-shadow: 4px 4px 0px {THEME['accent']} !important;
        margin-bottom: 12px !important; display: flex; flex-direction: column; justify-content: center;
    }}
    .kw {{ color: {THEME['keyword']}; font-weight: bolder; background-color: #FFFF00; padding: 2px 4px; border-radius: 4px; }}
    .img-box img {{ border-radius: 15px; max-width: 100%; }}
    </style>
    """, unsafe_allow_html=True)

# --- 5. å®šç¾©æ¨™ç±¤é  (è§£æ±º NameError) ---
tab_home, tab_play, tab_tool = st.tabs(["ğŸ  æˆ‘çš„æ›¸æ¡Œ", "ğŸ¯ éš¨è¨˜æŒ‘æˆ°", "ğŸ§ª è‡ªå‹•åˆ†é¡å·¥å…·"])

# --- TAB 1: æˆ‘çš„æ›¸æ¡Œ (å²åŠªæ¯”åœ– 1 & 2) ---
with tab_home:
    v1, w1, p1 = st.session_state.verse_data, st.session_state.word_data, st.session_state.phrase_data
    c1, c2, c3 = st.columns(3)
    with c1:
        st.markdown(f'<div class="feature-box"><small>ğŸ”¤ å–®å­—</small><br><b style="font-size:24px;">{w1.get("Vocab","")}</b><br>{w1.get("Definition","")}</div>', unsafe_allow_html=True)
    with c2:
        st.markdown(f'<div class="feature-box"><small>ğŸ”— ç‰‡èª</small><br><b style="font-size:22px;">{p1.get("Phrase","")}</b><br>{p1.get("Definition","")}</div>', unsafe_allow_html=True)
    with c3:
        b64 = get_img_as_base64("f364bd220887627.67cae1bd07457.jpg")
        if b64: st.markdown(f'<div class="img-box" style="height:150px; text-align:center;"><img src="{b64}" style="height:100%;"></div>', unsafe_allow_html=True)
    
    st.markdown(f'<div class="feature-box"><h3>ğŸ’¡ ä»Šæ—¥é‡‘å¥</h3><div style="font-size:22px;">{v1.get("Chinese","")}</div><div style="text-align:right;">â€” {v1.get("Reference","")}</div></div>', unsafe_allow_html=True)
    
    c4, c5 = st.columns([2, 1])
    with c4:
        st.markdown(f'<div class="feature-box" style="background-color:#E3F2FD !important; min-height:180px;"><small>ğŸ“ æ–‡æ³•</small><br>{w1.get("Grammar","")}</div>', unsafe_allow_html=True)
    with c5:
        b64_2 = get_img_as_base64("183ebb183330643.Y3JvcCw4MDgsNjMyLDAsMA.jpg")
        if b64_2: st.markdown(f'<div class="img-box" style="height:180px; text-align:center;"><img src="{b64_2}" style="height:100%;"></div>', unsafe_allow_html=True)

# --- TAB 2: éš¨è¨˜æŒ‘æˆ° (å²åŠªæ¯”åœ– 3) ---
with tab_play:
    col_txt, col_img = st.columns([2, 1])
    with col_txt:
        st.subheader("ğŸ¯ ç¿»è­¯æŒ‘æˆ°")
        curr = st.session_state.quiz_data
        st.info(f"è«‹ç¿»è­¯ï¼š{curr.get('Text_CN','')}")
        ans = st.text_area("åœ¨æ­¤è¼¸å…¥è‹±æ–‡...", height=100)
        if st.button("æäº¤ç­”æ¡ˆ"):
            st.balloons()
            st.success(f"åƒè€ƒç­”æ¡ˆ: {curr.get('Text_EN','')}")
            st.session_state.score += 20
    with col_img:
        t_img = "68254faebaafed9dafb41918f74c202e.jpg"
        if os.path.exists(t_img): st.image(t_img, caption="Cheers!")

# --- TAB 3: è‡ªå‹•åˆ†é¡å·¥å…· (AI & æ‰‹å‹•è§£æ) ---
with tab_tool:
    st.markdown("### ğŸ§ª è¬ç”¨è–ç¶“è³‡æ–™ AI è§£æå™¨ (2026 ç‰ˆ)")
    mode = st.radio("æ¨¡å¼é¸æ“‡", ["æ‰‹å‹•è²¼ä¸Šå¤§é‡ç­†è¨˜", "AI æŒ‡å®šç« ç¯€æŠ“å–"], horizontal=True)
    auto = BibleAutomator()
    
    if mode == "æ‰‹å‹•è²¼ä¸Šå¤§é‡ç­†è¨˜":
        raw_input = st.text_area("è²¼ä¸Šå«è§£æçš„æ–‡å­—ï¼š", height=250, placeholder="è©©ç¯‡19ç¯‡\n19:1... (Subject:...)")
        if st.button("ğŸš€ åŸ·è¡Œè§£æåŒ¯å‡º"):
            if raw_input:
                res_df = auto.parse_manual(raw_input)
                st.data_editor(res_df, use_container_width=True)
                csv = res_df.to_csv(index=False).encode('utf-8-sig')
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel (CSV)", csv, "bible_parsed.csv", "text/csv")
    else:
        cmd = st.text_input("è¼¸å…¥è‹±æ–‡æ›¸å·ç« ç¯€ (ä¾‹: Psalms 19:1-5)ï¼š")
        if st.button("ğŸ” AI è‡ªå‹•æª¢ç´¢"):
            if cmd:
                with st.spinner("æŠ“å–å¤šåœ‹å®˜æ–¹ç¶“æ–‡ä¸­..."):
                    results = {
                        "Reference": cmd,
                        "Chinese": auto.fetch_real_bible(cmd, "CN"),
                        "English": auto.fetch_real_bible(cmd, "EN"),
                        "Japanese": auto.fetch_real_bible(cmd, "JA"),
                        "Korean": auto.fetch_real_bible(cmd, "KO"),
                        "Thai": auto.fetch_real_bible(cmd, "TH"),
                        "Key word": "æª¢ç´¢ä¸­...", "Grammar": "å¾…åˆ†æ"
                    }
                    st.data_editor(pd.DataFrame([results]), use_container_width=True)
            else: st.warning("è«‹è¼¸å…¥ç« ç¯€")

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.title("ğŸ¾ æ§åˆ¶å°")
    st.metric("å¾—åˆ†", st.session_state.score)
    st.metric("ç”Ÿå‘½", "â¤ï¸" * st.session_state.lives)
    if st.button("â™»ï¸ åˆ·æ–°å…§å®¹"):
        df_w = fetch_data("1400979824")
        if not df_w.empty: st.session_state.word_data = df_w.sample(1).iloc[0].to_dict()
        st.rerun()
