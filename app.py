# ===================================================================
# 0. å¥—ä»¶ & å…¨åŸŸå‡½å¼ï¼ˆä¸€å®šæ”¾æœ€é ‚ï¼‰
# ===================================================================
import streamlit as st
import subprocess, sys, os, datetime as dt, pandas as pd, io, json, re, tomli, tomli_w
from streamlit_calendar import calendar

# ========== é™¤éŒ¯æ¸¬è©¦ ==========
st.sidebar.markdown("## ğŸ”§ é™¤éŒ¯è³‡è¨Š")

api_key = os.getenv("GEMINI_API_KEY")

if api_key:
    st.sidebar.success("âœ… GEMINI_API_KEY å·²è¨­å®š")
    st.sidebar.write(f"é•·åº¦: {len(api_key)} å­—å…ƒ")
else:
    st.sidebar.error("âŒ GEMINI_API_KEY æœªè¨­å®š")
    st.sidebar.info("è«‹åˆ° Settings â†’ Secrets è¨­å®š")
    
# ---------- å…¨åŸŸå·¥å…·å‡½å¼ ----------
def save_analysis_result(result, input_text):
    if "analysis_history" not in st.session_state:
        st.session_state.analysis_history = []
    st.session_state.analysis_history.append({
        "date": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
        "input_preview": input_text[:50] + "..." if len(input_text) > 50 else input_text,
        "result": result
    })
    if len(st.session_state.analysis_history) > 10:
        st.session_state.analysis_history.pop(0)

def to_excel(result: dict) -> bytes:
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        for sheet, key in [("Words", "words"), ("Phrases", "phrases"), ("Grammar", "grammar")]:
            if key in result and result[key]:
                pd.DataFrame(result[key]).to_excel(writer, sheet_name=sheet, index=False)
        stats = pd.DataFrame({
            "é …ç›®": ["ç¸½å­—å½™æ•¸", "ç¸½ç‰‡èªæ•¸", "æ–‡æ³•é»æ•¸", "åˆ†ææ—¥æœŸ"],
            "æ•¸å€¼": [
                len(result.get("words", [])),
                len(result.get("phrases", [])),
                len(result.get("grammar", [])),
                dt.date.today().strftime("%Y-%m-%d")
            ]
        })
        stats.to_excel(writer, sheet_name="çµ±è¨ˆ", index=False)
    buffer.seek(0)
    return buffer.getvalue()

# ===================================================================
# 1. å´é‚Šæ¬„ï¼ˆä¸€æ¬¡ 4 é€£çµï¼Œç„¡é‡è¤‡ï¼‰
# ===================================================================
with st.sidebar:
    st.divider()
    c1, c2 = st.columns(2)
    c1.link_button("âœ¨ Google AI", "https://gemini.google.com/ ")
    c2.link_button("ğŸ¤– Kimi K2",   "https://kimi.moonshot.cn/ ")
    c3, c4 = st.columns(2)
    c3.link_button("ESV Bible", "https://wd.bible/bible/gen.1.cunps?parallel=esv.klb.jcb ")
    c4.link_button("THSV11",    "https://www.bible.com/zh-TW/bible/174/GEN.1.THSV11 ")

# ===================================================================
# 2. é é¢é…ç½® & Session åˆå€¼ï¼ˆåªç•™å…¨åŸŸæœƒç”¨åˆ°çš„ï¼‰
# ===================================================================
st.set_page_config(layout="wide", page_title="Bible Study AI App 2026")

# é€™äº›è®Šæ•¸åªæœ‰ TAB2 æœƒç”¨åˆ°ï¼Œä½†ç‚ºäº†é¿å…å¾ŒçºŒ TAB å¼•ç”¨å‡ºéŒ¯ï¼Œå…ˆçµ¦ç©ºå€¼
if 'analysis_history' not in st.session_state: st.session_state.analysis_history = []

# ---------- CSS ----------
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Gamja+Flower&display=swap ');
.cute-korean { font-family: 'Gamja Flower', cursive; font-size: 20px; color: #FF8C00; text-align: center; }
.small-font { font-size: 13px; color: #555555; margin-top: 5px !important; }
.grammar-box-container {
    background-color: #f8f9fa; border-radius: 8px; padding: 12px;
    border-left: 5px solid #FF8C00; text-align: left; margin-top: 0px;
}
.fc-daygrid-day-frame:hover {background-color: #FFF3CD !important; cursor: pointer; transform: scale(1.03); transition: .2s}
.fc-daygrid-day-frame:active {transform: scale(0.98); background-color: #FFE69C !important}
</style>
""", unsafe_allow_html=True)

# ---------- åœ–ç‰‡ & ç¾æˆ TAB ----------
IMG_URLS = {
    "A": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/183ebb183330643.Y3JvcCw4MDgsNjMyLDAsMA.jpg ",
    "B": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/f364bd220887627.67cae1bd07457.jpg ",
    "C": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/68254faebaafed9dafb41918f74c202e.jpg ",
    "M1": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro1.jpg ",
    "M2": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro2.jpg ",
    "M3": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro3.jpg ",
    "M4": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro4.jpg "
}
with st.sidebar:
    st.markdown('<p class="cute-korean">ë‹¹ì‹ ì€ í•˜ë‚˜ë‹˜ì˜ ì†Œì¤‘í•œ ë³´ë¬¼ì…ë‹ˆë‹¤</p>', unsafe_allow_html=True)
    st.image(IMG_URLS["M3"], width=250)
    st.divider()

tabs = st.tabs(["ğŸ  æ›¸æ¡Œ", "ğŸ““ ç­†è¨˜", "âœï¸ æŒ‘æˆ°", "ğŸ“‚ è³‡æ–™åº«"])

# ===================================================================
# 3. TAB1 â”€ æ›¸æ¡Œï¼ˆå–®ç´”ç¶“æ–‡èˆ‡ä¾‹å¥ï¼Œç„¡æœˆæ›†ï¼‰
# ===================================================================
with tabs[0]:
    col_content, col_m1 = st.columns([0.65, 0.35])
    with col_content:
        st.info("**Becoming** / ğŸ‡¯ğŸ‡µ ãµã•ã‚ã—ã„ | ğŸ‡°ğŸ‡· ì–´ìš¸ë¦¬ëŠ” | ğŸ‡¹ğŸ‡­ à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ | ğŸ‡¨ğŸ‡³ ç›¸ç¨±")
        st.success("""
            ğŸŒŸ **Pro 17:07** Fine speech is not becoming to a fool; still less is false speech to a prince.   
            ğŸ‡¯ğŸ‡µ ã™ãã‚ŒãŸè¨€è‘‰ã¯æ„šã‹è€…ã«ã¯ãµã•ã‚ã—ããªã„ã€‚å½ã‚Šã®è¨€è‘‰ã¯å›ä¸»ã«ã¯ãªãŠã•ã‚‰ãµã•ã‚ã—ããªã„ã€‚   
            ğŸ‡¨ğŸ‡³ æ„šé ‘äººèªªç¾è¨€æœ¬ä¸ç›¸ç¨±ï¼Œä½•æ³å›ç‹èªªè¬Šè©±å‘¢ï¼Ÿ
            """, icon="ğŸ“–")
    with col_m1:
        st.markdown(f"""
            <div style="display:flex;flex-direction:column;justify-content:space-between;height:100%;min-height:250px;text-align:center;">
                <div style="flex-grow:1;display:flex;align-items:center;justify-content:center;">
                    <img src="{IMG_URLS['M1']}" style="width:200px;margin-bottom:10px;">
                </div>
                <div class="grammar-box-container" style="margin-top:auto;">
                    <p style="margin:2px 0;font-size:14px;font-weight:bold;color:#333;">æ™‚æ…‹: ç¾åœ¨ç°¡å–®å¼</p>
                    <p style="margin:2px 0;font-size:14px;font-weight:bold;color:#333;">æ ¸å¿ƒç‰‡èª:</p>
                    <ul style="margin:0;padding-left:18px;font-size:13px;line-height:1.4;color:#555;">
                        <li>Fine speech (å„ªç¾è¨€è¾­)</li>
                        <li>Becoming to (ç›¸ç¨±)</li>
                        <li>Still less (ä½•æ³)</li>
                        <li>False speech (è™›å‡è¨€è¾­)</li>
                    </ul>
                </div>
            </div>
        """, unsafe_allow_html=True)
    st.divider()
    st.markdown("### âœï¸ æ–‡æ³•é‹ç”¨ä¾‹å¥")
    cl1, cl2 = st.columns(2)
    with cl1:
        st.markdown("**Ex 1:** *Casual attire is not becoming to a CEO; still less is unprofessional language.* <p class='small-font'>ä¾¿æœå°åŸ·è¡Œé•·ä¸ç›¸ç¨±ï¼›æ›´ä¸ç”¨èªªä¸å°ˆæ¥­çš„è¨€èªäº†ã€‚</p>", unsafe_allow_html=True)
    with cl2:
        st.markdown("**Ex 2:** *Wealth is not becoming to a man without virtue; still less is power.* <p class='small-font'>è²¡å¯Œå°æ–¼ç„¡å¾·ä¹‹äººä¸ç›¸ç¨±ï¼›æ›´ä¸ç”¨èªªæ¬ŠåŠ›äº†ã€‚</p>", unsafe_allow_html=True)

# ===================================================================
# 4. TAB2 â”€ æœˆæ›†å¾…è¾¦ï¼ˆç©©å®šæœ€çµ‚ç‰ˆï¼‰
# ===================================================================
with tabs[1]:
    import datetime as dt, re, os, json
    from streamlit_calendar import calendar

    # ---------- èƒŒæ™¯åœ–ï¼ˆåƒ… TAB2ï¼Œæ·¡åŒ–ï¼‰ ----------
    st.markdown("""
    <style>
    section[data-testid="stSidebar"] + div [data-testid="stVerticalBlock"] {
        background-image: url("assets/68254faebaafed9dafb41918f74c202e.jpg");
        background-size: cover;
        background-position: center;
        background-repeat: no-repeat;
    }
    section[data-testid="stSidebar"] + div [data-testid="stVerticalBlock"]::before {
        content: "";
        position: fixed;
        inset: 0;
        background: rgba(255,255,255,0.82);
        z-index: -1;
    }
    </style>
    """, unsafe_allow_html=True)

    # ---------- 0. æª”æ¡ˆæŒä¹…åŒ– ----------
    TODO_FILE = "todos.json"

    def load_todos():
        if os.path.exists(TODO_FILE):
            try:
                with open(TODO_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except:
                pass
        return {}

    def save_todos():
        with open(TODO_FILE, "w", encoding="utf-8") as f:
            json.dump(st.session_state.todo, f, ensure_ascii=False, indent=2)

    # ---------- 1. åˆå§‹åŒ– ----------
    if "todo" not in st.session_state:
        st.session_state.todo = load_todos()
    if "sel_date" not in st.session_state:
        st.session_state.sel_date = str(dt.date.today())
    if "cal_key" not in st.session_state:
        st.session_state.cal_key = 0
    if "active_del_id" not in st.session_state:
        st.session_state.active_del_id = None

    # ---------- 2. Emoji å·¥å…· ----------
    _EMOJI_RE = re.compile(
        r'[\U0001F300-\U0001FAFF\U00002700-\U000027BF]+', flags=re.UNICODE
    )
    def first_emoji(text: str) -> str:
        m = _EMOJI_RE.search(text)
        return m.group(0) if m else ""

    # ---------- 3. æœˆæ›†äº‹ä»¶ï¼ˆæ ¼å­åªé¡¯ç¤ºæ–‡å­— + Emojiï¼‰ ----------
    def build_events():
        ev = []
        for d, items in st.session_state.todo.items():
            if not isinstance(items, list):
                continue
            for t in items:
                ev.append({
                    "title": f"{t.get('emoji','')}{t['title']}",
                    "start": f"{d}T{t.get('time','00:00:00')}",
                    "backgroundColor": "#FFE4E1",
                    "borderColor": "#FFE4E1",
                    "textColor": "#333"
                })
        return ev

    # ---------- 4. æœˆæ›†ï¼ˆæŠ˜ç–Šæ¬„ï¼‰ ----------
    with st.expander("ğŸ“… è–ç¶“å­¸ç¿’ç”Ÿæ´»æœˆæ›†", expanded=True):
        cal_options = {
            "headerToolbar": {
                "left": "prev,next today",
                "center": "title",
                "right": ""
            },
            "initialView": "dayGridMonth",
            "displayEventTime": False,
            "height": "auto"
        }

        state = calendar(
            events=build_events(),
            options=cal_options,
            key=f"calendar_{st.session_state.cal_key}"
        )

        if state.get("dateClick"):
            st.session_state.sel_date = state["dateClick"]["date"][:10]
            st.rerun()

    # ---------- 5. ä¸‹æ–¹ä¸‰æ—¥æ¸…å–®ï¼ˆğŸ’Ÿ â†’ ğŸ—‘ï¸ï¼‰ ----------
    st.markdown("##### ğŸ“‹ å¾…è¾¦äº‹é …")

    try:
        base_date = dt.datetime.strptime(
            st.session_state.sel_date, "%Y-%m-%d"
        ).date()
    except:
        base_date = dt.date.today()

    for offset in range(3):
        d_obj = base_date + dt.timedelta(days=offset)
        d_str = str(d_obj)
        if d_str in st.session_state.todo:
            for idx, item in enumerate(st.session_state.todo[d_str]):
                item_id = f"{d_str}_{idx}"

                c1, c2, c3 = st.columns([1, 7, 2], vertical_alignment="top")

                with c1:
                    if st.button("ğŸ’Ÿ", key=f"h_{item_id}"):
                        st.session_state.active_del_id = (
                            None if st.session_state.active_del_id == item_id else item_id
                        )
                        st.rerun()

                with c2:
                    st.write(
                        f"{d_obj.month}/{d_obj.day} "
                        f"{item['time'][:5]} "
                        f"{item.get('emoji','')}{item['title']}"
                    )

                with c3:
                    if st.session_state.active_del_id == item_id:
                        if st.button("ğŸ—‘ï¸", key=f"d_{item_id}"):
                            st.session_state.todo[d_str].pop(idx)
                            save_todos()
                            st.session_state.cal_key += 1
                            st.session_state.active_del_id = None
                            st.rerun()

    # ---------- 6. æ–°å¢å¾…è¾¦ ----------
    st.divider()
    with st.expander("â• æ–°å¢å¾…è¾¦", expanded=True):
        with st.form("todo_form", clear_on_submit=True):
            col1, col2 = st.columns(2)
            with col1:
                in_date = st.date_input("æ—¥æœŸ", base_date)
            with col2:
                in_time = st.time_input("æ™‚é–“", dt.time(9, 0))

            in_title = st.text_input("å¾…è¾¦äº‹é …ï¼ˆå¯å« Emojiï¼‰")

            if st.form_submit_button("ğŸ’¾ å„²å­˜"):
                if in_title:
                    k = str(in_date)
                    if k not in st.session_state.todo:
                        st.session_state.todo[k] = []
                    st.session_state.todo[k].append({
                        "title": in_title,
                        "time": str(in_time),
                        "emoji": first_emoji(in_title)
                    })
                    save_todos()
                    st.session_state.cal_key += 1
                    st.rerun()

# ===================================================================
# 5. TAB3 â”€ æŒ‘æˆ°ï¼ˆå–®ç´”ç¿»è­¯é¡Œï¼Œç„¡æœˆæ›†ï¼‰
# ===================================================================
with tabs[2]:
    col_challenge, col_deco = st.columns([0.7, 0.3])
    with col_challenge:
        st.subheader("ğŸ“ ç¿»è­¯æŒ‘æˆ°")
        st.write("é¡Œç›® 1: æ„šé ‘äººèªªç¾è¨€æœ¬ä¸ç›¸ç¨±...")
        st.text_input("è«‹è¼¸å…¥è‹±æ–‡ç¿»è­¯", key="ans_1_final", placeholder="Type your translation here...")
    with col_deco:
        st.image(IMG_URLS.get("B"), width=150, caption="Keep Going!")

# ===================================================================
# 5. TAB4 â”€ AI æ§åˆ¶å°ï¼ˆé›¶å¾ªç’° + æ°¸ä¹…å­˜æª” + è¼¸å…¥ç”Ÿæ•ˆï¼‰
# ===================================================================
with tabs[3]:
    import os, pandas as pd, io, json
    import datetime as dt  # è£œä¸Šé€™å€‹ import

    # ---------- 0. AI Prompt å®šç¾© ----------
    PROMPT_BIBLE_MASTER = """
ä½ æ˜¯ä¸€ä½ç²¾é€šå¤šåœ‹èªè¨€çš„è–ç¶“å°ˆå®¶èˆ‡èªè¨€å­¸æ•™æˆã€‚è«‹æ ¹æ“šä½¿ç”¨è€…è¼¸å…¥çš„å…§å®¹é¡å‹ï¼Œé¸æ“‡å°æ‡‰çš„æ¨¡å¼è¼¸å‡ºã€‚

---
### æ¨¡å¼ Aï¼šã€è–ç¶“ç¶“æ–‡æ¨¡å¼ã€‘
ç•¶ä½¿ç”¨è€…è¼¸å…¥ç‚ºã€Œä¸­æ–‡è–ç¶“ç¶“æ–‡ã€æ™‚ï¼Œè«‹åš´æ ¼ç”¢å‡ºä»¥ä¸‹ V1 èˆ‡ V2 è¡¨æ ¼æ•¸æ“šï¼Œç¦æ­¢ç”¢å‡ºè¬›ç« ã€‚

ğŸ”¹ V1 Sheet è¦æ±‚ï¼š
1. Ref.ï¼šè‡ªå‹•æ‰¾å°‹ç¶“å·ç« ç¯€ä¸¦ç”¨ç¸®å¯« (å¦‚: Pro, Rom, Gen)ã€‚
2. English (ESV)ï¼šæª¢ç´¢å°æ‡‰çš„ ESV è‹±æ–‡ç¶“æ–‡ã€‚
3. Chineseï¼šå¡«å…¥æˆ‘æä¾›çš„ä¸­æ–‡åŸæ–‡ã€‚
4. Syn/Antï¼š
   - ESV ä¸­çš„å–®å­—æˆ–ç‰‡èªï¼Œä¾å„ªå…ˆé †åºæŒ‘é¸ï¼šé«˜ç´š â†’ ä¸­é«˜ç´š â†’ ä¸­ç´š â†’ ä¸­ç´šä»¥ä¸‹ï¼ˆåƒ…ç•¶å‰ä¸‰é¡çš†ç„¡æ™‚æ‰å¯åˆ—å‡ºï¼‰ã€‚
   - æ¯å€‹è©éœ€åŒ…å«ä¸­/è‹±ç¿»è­¯ã€åŒåç¾©è©ï¼Œä»¥åŠä¸­è‹±å°ç…§è–ç¶“ä¾‹å¥ã€‚
5. Grammarï¼šåš´æ ¼éµå®ˆç¬¦è™ŸåŒ–æ ¼å¼ï¼š
   1ï¸âƒ£[æ–‡æ³•é‚è¼¯è§£æ] 
   2ï¸âƒ£[è£œé½Šå¾Œçš„å®Œæ•´æ‡‰ç”¨å¥] 
   3ï¸âƒ£Ex. [ä¸­è‹±å°ç…§è–ç¶“æ‡‰ç”¨ä¾‹å¥]

ğŸ”¹ V2 Sheet è¦æ±‚ï¼š
1. Ref.ï¼šåŒ V1ã€‚
2. å£èªè¨³ï¼šæª¢ç´¢å°æ‡‰çš„æ—¥æœ¬ã€Šå£èªè¨³è–ç¶“ã€‹(1955)ã€‚
3. Grammarï¼šè§£ææ—¥æ–‡æ–‡æ³•ï¼ˆæ ¼å¼åŒ V1ï¼Œä½¿ç”¨ 1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£Ex.ï¼‰ã€‚
4. Noteï¼šæ—¥æ–‡æ–‡æ³•æˆ–èªå¢ƒçš„è£œå……èªªæ˜ã€‚
5. KRFï¼šæª¢ç´¢å°æ‡‰çš„éŸ“æ–‡ã€ŠKorean Revised Versionã€‹ã€‚
6. Syn/Antï¼š
   - éŸ“æ–‡ä¸­é«˜ç´šå­—ï¼ˆå«æ—¥/éŸ“/ä¸­ç¿»è­¯ï¼‰ï¼Œä¾åŒæ¨£å„ªå…ˆé †åºæŒ‘é¸ï¼šé«˜ç´š â†’ ä¸­é«˜ç´š â†’ ä¸­ç´š â†’ ä¸­ç´šä»¥ä¸‹ï¼ˆåƒ…ç•¶å‰ä¸‰é¡çš†ç„¡æ™‚æ‰å¯åˆ—å‡ºï¼‰ã€‚
7. THSV11ï¼šæª¢ç´¢å°æ‡‰çš„æ³°æ–‡ã€ŠThai Holy Bible, Standard Version 2011ã€‹ã€‚

---
### æ¨¡å¼ Bï¼šã€è‹±æ–‡æ–‡ç¨¿æ¨¡å¼ã€‘
ç•¶ä½¿ç”¨è€…è¼¸å…¥ç‚ºã€Œè‹±æ–‡è¬›é“åˆç¨¿ã€æ™‚ï¼Œè«‹åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š

ğŸ”¹ ç¬¬ä¸€æ­¥ï½œå…§å®¹äº¤éŒ¯ (I-V)ï¼š
åš´æ ¼åŸ·è¡Œå°‡é€å­—ç¨¿è½‰åŒ–ç‚ºæµæš¢ã€æ–‡æ³•æ­£ç¢ºï¼Œ
ä¿ç•™åŸæ–‡ä¸­çš„é«˜ç´š/ä¸­é«˜ç´šå­—èˆ‡ç‰‡èªçš„å®Œæ•´æ–‡ç« ï¼Œä¸å¾—åé›¢åŸç¨¿å…§å®¹
æ®µè½å‘ˆç¾ï¼šã€Œä¸€æ®µç´”è‹±æ–‡ç²¾ç…‰ç¨¿ã€éš¨å³æ¥ã€Œä¸€æ®µä¸­è‹±å¤¾é›œè¬›ç« ã€çš„æ ¼å¼ã€‚

1. ç´”è‹±æ–‡æ®µè½ï¼šä¿®å¾©å¥å¼ï¼‹è¬›å“¡èªæ°£ï¼‹ç¢ºä¿ç¥å­¸ç”¨è©ç²¾ç¢ºä¸”å„ªé›…ä½†ä¸ç”¨è‰±æ·±çš„å­—åŠ é‡é–±è®€é›£åº¦ã€‚
2. ä¸­è‹±å¤¾é›œæ®µè½ï¼šä¿ç•™å®Œæ•´çš„ä¸­æ–‡æ•˜è¿°ï¼Œä¸¦å°‡å°æ‡‰çš„é«˜ç´šåŠä¸­é«˜ç´šè‹±æ–‡è©å½™èˆ‡ç‰‡èªåµŒå…¥æ‹¬è™Ÿä¸­å°ç…§ã€‚
é—œéµè‹±æ–‡è¡“èªåµŒå…¥ä¸­æ–‡æ‹¬è™Ÿï¼Œå¦‚ï¼šæˆ‘å€‘éœ€è¦ä¿æŒå¿ å¿ƒ (steadfast)ã€‚
3. æ’ç‰ˆï¼šå¤§ç¶±æ¨™é¡Œèˆ‡å…§å®¹é–“é ˆæœ‰ç©ºè¡Œã€‚

ğŸ”¹ ç¬¬äºŒæ­¥ï½œèªè¨€ç´ æï¼š
1. Vocabulary (20å€‹) & Phrases (15å€‹): 
    é«˜ç´š/ä¸­é«˜ç´šå­—è©ï¼‹ç‰‡èªï¼›å«ä¸­è­¯ã€å«ä¸­è­¯ä¹‹åŒåç¾©è©ã€ä¸­è‹±å°ç…§è–ç¶“å®Œæ•´ä¾‹å¥ã€‚
    ç¿»è­¯è«‹å®Œå…¨å°ç…§è–ç¶“è£¡çš„ç¶“æ–‡ï¼Œç¦æ­¢è‡ªå·±äº‚ç¿»ï¼Œè–ç¶“æ²’æ™‚æ‰æŒ‰é‚è¼¯ç¿»è­¯ã€‚

2.Grammar List (6å€‹)ï¼šè¦å‰‡å + åŸç¨¿ç¯„ä¾‹ + æ–‡æ³•è§£æ + çµæ§‹é‚„åŸ + [ä¸­è‹±å°ç…§æ‡‰ç”¨ä¾‹å¥]ã€‚
           èªæ³•é‚è¼¯é‚„åŸ (Grammar Restoration)ï¼šé‡å°åŒ…å«ã€Œå€’è£ã€çœç•¥ã€ä»‹ä¿‚è©å‰ç½®ã€
           ç­‰é«˜é›£åº¦çµæ§‹çš„å¥å­ï¼Œ
           åŸ·è¡Œä»¥ä¸‹æ ¼å¼ï¼š
    * åŸæ–‡å‘ˆç¾ï¼š[æ‘˜éŒ„è¬›ç¨¿ä¸­çš„åŸå¥]
    * çµæ§‹é‚„åŸï¼š[å°‡è©²å¥é‚„åŸç‚ºã€Œæ¨™æº–èªåºã€ä¸”ã€Œç„¡çœç•¥ã€çš„å®Œæ•´å¥å­]
    * é‚è¼¯è©³è§£ï¼šä½¿ç”¨ç°¡å–®ä¸­æ–‡èªªæ˜è©²èªæ³•çµæ§‹çš„è®ŠåŒ–é‚è¼¯ï¼ˆå¦‚ï¼šä»‹ä¿‚è©ç‚ºä½•å‰ç§»ï¼‰ã€‚

ã€è¼¸å…¥å…§å®¹ã€‘ï¼š
[[TEXT]]
"""

    # ---------- 1. è³‡æ–™åº«æŒä¹…åŒ–å·¥å…· ----------
    SENTENCES_FILE = "sentences.json"
    
    def load_sentences():
        if os.path.exists(SENTENCES_FILE):
            try:
                with open(SENTENCES_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except:
                pass
        return {}
    
    def save_sentences():
        with open(SENTENCES_FILE, "w", encoding="utf-8") as f:
            json.dump(st.session_state.sentences, f, ensure_ascii=False, indent=2)
    
    def save_analysis_result(data, input_text):
        if "analysis_history" not in st.session_state:
            st.session_state.analysis_history = []
        record = {
            "timestamp": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
            "ref_no": data.get("ref_no", ""),
            "input": input_text[:100] + "..." if len(input_text) > 100 else input_text,
            "data": data
        }
        st.session_state.analysis_history.append(record)

    # ---------- 2. åˆå€¼èˆ‡è‡ªå‹•è®€æª” ----------
    if 'sentences' not in st.session_state:
        st.session_state.sentences = load_sentences()

    with st.expander("ğŸ“šâ‘  è²¼ç¶“æ–‡/è¬›ç¨¿ â†’ â‘¡ ä¸€éµç”Ÿæˆ Prompt â†’ â‘¢ è¤‡è£½åˆ°ä»»æ„ LLM UI â†’ â‘£ å°‡çµæœè²¼å›", expanded=True):
        input_text = st.text_area("", height=300, key="input_text")

        col1, col2, col3, col4 = st.columns([2.5, 3.5, 2, 2])
        
        with col1:
            search_type = st.selectbox("æ“ä½œ", ["AI åˆ†æ", "Ref. åˆªé™¤", "é—œéµå­—åˆªé™¤"])
        
        with col2:
            query_box = None
            if search_type == "Ref. åˆªé™¤":
                query_box = st.text_input("è¼¸å…¥ Ref.ï¼ˆä¾‹ï¼š2Ti 3:10ï¼‰", key="ref_del")
            elif search_type == "é—œéµå­—åˆªé™¤":
                query_box = st.text_input("è¼¸å…¥é—œéµå­—", key="kw_del")
            else:
                st.empty()
        
        with col3:
            if st.button("ğŸ¤– ç”Ÿæˆ AI æŒ‡ä»¤", type="primary", key="ai_analyze_btn"):
                if not input_text:
                    st.error("è«‹å…ˆè²¼ç¶“æ–‡æˆ–è¬›ç¨¿")
                    st.stop()
                if search_type != "AI åˆ†æ":
                    st.warning("è«‹å…ˆé¸æ“‡ã€ŒAI åˆ†æã€æ“ä½œ")
                    st.stop()
                
                final_prompt = PROMPT_BIBLE_MASTER.replace("[[TEXT]]", input_text)
                st.success("âœ… AI æŒ‡ä»¤å·²ç”Ÿæˆï¼è«‹è¤‡è£½ä¸‹æ–¹å…§å®¹åˆ°ä»»æ„ LLM UI")
                st.code(final_prompt, language="text")
                st.info("æ­¥é©Ÿï¼š1) é–‹å•Ÿä»»æ„ LLM UI â†’ 2) æ–°å»ºå°è©± â†’ 3) è¤‡è£½ä¸Šæ–¹æŒ‡ä»¤è²¼ä¸Š â†’ 4) é€å‡ºç­‰å¾…ç”Ÿæˆ â†’ 5) å°‡çµæœè²¼å›ä¸‹æ–¹ã€ŒAI å›å‚³çµæœã€æ¬„ä½")
                
                st.session_state["generated_prompt"] = final_prompt
        
        with col4:
            st.write("")  
            if search_type in ["Ref. åˆªé™¤", "é—œéµå­—åˆªé™¤"]:
                if st.button("ğŸ—‘ï¸ å·¨é‡åˆªé™¤", type="primary", key="bulk_delete_btn"):
                    if query_box is None or not query_box.strip():
                        st.error("è«‹å…ˆè¼¸å…¥åˆªé™¤æ¢ä»¶")
                        st.stop()
                    hits = []
                    for d, v in st.session_state.sentences.items():
                        txt = f"{v.get('ref', '')} {v.get('en', '')} {v.get('zh', '')}".lower()
                        if search_type == "Ref. åˆªé™¤" and query_box.lower() in v.get('ref', '').lower():
                            hits.append((d, v))
                        elif search_type == "é—œéµå­—åˆªé™¤" and query_box.lower() in txt:
                            hits.append((d, v))
                    if hits:
                        st.write(f"å…± {len(hits)} ç­†ï¼ˆå«è–ç¶“ç¶“ç¯€ï¼‰")
                        selected_keys = st.multiselect("å‹¾é¸è¦åˆªé™¤çš„é …ç›®", [d for d, _ in hits])
                        if st.button("ç¢ºèªåˆªé™¤", type="secondary"):
                            for k in selected_keys:
                                st.session_state.sentences.pop(k, None)
                            save_sentences()
                            st.success(f"å·²åˆªé™¤ {len(selected_keys)} ç­†ï¼")
                    else:
                        st.info("ç„¡ç¬¦åˆæ¢ä»¶")

    # ---------- 3. è²¼å› AI çµæœå€ ----------
    st.divider()
    st.markdown("### ğŸ“¥ æ­¥é©Ÿ â‘¡ï¼šå°‡ AI ç”Ÿæˆçš„çµæœè²¼å›é€™è£¡")
    
    ai_result = st.text_area("è²¼ä¸Š LLM å›å‚³çš„åˆ†æçµæœï¼ˆJSON æˆ–è¡¨æ ¼æ ¼å¼ï¼‰", height=250, key="ai_result")
    
    if st.button("ğŸ’¾ å„²å­˜åˆ†æçµæœåˆ°è³‡æ–™åº«", type="primary"):
        if not ai_result:
            st.error("è«‹å…ˆè²¼ä¸Š AI åˆ†æçµæœ")
            st.stop()
        
        try:
            cleaned = ai_result.replace("```json", "").replace("```", "").strip()
            data = json.loads(cleaned)
            
            ref_no = data.get("ref_no", f"AI{dt.datetime.now().strftime('%Y%m%d%H%M')}")
            st.session_state.sentences[ref_no] = {
                "ref": ref_no,
                "en": data.get("ref_article", ""),
                "zh": data.get("ref_article_zh", ""),
                "data": data,
                "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M")
            }
            save_sentences()
            st.session_state["analysis"] = data
            st.session_state["show_result"] = True
            st.success(f"âœ… å·²å„²å­˜ï¼Ref: {ref_no}")
            st.rerun()
            
        except json.JSONDecodeError:
            ref_no = f"TXT{dt.datetime.now().strftime('%Y%m%d%H%M')}"
            st.session_state.sentences[ref_no] = {
                "ref": ref_no,
                "raw_text": ai_result,
                "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M")
            }
            save_sentences()
            st.success(f"âœ… å·²å„²å­˜ç‚ºç´”æ–‡å­—æ ¼å¼ï¼Ref: {ref_no}")

    # ---------- 4. çµæœå‘ˆç¾ ----------
    if st.session_state.get("show_result", False) and st.session_state.get("analysis"):
        data = st.session_state["analysis"]
        st.divider()
        st.markdown(f"## ğŸ“‹ åˆ†æçµæœï¼š{data.get('ref_no', 'N/A')}")
        
        if data.get("ref_article"):
            with st.expander("ğŸ“„ æª¢è¦–ç²¾ç…‰æ–‡ç« ", expanded=True):
                st.markdown(data["ref_article"])
        
        col_w, col_p, col_g = st.tabs(["å–®å­—", "ç‰‡èª", "æ–‡æ³•"])
        with col_w:
            if data.get("words"):
                df = pd.DataFrame(data["words"])
                st.dataframe(df, use_container_width=True)
            else:
                st.info("æœ¬æ¬¡ç„¡å–®å­—åˆ†æ")
        with col_p:
            if data.get("phrases"):
                df = pd.DataFrame(data["phrases"])
                st.dataframe(df, use_container_width=True)
            else:
                st.info("æœ¬æ¬¡ç„¡ç‰‡èªåˆ†æ")
        with col_g:
            if data.get("grammar"):
                df = pd.DataFrame(data["grammar"])
                st.table(df)
            else:
                st.info("æœ¬æ¬¡ç„¡æ–‡æ³•é»")

    # ---------- 5. å®¹é‡ç®¡ç† ----------
    st.divider()
    with st.expander("âš™ï¸ å®¹é‡ç®¡ç†ï¼ˆå«åˆªé™¤åŠŸèƒ½ï¼‰", expanded=False):
        max_keep = st.number_input("æœ€å¤šä¿ç•™æœ€è¿‘å¹¾ç­†åˆ†æç´€éŒ„", min_value=10, max_value=1000, value=50)
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ‚ï¸ å£“ç¸®èˆŠç´€éŒ„"):
                hist = st.session_state.get("analysis_history", [])
                if len(hist) > max_keep:
                    st.session_state.analysis_history = hist[-max_keep:]
                    st.success(f"å·²å£“ç¸®è‡³æœ€è¿‘ {max_keep} ç­†ï¼")
                else:
                    st.info("æœªé”å£“ç¸®é–€æª»")
        
        with col2:
            del_ref = st.text_input("è¼¸å…¥ Ref. åˆªé™¤ç‰¹å®šé …ç›®", key="del_ref_input")
            if st.button("ğŸ—‘ï¸ åˆªé™¤æŒ‡å®š Ref"):
                if del_ref in st.session_state.sentences:
                    del st.session_state.sentences[del_ref]
                    save_sentences()
                    st.success(f"å·²åˆªé™¤ {del_ref}")
                    st.rerun()
                else:
                    st.error("æ‰¾ä¸åˆ°æ­¤ Ref")

    # ---------- 6. åŒ¯å‡º ----------
    if st.button("ğŸ“‹ åŒ¯å‡ºå«å›æº¯æ¬„ä½"):
        export = []
        for k, v in st.session_state.sentences.items():
            export.append(f"{k}\t{v.get('ref', '')}\t{v.get('en', '')}\t{v.get('raw_text', '')[:100]}")
        st.code("\n".join(export), language="text")

