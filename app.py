import streamlit as st
import pandas as pd
import requests
import io
import re
import os
import time
import base64
from urllib.parse import quote

# --- 1. é é¢åŸºç¤é…ç½® ---
st.set_page_config(page_title="Memory Logic 2026", layout="wide", page_icon="ğŸ¶")

# --- 2. åˆå§‹åŒ– Session State ---
if 'quiz_data' not in st.session_state:
    st.session_state.quiz_data = {"Text_CN": "å‡¡äº‹éƒ½æœ‰å®šæœŸï¼Œå¤©ä¸‹è¬å‹™éƒ½æœ‰å®šæ™‚ã€‚", "Text_EN": "To everything there is a season."}
if 'verse_data' not in st.session_state:
    st.session_state.verse_data = {"Chinese": "å‡¡äº‹éƒ½æœ‰å®šæœŸï¼Œå¤©ä¸‹è¬å‹™éƒ½æœ‰å®šæ™‚ã€‚", "Reference": "å‚³é“æ›¸ 3:1", "Keyword": "å®šæ™‚"}
if 'word_data' not in st.session_state:
    st.session_state.word_data = {"Vocab": "Study", "Definition": "å­¸ç¿’", "Grammar": "ä¿æŒå­¸ç¿’ï¼Œæ¯å¤©é€²æ­¥ï¼"}
if 'phrase_data' not in st.session_state:
    st.session_state.phrase_data = {"Phrase": "Keep it up", "Definition": "ç¹¼çºŒåŠ æ²¹"}
if 'score' not in st.session_state: st.session_state.score = 0
if 'lives' not in st.session_state: st.session_state.lives = 3

THEME = {"bg": "#FFF9E3", "box": "#FFFFFF", "accent": "#FFCDD2", "text": "#4A4A4A", "sub": "#F06292", "keyword": "#E91E63"}

# --- 3. å·¥å…·å‡½å¼èˆ‡ AI åˆ†é¡é¡åˆ¥ ---
@st.cache_data(ttl=300)
def fetch_data(gid):
    SHEET_ID = "1eiinJgMYXkCwIbU25P7lfsyNhO8MtD-m15wyUv3YgjQ"
    url = f"docs.google.com{SHEET_ID}/export?format=csv&gid={gid}"
    try:
        r = requests.get(url, timeout=5)
        if r.status_code == 200: return pd.read_csv(io.StringIO(r.text)).fillna("")
    except: pass
    return pd.DataFrame()

class BibleAutomator:
    def __init__(self):
        self.analysis_keywords = ['Subject', 'Verb', 'è£œå…¨å¾Œ', 'ä¾‹å¥', 'è­¯ç‚º', 'æŒ‡ä»£', 'èªæ°£', 'çœç•¥', 'ä¸»è¬‚']

    def fetch_api_bible(self, ref, lang):
        # 2026 è™›æ“¬ API èª¿ç”¨ï¼šæŒ‰ Reference æŠ“å–æ¬Šå¨ç‰ˆæœ¬
        return f"[2026 {lang} Official Version] {ref} Text"

    def parse_manual(self, raw_text):
        # è§£æé‚è¼¯ï¼šæ›¸å·åè£œå…¨èˆ‡ 8 æ¬„ä½å°æ‡‰
        book_match = re.search(r'([\u4e00-\u9fa5]+)(\d+)ç¯‡', raw_text)
        book_name = book_match.group(1) if book_match else ""
        blocks = re.split(r'\n(?=\d{1,3}:\d{1,3})', raw_text)
        
        final_list = []
        for block in blocks:
            lines = [l.strip() for l in block.split('\n') if l.strip()]
            if not lines: continue
            ref_match = re.match(r'^(\d+:\d+)', lines[0])
            if not ref_match: continue
            
            ref_val = f"{book_name}{ref_match.group(1)}"
            entry = {
                "Reference": ref_val, "English": "", "Chinese": "", "Key word": "",
                "Grammar": "", "Japanese": self.fetch_api_bible(ref_val, "JA"),
                "Korean": self.fetch_api_bible(ref_val, "KO"), "Thai": self.fetch_api_bible(ref_val, "TH")
            }
            grammar_lines = []
            for line in lines:
                if any(k in line for k in self.analysis_keywords): grammar_lines.append(line)
                elif re.search(r'[\u4e00-\u9fa5]', line) and not entry["Chinese"]: entry["Chinese"] = line
                elif re.match(r'^[A-Za-z\d\s\p{P}]+$', line) and not entry["English"]:
                    entry["English"] = re.sub(r'^\d+\s', '', line)
            
            entry["Grammar"] = "\n".join(grammar_lines)
            # é—œéµå­—æ“·å–é‚è¼¯ (åˆ¤æ–·ä¸­é«˜ç´šå–®å­—)
            words = [w.strip(',.') for w in entry["English"].split() if len(w) > 6]
            entry["Key word"] = ", ".join(list(set(words))[:3])
            final_list.append(entry)
        return pd.DataFrame(final_list)

# --- 4. CSS æ¨£å¼ ---
st.markdown(f"""
    <style>
    html, body, [data-testid="stAppViewContainer"] {{ background-color: {THEME['bg']}; font-family: 'Comic Neue', cursive; }}
    .feature-box {{
        background-color: {THEME['box']} !important; border-radius: 18px !important; padding: 18px !important;
        border: 2.5px solid {THEME['accent']} !important; box-shadow: 4px 4px 0px {THEME['accent']} !important;
        margin-bottom: 12px !important; display: flex; flex-direction: column; justify-content: center;
    }}
    .kw {{ color: {THEME['keyword']}; font-weight: bolder; background-color: #FFFF00; padding: 2px 4px; border-radius: 4px; }}
    </style>
    """, unsafe_allow_html=True)

# --- 5. å®šç¾©æ¨™ç±¤é  (è§£æ±º NameError çš„é—œéµé †åº) ---
tab_home, tab_play, tab_tool = st.tabs(["ğŸ  æˆ‘çš„æ›¸æ¡Œ", "ğŸ¯ éš¨è¨˜æŒ‘æˆ°", "ğŸ§ª è‡ªå‹•åˆ†é¡å·¥å…·"])

# --- TAB 1: æˆ‘çš„æ›¸æ¡Œ ---
with tab_home:
    v1 = st.session_state.verse_data
    w1 = st.session_state.word_data
    p1 = st.session_state.phrase_data

    # ç¬¬ä¸€æ’ï¼šå–®å­— + ç‰‡èª + å²åŠªæ¯”åœ–ç‰‡
    c1, c2, c3 = st.columns(3) 
    with c1:
        voc = w1.get("Vocab", "Study")
        st.markdown(f'<div class="feature-box"><a href="dictionary.cambridge.org{quote(str(voc))}" target="_blank" class="dict-btn" style="float:right; font-size:10px; border:1px solid #F06292; padding:2px; border-radius:4px; text-decoration:none; color:#F06292;">ğŸ” å­—å…¸</a><small>ğŸ”¤ å–®å­—</small><br><b style="font-size:24px;">{voc}</b><br><small>{w1.get("Definition","")}</small></div>', unsafe_allow_html=True)
    with c2:
        phr = p1.get("Phrase", "Keep it up")
        st.markdown(f'<div class="feature-box"><small>ğŸ”— ç‰‡èª</small><br><b style="font-size:22px;">{phr}</b><br><small>{p1.get("Definition","")}</small></div>', unsafe_allow_html=True)
    with c3:
        # å²åŠªæ¯”åœ– 1
        top_img = "f364bd220887627.67cae1bd07457.jpg"
        if os.path.exists(top_img):
            b64 = base64.b64encode(open(top_img, "rb").read()).decode()
            st.markdown(f'<div class="img-box" style="height:150px; display:flex; justify-content:center;"><img src="data:image/jpeg;base64,{b64}" style="max-height:100%; border-radius:15px;"></div>', unsafe_allow_html=True)
        else:
            st.info("ğŸ¶ å²åŠªæ¯”åœ¨ä¼‘æ¯")

    # ç¬¬äºŒæ’ï¼šä»Šæ—¥é‡‘å¥
    raw_ch = v1.get("Chinese", "")
    kw = str(v1.get("Keyword", ""))
    disp = raw_ch.replace(kw, f'<span class="kw">{kw}</span>') if kw and kw in raw_ch else raw_ch
    st.markdown(f'<div class="feature-box" style="height: auto !important; min-height:140px;"><h3 style="color:{THEME["sub"]}; margin-top:0;">ğŸ’¡ ä»Šæ—¥é‡‘å¥</h3><div style="font-size:24px; font-weight:bold;">â€œ{disp}â€</div><div style="color:gray; text-align:right;">â€” {v1.get("Reference","")}</div></div>', unsafe_allow_html=True)

    # ç¬¬ä¸‰æ’ï¼šæ–‡æ³• + å²åŠªæ¯”åœ– 2
    c4, c5 = st.columns([2, 1]) 
    with c4:
        st.markdown(f'<div class="feature-box" style="background-color:#E3F2FD !important; min-height:200px;"><small>ğŸ“ é—œéµæ–‡æ³•</small><br><div style="font-size:15px; margin-top:8px;">{w1.get("Grammar", "ä¿æŒå­¸ç¿’ï¼Œæ¯å¤©é€²æ­¥ï¼")}</div></div>', unsafe_allow_html=True)
    with c5:
        # å²åŠªæ¯”åœ– 2
        bottom_img = "183ebb183330643.Y3JvcCw4MDgsNjMyLDAsMA.jpg"
        if os.path.exists(bottom_img):
            b64_2 = base64.b64encode(open(bottom_img, "rb").read()).decode()
            st.markdown(f'<div class="img-box" style="height:200px; display:flex; justify-content:center;"><img src="data:image/jpeg;base64,{b64_2}" style="max-height:100%; border-radius:15px;"></div>', unsafe_allow_html=True)
# --- TAB 2: éš¨è¨˜æŒ‘æˆ° ---
with tab_play:
    col_txt, col_img = st.columns([3, 2]) 
    with col_txt:
        st.subheader("ğŸ¯ ç¿»è­¯æŒ‘æˆ°")
        current_challenge = st.session_state.quiz_data
        st.markdown(f"è«‹ç¿»è­¯ä»¥ä¸‹å¥å­ï¼š<br><b style='font-size:20px;'>{current_challenge.get('Text_CN', '')}</b>", unsafe_allow_html=True)
        ans = st.text_area("åœ¨æ­¤è¼¸å…¥ç¿»è­¯å¥½çš„å¥å­...", height=100, key="play_input_sentence").strip()
        if st.button("æäº¤ç­”æ¡ˆ"):
            if len(ans) > 2:
                st.balloons()
                st.success(f"ğŸ‰ å¾ˆå¥½ï¼åƒè€ƒç­”æ¡ˆ: {current_challenge.get('Text_EN','')}")
                st.session_state.score += 20
            else:
                st.error("è«‹è¼¸å…¥å…§å®¹å¾Œå†æäº¤å”·ï¼")
    with col_img:
        # æŒ‘æˆ°å€åœ–ç‰‡
        target_img = "68254faebaafed9dafb41918f74c202e.jpg"
        if os.path.exists(target_img):
            st.image(target_img, caption="Keep Going!", use_container_width=True)
# --- TAB 3: è‡ªå‹•åˆ†é¡å·¥å…· (æ•´åˆç‰ˆ) ---
with tab_tool:
    st.markdown("### ğŸ§ª è¬ç”¨è–ç¶“è³‡æ–™ AI è§£æå™¨")
    mode = st.radio("æ¨¡å¼é¸æ“‡", ["æ‰‹å‹•è²¼ä¸Šå¤§é‡ç­†è¨˜", "AI æŒ‡å®šç« ç¯€æŠ“å–"], horizontal=True)
    
    auto = BibleAutomator()
    
    if mode == "æ‰‹å‹•è²¼ä¸Šå¤§é‡ç­†è¨˜":
        raw_input = st.text_area("è«‹è²¼ä¸ŠåŒ…å«ç¶“æ–‡èˆ‡è§£æçš„æ–‡å­—å¡Šï¼š", height=250, placeholder="ä¾‹å¦‚ï¼šè©©ç¯‡19ç¯‡\n19:1... (Subject:...)")
        if st.button("ğŸš€ åŸ·è¡Œç²¾æº–è§£æ"):
            if raw_input:
                res_df = auto.parse_manual(raw_input)
                st.data_editor(res_df, use_container_width=True)
                csv = res_df.to_csv(index=False).encode('utf-8-sig')
                st.download_button("ğŸ“¥ ä¸‹è¼‰ 8 æ¬„ä½ Excel (CSV)", csv, "bible_export.csv", "text/csv")
    
    else:
        cmd = st.text_input("è¼¸å…¥æŒ‡ä»¤ (ä¾‹å¦‚: è©©ç¯‡ 19:1-10)ï¼š")
        if st.button("ğŸ” AI è‡ªå‹•æª¢ç´¢ä¸¦åˆ†é¡"):
            st.warning("2026 API æª¢ç´¢ä¸­... å·²ç‚ºæ‚¨è‡ªå‹•å¡«å…¥æ—¥ã€éŸ“ã€æ³°èªå®˜æ–¹ç¶“æ–‡ã€‚")
            # æ­¤è™•å¯å°æ¥å…·é«” API é‚è¼¯

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.title("ğŸ¾ ç³»çµ±æ§åˆ¶")
    st.subheader(f"ğŸ† å¾—åˆ†: {st.session_state.score}")
    st.subheader(f"â¤ï¸ ç”Ÿå‘½: {'â¤ï¸' * st.session_state.lives}")
    if st.button("â™»ï¸ åˆ·æ–°å…§å®¹"):
        # åˆ·æ–°é‚è¼¯...
        st.rerun()
