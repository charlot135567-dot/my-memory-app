# ===================================================================
# 0. å¥—ä»¶ & å…¨åŸŸå‡½å¼ï¼ˆä¸€å®šæ”¾æœ€é ‚ï¼‰
# ===================================================================
import streamlit as st
import subprocess, sys, os, datetime as dt, pandas as pd, io, json, re, tomli, tomli_w
from streamlit_calendar import calendar

# ========== é™¤éŒ¯æ¸¬è©¦ ==========
st.sidebar.markdown("## ğŸ”§ é™¤éŒ¯è³‡è¨Š")

api_key = os.getenv("GEMINI_API_KEY")

if api_key:
    st.sidebar.success("âœ… GEMINI_API_KEY å·²è¨­å®š")
    st.sidebar.write(f"é•·åº¦: {len(api_key)} å­—å…ƒ")
else:
    st.sidebar.error("âŒ GEMINI_API_KEY æœªè¨­å®š")
    st.sidebar.info("è«‹åˆ° Settings â†’ Secrets è¨­å®š")
    
# ---------- å…¨åŸŸå·¥å…·å‡½å¼ ----------
def save_analysis_result(result, input_text):
    if "analysis_history" not in st.session_state:
        st.session_state.analysis_history = []
    st.session_state.analysis_history.append({
        "date": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
        "input_preview": input_text[:50] + "..." if len(input_text) > 50 else input_text,
        "result": result
    })
    if len(st.session_state.analysis_history) > 10:
        st.session_state.analysis_history.pop(0)

def to_excel(result: dict) -> bytes:
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        for sheet, key in [("Words", "words"), ("Phrases", "phrases"), ("Grammar", "grammar")]:
            if key in result and result[key]:
                pd.DataFrame(result[key]).to_excel(writer, sheet_name=sheet, index=False)
        stats = pd.DataFrame({
            "é …ç›®": ["ç¸½å­—å½™æ•¸", "ç¸½ç‰‡èªæ•¸", "æ–‡æ³•é»æ•¸", "åˆ†ææ—¥æœŸ"],
            "æ•¸å€¼": [
                len(result.get("words", [])),
                len(result.get("phrases", [])),
                len(result.get("grammar", [])),
                dt.date.today().strftime("%Y-%m-%d")
            ]
        })
        stats.to_excel(writer, sheet_name="çµ±è¨ˆ", index=False)
    buffer.seek(0)
    return buffer.getvalue()

# ===================================================================
# 1. å´é‚Šæ¬„ï¼ˆä¸€æ¬¡ 4 é€£çµï¼Œç„¡é‡è¤‡ï¼‰
# ===================================================================
with st.sidebar:
    st.divider()
    c1, c2 = st.columns(2)
    c1.link_button("âœ¨ Google AI", "https://gemini.google.com/ ")
    c2.link_button("ğŸ¤– Kimi K2",   "https://kimi.moonshot.cn/ ")
    c3, c4 = st.columns(2)
    c3.link_button("ESV Bible", "https://wd.bible/bible/gen.1.cunps?parallel=esv.klb.jcb ")
    c4.link_button("THSV11",    "https://www.bible.com/zh-TW/bible/174/GEN.1.THSV11 ")

# ===================================================================
# 2. é é¢é…ç½® & Session åˆå€¼ï¼ˆåªç•™å…¨åŸŸæœƒç”¨åˆ°çš„ï¼‰
# ===================================================================
st.set_page_config(layout="wide", page_title="Bible Study AI App 2026")

# é€™äº›è®Šæ•¸åªæœ‰ TAB2 æœƒç”¨åˆ°ï¼Œä½†ç‚ºäº†é¿å…å¾ŒçºŒ TAB å¼•ç”¨å‡ºéŒ¯ï¼Œå…ˆçµ¦ç©ºå€¼
if 'analysis_history' not in st.session_state: st.session_state.analysis_history = []

# ---------- CSS ----------
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Gamja+Flower&display=swap ');
.cute-korean { font-family: 'Gamja Flower', cursive; font-size: 20px; color: #FF8C00; text-align: center; }
.small-font { font-size: 13px; color: #555555; margin-top: 5px !important; }
.grammar-box-container {
    background-color: #f8f9fa; border-radius: 8px; padding: 12px;
    border-left: 5px solid #FF8C00; text-align: left; margin-top: 0px;
}
.fc-daygrid-day-frame:hover {background-color: #FFF3CD !important; cursor: pointer; transform: scale(1.03); transition: .2s}
.fc-daygrid-day-frame:active {transform: scale(0.98); background-color: #FFE69C !important}
</style>
""", unsafe_allow_html=True)

# ---------- åœ–ç‰‡ & ç¾æˆ TAB ----------
IMG_URLS = {
    "A": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/183ebb183330643.Y3JvcCw4MDgsNjMyLDAsMA.jpg ",
    "B": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/f364bd220887627.67cae1bd07457.jpg ",
    "C": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/68254faebaafed9dafb41918f74c202e.jpg ",
    "M1": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro1.jpg ",
    "M2": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro2.jpg ",
    "M3": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro3.jpg ",
    "M4": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro4.jpg "
}
with st.sidebar:
    st.markdown('<p class="cute-korean">ë‹¹ì‹ ì€ í•˜ë‚˜ë‹˜ì˜ ì†Œì¤‘í•œ ë³´ë¬¼ì…ë‹ˆë‹¤</p>', unsafe_allow_html=True)
    st.image(IMG_URLS["M3"], width=250)
    st.divider()

tabs = st.tabs(["ğŸ  æ›¸æ¡Œ", "ğŸ““ ç­†è¨˜", "âœï¸ æŒ‘æˆ°", "ğŸ“‚ è³‡æ–™åº«"])

# ===================================================================
# 3. TAB1 â”€ æ›¸æ¡Œï¼ˆå–®ç´”ç¶“æ–‡èˆ‡ä¾‹å¥ï¼Œç„¡æœˆæ›†ï¼‰
# ===================================================================
with tabs[0]:
    col_content, col_m1 = st.columns([0.65, 0.35])
    with col_content:
        st.info("**Becoming** / ğŸ‡¯ğŸ‡µ ãµã•ã‚ã—ã„ | ğŸ‡°ğŸ‡· ì–´ìš¸ë¦¬ëŠ” | ğŸ‡¹ğŸ‡­ à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ | ğŸ‡¨ğŸ‡³ ç›¸ç¨±")
        st.success("""
            ğŸŒŸ **Pro 17:07** Fine speech is not becoming to a fool; still less is false speech to a prince.   
            ğŸ‡¯ğŸ‡µ ã™ãã‚ŒãŸè¨€è‘‰ã¯æ„šã‹è€…ã«ã¯ãµã•ã‚ã—ããªã„ã€‚å½ã‚Šã®è¨€è‘‰ã¯å›ä¸»ã«ã¯ãªãŠã•ã‚‰ãµã•ã‚ã—ããªã„ã€‚   
            ğŸ‡¨ğŸ‡³ æ„šé ‘äººèªªç¾è¨€æœ¬ä¸ç›¸ç¨±ï¼Œä½•æ³å›ç‹èªªè¬Šè©±å‘¢ï¼Ÿ
            """, icon="ğŸ“–")
    with col_m1:
        st.markdown(f"""
            <div style="display:flex;flex-direction:column;justify-content:space-between;height:100%;min-height:250px;text-align:center;">
                <div style="flex-grow:1;display:flex;align-items:center;justify-content:center;">
                    <img src="{IMG_URLS['M1']}" style="width:200px;margin-bottom:10px;">
                </div>
                <div class="grammar-box-container" style="margin-top:auto;">
                    <p style="margin:2px 0;font-size:14px;font-weight:bold;color:#333;">æ™‚æ…‹: ç¾åœ¨ç°¡å–®å¼</p>
                    <p style="margin:2px 0;font-size:14px;font-weight:bold;color:#333;">æ ¸å¿ƒç‰‡èª:</p>
                    <ul style="margin:0;padding-left:18px;font-size:13px;line-height:1.4;color:#555;">
                        <li>Fine speech (å„ªç¾è¨€è¾­)</li>
                        <li>Becoming to (ç›¸ç¨±)</li>
                        <li>Still less (ä½•æ³)</li>
                        <li>False speech (è™›å‡è¨€è¾­)</li>
                    </ul>
                </div>
            </div>
        """, unsafe_allow_html=True)
    st.divider()
    st.markdown("### âœï¸ æ–‡æ³•é‹ç”¨ä¾‹å¥")
    cl1, cl2 = st.columns(2)
    with cl1:
        st.markdown("**Ex 1:** *Casual attire is not becoming to a CEO; still less is unprofessional language.* <p class='small-font'>ä¾¿æœå°åŸ·è¡Œé•·ä¸ç›¸ç¨±ï¼›æ›´ä¸ç”¨èªªä¸å°ˆæ¥­çš„è¨€èªäº†ã€‚</p>", unsafe_allow_html=True)
    with cl2:
        st.markdown("**Ex 2:** *Wealth is not becoming to a man without virtue; still less is power.* <p class='small-font'>è²¡å¯Œå°æ–¼ç„¡å¾·ä¹‹äººä¸ç›¸ç¨±ï¼›æ›´ä¸ç”¨èªªæ¬ŠåŠ›äº†ã€‚</p>", unsafe_allow_html=True)

# ===================================================================
# 4. TAB2 â”€ æœˆæ›†å¾…è¾¦ï¼ˆç©©å®šæœ€çµ‚ç‰ˆï¼Œå²å¥´æ¯”ç§»é™¤ & Reboot è³‡æ–™æŒä¹…åŒ–ï¼‰
# ===================================================================
with tabs[1]:
    import datetime as dt, re, os, json
    import streamlit as st
    from streamlit_calendar import calendar

    # ---------- 0. æª”æ¡ˆæŒä¹…åŒ– (Persistence) ----------
    DATA_DIR = "data"
    os.makedirs(DATA_DIR, exist_ok=True)
    TODO_FILE = os.path.join(DATA_DIR, "todos.json")

    def load_todos():
        if os.path.exists(TODO_FILE):
            try:
                with open(TODO_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                st.error(f"è¼‰å…¥å¤±æ•—: {e}")
        return {}

    def save_todos():
        try:
            with open(TODO_FILE, "w", encoding="utf-8") as f:
                json.dump(st.session_state.todo, f, ensure_ascii=False, indent=2)
        except Exception as e:
            st.error(f"å„²å­˜å¤±æ•—: {e}")

    # ---------- 1. åˆå§‹åŒ– (Initialization) ----------
    if "todo" not in st.session_state:
        st.session_state.todo = load_todos()
    if "sel_date" not in st.session_state:
        st.session_state.sel_date = str(dt.date.today())
    if "cal_key" not in st.session_state:
        st.session_state.cal_key = 0

    # ---------- 2. Emoji å·¥å…· (Emoji Utils) ----------
    _EMOJI_RE = re.compile(r'[\U0001F300-\U0001FAFF\U00002700-\U000027BF]+', flags=re.UNICODE)
    
    def get_clean_title(text: str) -> tuple:
        """å›å‚³ (å–®å€‹Emoji, ç„¡Emojiçš„æ¨™é¡Œ)"""
        found = _EMOJI_RE.search(text)
        emoji = found.group(0)[0] if found else "" # åªå–ç¬¬ä¸€å€‹å­—å…ƒ
        clean_text = _EMOJI_RE.sub('', text).strip() # ç§»é™¤æ‰€æœ‰ Emoji
        return emoji, clean_text

    # ---------- 3. æœˆæ›†äº‹ä»¶ (Calendar Events) ----------
    def build_events():
        ev = []
        for d, items in st.session_state.todo.items():
            for t in items:
                # é‡æ–°è§£æï¼Œç¢ºä¿æ ¼å­å…§ä¸é‡è¤‡
                emo, pure_title = get_clean_title(t['title'])
                ev.append({
                    "title": f"{emo} {pure_title}",
                    "start": f"{d}T{t.get('time','00:00:00')}",
                    "backgroundColor": "#FFE4E1",
                    "borderColor": "#FFE4E1",
                    "textColor": "#333"
                })
        return ev

    # ---------- 4. æœˆæ›†çµ„ä»¶ ----------
    with st.expander("ğŸ“… è–ç¶“å­¸ç¿’ç”Ÿæ´»æœˆæ›†", expanded=True):
        cal_options = {
            "headerToolbar": {"left": "prev,next today", "center": "title", "right": ""},
            "initialView": "dayGridMonth",
            "height": "auto"
        }
        state = calendar(events=build_events(), options=cal_options, key=f"cal_{st.session_state.cal_key}")
        if state.get("dateClick"):
            st.session_state.sel_date = state["dateClick"]["date"][:10]
            st.rerun()

    # ---------- 5. å¾…è¾¦æ¸…å–® (CRUD Operations) ----------
    st.markdown(f"##### ğŸ“‹ {st.session_state.sel_date} èµ·ä¸‰æ—¥æ¸…å–®")
    base_date = dt.datetime.strptime(st.session_state.sel_date, "%Y-%m-%d").date()

    for offset in range(3):
        curr_d = str(base_date + dt.timedelta(days=offset))
        if curr_d in st.session_state.todo:
            # å€’åºåˆªé™¤æ‰ä¸æœƒå½±éŸ¿ index
            for idx, item in enumerate(st.session_state.todo[curr_d]):
                emo, txt = get_clean_title(item['title'])
                c1, c2, c3 = st.columns([1, 8, 1])
                c1.write("ğŸ“")
                c2.write(f"**{item['time'][:5]}** {emo} {txt}")
                if c3.button("ğŸ—‘ï¸", key=f"del_{curr_d}_{idx}"):
                    st.session_state.todo[curr_d].pop(idx)
                    save_todos() # ç«‹å³å­˜æª”
                    st.session_state.cal_key += 1
                    st.rerun()

    # ---------- 6. æ–°å¢ (Create) ----------
    with st.form("add_todo"):
        col1, col2 = st.columns(2)
        in_date = col1.date_input("æ—¥æœŸ", base_date)
        in_time = col2.time_input("æ™‚é–“", dt.time(9, 0))
        in_title = st.text_input("äº‹é …å…§å®¹ (å¯è¼¸å…¥ Emoji)")
        if st.form_submit_button("ğŸ’¾ å„²å­˜ä¸¦åŒæ­¥"):
            if in_title:
                d_key = str(in_date)
                if d_key not in st.session_state.todo:
                    st.session_state.todo[d_key] = []
                st.session_state.todo[d_key].append({"title": in_title, "time": str(in_time)})
                save_todos() # ç«‹å³å­˜æª”
                st.session_state.cal_key += 1
                st.rerun()

# ===================================================================
# 5. TAB3 â”€ æŒ‘æˆ°ï¼ˆå–®ç´”ç¿»è­¯é¡Œï¼Œç„¡æœˆæ›†ï¼‰
# ===================================================================
with tabs[2]:
    col_challenge, col_deco = st.columns([0.7, 0.3])
    with col_challenge:
        st.subheader("ğŸ“ ç¿»è­¯æŒ‘æˆ°")
        st.write("é¡Œç›® 1: æ„šé ‘äººèªªç¾è¨€æœ¬ä¸ç›¸ç¨±...")
        st.text_input("è«‹è¼¸å…¥è‹±æ–‡ç¿»è­¯", key="ans_1_final", placeholder="Type your translation here...")
    with col_deco:
        st.image(IMG_URLS.get("B"), width=150, caption="Keep Going!")

# ===================================================================
# 6. TAB4 â”€ AI æ§åˆ¶å°ï¼ˆSnoopyç½®ä¸­ç‰ˆ + åŠŸèƒ½ä¿®å¾©ï¼‰
# ===================================================================
with tabs[3]:
    import os, json, datetime as dt, pandas as pd, urllib.parse, base64

    # ---------- ğŸ¨ Snoopy èƒŒæ™¯ï¼ˆç°¡åŒ–ç‰ˆï¼Œä¸å½±éŸ¿å…§å®¹ï¼‰----------
    try:
        with open("Snoopy.jpg", "rb") as f:
            img_b64 = base64.b64encode(f.read()).decode()

        st.markdown(f"""
        <style>
        .stApp {{
            background-image: url("data:image/jpeg;base64,{img_b64}");
            background-size: 15% auto;
            background-position: center bottom 30px;
            background-attachment: fixed;
            background-repeat: no-repeat;
        }}
        </style>
        """, unsafe_allow_html=True)
    except:
        pass  # æ²’åœ–ç‰‡ä¹Ÿæ²’é—œä¿‚ï¼Œç¹¼çºŒåŸ·è¡Œ

    # ---------- è³‡æ–™åº«æŒä¹…åŒ– ----------
    SENTENCES_FILE = "sentences.json"

    def load_sentences():
        if os.path.exists(SENTENCES_FILE):
            try:
                with open(SENTENCES_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except:
                pass
        return {}

    def save_sentences(data):
        with open(SENTENCES_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    # åˆå§‹åŒ– session_state
    if 'sentences' not in st.session_state:
        st.session_state.sentences = load_sentences()
    if 'search_results' not in st.session_state:
        st.session_state.search_results = []

    # ---------- ğŸ“ æŠ˜ç–Šæ¬„ 1ï¼šè¼¸å…¥èˆ‡åˆ†æ ----------
    with st.expander("ğŸ“ ç¶“æ–‡è¼¸å…¥èˆ‡AIåˆ†æ", expanded=True):
        c1, c2, c3, c4 = st.columns(4)

        current_input = st.session_state.get("main_input", "")
        ai_prompt = f"""åˆ†æç¶“æ–‡å›å‚³JSONï¼š{{"ref_no":"ç·¨è™Ÿ","ref_article":"è‹±æ–‡","zh_translation":"ä¸­æ–‡","words":[],"phrases":[],"grammar":[]}}ã€‚ç¶“æ–‡ï¼š{current_input}"""
        encoded_prompt = urllib.parse.quote(ai_prompt)

        with c1:
            st.link_button("ğŸ’¬ GPT", f"https://chat.openai.com/?q={encoded_prompt}", use_container_width=True)
        with c2:
            st.link_button("ğŸŒ™ K2", f"https://kimi.com/?q={encoded_prompt}", use_container_width=True)
        with c3:
            st.link_button("ğŸ” G", f"https://gemini.google.com/app?q={encoded_prompt}", use_container_width=True)
        with c4:
            if st.button("ğŸ’¾ å­˜", type="primary", use_container_width=True):
                if not current_input.strip():
                    st.error("è«‹è¼¸å…¥å…§å®¹")
                else:
                    try:
                        data = json.loads(current_input)
                        ref = data.get("ref_no") or data.get("ref") or f"R_{dt.datetime.now().strftime('%m%d%H%M')}"
                        st.session_state.sentences[ref] = {
                            "ref": ref,
                            "en": data.get("ref_article", data.get("en", "")),
                            "zh": data.get("zh_translation", data.get("zh", "")),
                            "words": data.get("words", []),
                            "phrases": data.get("phrases", []),
                            "grammar": data.get("grammar", []),
                            "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M")
                        }
                        save_sentences(st.session_state.sentences)
                        st.success(f"âœ… å·²å­˜ï¼š{ref}")
                        st.session_state["main_input"] = ""
                        st.rerun()
                    except:
                        ref = f"N_{dt.datetime.now().strftime('%m%d%H%M')}"
                        st.session_state.sentences[ref] = {
                            "ref": ref,
                            "en": current_input,
                            "zh": "",
                            "words": [],
                            "phrases": [],
                            "grammar": [],
                            "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M")
                        }
                        save_sentences(st.session_state.sentences)
                        st.success(f"âœ… å·²å­˜ç­†è¨˜ï¼š{ref}")
                        st.session_state["main_input"] = ""
                        st.rerun()

        # ---------- è¼¸å…¥æ¡† ----------
        st.text_area(
            "",
            height=260,
            key="main_input",
            placeholder="ğŸ“ è²¼ç¶“æ–‡â†’é»ä¸‹æ–¹AIé€£çµï¼ˆç³»çµ±æœƒè‡ªå‹•å¸¶ä¸Šé€™æ®µæ–‡å­—ï¼‰",
            label_visibility="collapsed"
        )

        # ---------- AI é€£çµå€ ----------
        current_input = st.session_state.get("main_input", "")
        if current_input.strip():
            ai_prompt = f"""è«‹åˆ†æä»¥ä¸‹è–ç¶“ç¶“æ–‡ï¼Œä»¥ JSON æ ¼å¼å›å‚³ï¼š
{{
  "ref_no": "ç¶“æ–‡ç·¨è™Ÿ",
  "ref_article": "å®Œæ•´è‹±æ–‡ç¶“æ–‡", 
  "zh_translation": "ä¸­æ–‡ç¿»è­¯",
  "words": [],
  "phrases": [],
  "grammar": []
}}
å¾…åˆ†æç¶“æ–‡ï¼š
{current_input}"""
            encoded = urllib.parse.quote(ai_prompt)

            st.caption(f"âœ… ç³»çµ±å·²è®€å–è¼¸å…¥ï¼ˆ{len(current_input)} å­—ï¼‰ï¼Œé»æ“Šä¸‹æ–¹æŒ‰éˆ•å°‡è‡ªå‹•å‚³çµ¦ AIï¼š")
            c1, c2, c3, c4 = st.columns(4)
            with c1:
                st.link_button("ğŸ’¬ GPT", f"https://chat.openai.com/?q={encoded}", use_container_width=True, type="secondary")
            with c2:
                st.link_button("ğŸŒ™ K2", f"https://kimi.com/?q={encoded}", use_container_width=True, type="secondary")
            with c3:
                st.link_button("ğŸ” G", f"https://gemini.google.com/app?q={encoded}", use_container_width=True, type="secondary")
            with c4:
                # ä½ åŸæœ¬ save_data æœªå®šç¾©ï¼Œé€™è£¡å…ˆè¨»è§£æç¤º
                # st.button("ğŸ’¾ å­˜", type="primary", use_container_width=True, on_click=save_data)
                pass
        else:
            st.warning("âš ï¸ è«‹å…ˆåœ¨ä¸Šæ–¹è¼¸å…¥æ¡†è²¼ä¸Šç¶“æ–‡ï¼ŒAI é€£çµæ‰æœƒå‡ºç¾")
            st.write("ï¼ˆç³»çµ±éœ€è¦è¨˜éŒ„è¼¸å…¥å…§å®¹å¾Œï¼Œæ‰èƒ½ç”Ÿæˆå¸¶è³‡æ–™çš„é€£çµï¼‰")

    # ---------- ğŸ” æŠ˜ç–Šæ¬„ 2ï¼šè³‡æ–™ç®¡ç† ----------
    with st.expander("ğŸ” è³‡æ–™æœå°‹èˆ‡ç®¡ç†", expanded=False):
        search_col, btn_col = st.columns([3, 1])
        with search_col:
            query = st.text_input("æœå°‹ Ref. æˆ–é—œéµå­—", key="search_box", placeholder="ä¾‹ï¼š2Ti 3:10 æˆ– love")
        with btn_col:
            if st.button("æœå°‹", type="primary", use_container_width=True):
                if not query:
                    st.warning("è«‹è¼¸å…¥æœå°‹æ¢ä»¶")
                else:
                    kw = query.lower()
                    st.session_state.search_results = [
                        {"key": k, "é¸": False, "Ref.": v.get("ref", k),
                         "å…§å®¹": (v.get("en", "")[:50] + "...") if len(v.get("en", "")) > 50 else v.get("en", ""),
                         "æ—¥æœŸ": v.get("date_added", "")[:10]}
                        for k, v in st.session_state.sentences.items()
                        if kw in f"{v.get('ref','')} {v.get('en','')} {v.get('zh','')}".lower()
                    ]
                    if not st.session_state.search_results:
                        st.info("æ‰¾ä¸åˆ°ç¬¦åˆè³‡æ–™")

        if st.session_state.search_results:
            st.write(f"å…± {len(st.session_state.search_results)} ç­†")
            if st.checkbox("â˜‘ï¸ å…¨é¸"):
                for r in st.session_state.search_results:
                    r["é¸"] = True
            if st.button("ğŸ—‘ï¸ åˆªé™¤å‹¾é¸é …ç›®"):
                selected = [r["key"] for r in st.session_state.search_results if r.get("é¸")]
                if selected:
                    for k in selected:
                        st.session_state.sentences.pop(k, None)
                    save_sentences(st.session_state.sentences)
                    st.success(f"âœ… å·²åˆªé™¤ {len(selected)} ç­†")
                    st.session_state.search_results = []
                    st.rerun()
                else:
                    st.warning("è«‹å…ˆå‹¾é¸è¦åˆªé™¤çš„é …ç›®")
            df = pd.DataFrame(st.session_state.search_results)
            edited = st.data_editor(
                df,
                column_config={
                    "é¸": st.column_config.CheckboxColumn("é¸", width="small"),
                    "key": None,
                    "Ref.": st.column_config.TextColumn("Ref.", width="small"),
                    "å…§å®¹": st.column_config.TextColumn("å…§å®¹é è¦½", width="large"),
                    "æ—¥æœŸ": st.column_config.TextColumn("æ—¥æœŸ", width="small")
                },
                hide_index=True,
                use_container_width=True,
                height=min(350, len(df) * 35 + 40)
            )
            for i, row in edited.iterrows():
                st.session_state.search_results[i]["é¸"] = row["é¸"]

    # ---------- åº•éƒ¨çµ±è¨ˆ ----------
    st.divider()
    st.caption(f"ğŸ’¾ è³‡æ–™åº«ï¼š{len(st.session_state.sentences)} ç­†")
    if st.session_state.sentences:
        json_str = json.dumps(st.session_state.sentences, ensure_ascii=False, indent=2)
        st.download_button(
            "â¬‡ï¸ å‚™ä»½ JSON",
            json_str,
            file_name=f"backup_{dt.datetime.now().strftime('%m%d_%H%M')}.json",
            mime="application/json",
            use_container_width=True
        )

