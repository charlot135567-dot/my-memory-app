import streamlit as st
import pandas as pd
import random

# --- 1. é é¢é…ç½® ---
st.set_page_config(page_title="Memory Logic 2026", layout="wide")

# --- 2. å²åŠªæ¯” Ã— ç‘ªåˆ©æ­ è¦–è¦ºæ³¨å…¥ (å¥¶æ²¹é»ƒã€é»‘ç²—æ¡†ã€å­—é«”å¤§) ---
st.markdown("""
   <style>
    /* æ›ä¸€å€‹æ›´æœ‰æ‰‹ç¹ªæ„Ÿçš„å­—é«” */
    @import url('fonts.googleapis.com');
    
    html, body, [class*="css"] {
        font-family: 'Architects Daughter', cursive;
        background-color: #FFFFFF; /* æ”¹ç‚ºç´”ç™½ï¼Œåƒæ¼«ç•«ç´™ */
    }

    /* è®“é‚Šæ¡†æ›´åƒæ‰‹ç¹ªç·šæ¢ï¼ˆä¸è¦å‰‡æ„Ÿï¼‰ */
    .stAlert, [data-testid="stSidebar"], .stDataFrame {
        border: 4px solid #000000 !important;
        border-radius: 2px !important; /* æ¸›å°‘åœ“è§’ï¼Œæ”¹ç‚ºç¡¬é‚Šæ¡† */
        box-shadow: 8px 8px 0px #000000; /* æ›´åšé‡çš„é™°å½± */
    }
    </style>
    """, unsafe_allow_html=True)

# åœ¨æ¨™é¡Œä¸‹æ–¹åŠ å…¥ä¸€å¼µå²åŠªæ¯”æ’åœ–
st.sidebar.image("media.giphy.com", width=150)

# --- 3. å¤šåˆ†é è³‡æ–™è®€å–é‚è¼¯ ---
# é€™æ˜¯æ‚¨çš„ Google Sheets ID
SHEET_ID = "1eiinJgMYXkCwIbU25P7lfsyNhO8MtD-m15wyUv3YgjQ" 
GIDS = {
    "ğŸ“– ç¶“ç¯€": "1454083804",
    "ğŸ”¤ å–®å­—": "1400979824",
    "ğŸ”— ç‰‡èª": "1657258260"
}

def fetch_data(gid):
    # ä½¿ç”¨æ‚¨çš„å°ˆå±¬ ID é€²è¡Œè®€å–
    url = f"docs.google.com{gid}"
    try:
        data = pd.read_csv(url)
        data.columns = [str(c).strip() for c in data.columns]
        return data.dropna(how='all', axis=0)
    except:
        return pd.DataFrame()

# --- 4. å´é‚Šæ¬„ï¼šé€²åº¦ç®¡ç†èˆ‡é¡åˆ¥åˆ‡æ› ---
if 'exp' not in st.session_state: st.session_state.exp = 0

with st.sidebar:
    st.title("ğŸ¾ Snoopy's Desk")
    selected_tab = st.radio("ğŸ¾ é¸æ“‡å­¸ç¿’é¡åˆ¥", list(GIDS.keys()))
    st.divider()
    # ç‘ªåˆ©æ­éé—œéŠæˆ²é€²åº¦
    st.subheader(f"ğŸ† å²åŠªæ¯”éé—œé€²åº¦")
    lvl_progress = (st.session_state.exp % 5) / 5
    st.progress(lvl_progress)
    st.write(f"å·²æ”¶é›†éª¨é ­: {st.session_state.exp % 5} / 5")
    if st.session_state.exp > 0 and st.session_state.exp % 5 == 0:
        st.balloons()
        st.success("ğŸ‰ éé—œäº†ï¼å²åŠªæ¯”è·³éå±‹é ‚äº†ï¼")
    st.divider()
    search_query = st.text_input("ğŸ” æœå°‹é—œéµå­—...")

# --- 5. ä¸»ä»‹é¢é¡¯ç¤º ---
st.markdown(f'<h1 style="text-align:center;">ğŸ¶ {selected_tab} æ™ºæ…§åº«</h1>', unsafe_allow_html=True)
df = fetch_data(GIDS[selected_tab])

if not df.empty:
    # æœå°‹éæ¿¾é‚è¼¯
    if search_query:
        df = df[df.apply(lambda row: row.astype(str).str.contains(search_query, case=False).any(), axis=1)]

    cmd = st.text_input(f"ğŸ¾ è¼¸å…¥ R é–‹å§‹éš¨æ©Ÿè¤‡ç¿’ ({selected_tab}):").strip().upper()

    if cmd == "R":
        item = df.sample(1).iloc[0]
        st.divider()
        
        if "ç¶“ç¯€" in selected_tab:
            st.markdown(f"ğŸ“ **{item['Reference']}**")
            st.markdown(f'<div class="verse-text">{item["Chinese"]}</div>', unsafe_allow_html=True)
            if st.button("ğŸ“– é¡¯ç¤ºè‹±æ–‡èˆ‡å¤šèªç­”æ¡ˆ"):
                st.success(f"**English:** {item['English']}")
                st.info(f"ğŸ”‘ **Key:** {item['Key word']} | ğŸ“ **Grammar:** {item['Grammar']}")
                cols = st.columns(3)
                cols[0].write(f"ğŸ‡¯ğŸ‡µ {item['Japanese']}")
                cols[1].write(f"ğŸ‡°ğŸ‡· {item['Korean']}")
                cols[2].write(f"ğŸ‡¹ğŸ‡­ {item['Thai']}")
                st.session_state.exp += 1

        elif "å–®å­—" in selected_tab:
            st.subheader(f"â“ é€™å€‹å–®å­—ä»€éº¼æ„æ€ï¼Ÿ â†’ **{item['Vocab']}**")
            st.caption(f"èªè¨€æ¨™è¨»: {item['Language']}")
            if st.button("ğŸ” é¡¯ç¤ºå®šç¾©èˆ‡ä¾‹å¥"):
                st.success(f"**å®šç¾©:** {item['Definition']}")
                st.write(f"**åŒæ„èª:** {item['Synonym']}")
                st.write(f"**ä¾‹å¥:** {item['Example']}")
                st.caption(f"**ä¾‹å¥ç¿»è­¯:** {item['Example_CN']}")
                st.session_state.exp += 1

        elif "ç‰‡èª" in selected_tab:
            st.subheader(f"â“ é€™å€‹ç‰‡èªä»€éº¼æ„æ€ï¼Ÿ â†’ **{item['Phrase']}**")
            st.caption(f"èªè¨€æ¨™è¨»: {item['Language']}")
            if st.button("ğŸ” é¡¯ç¤ºè©³è§£"):
                st.success(f"**å®šç¾©:** {item['Definition']}")
                st.write(f"**ä¾‹å¥:** {item['Example']}")
                st.session_state.exp += 1

    # åº«å­˜è¡¨æ ¼
    with st.expander("ğŸ“š æŸ¥çœ‹æ‰€æœ‰åº«å­˜è³‡æ–™"):
        st.dataframe(df, use_container_width=True)
else:
    st.warning(f"ç›®å‰ {selected_tab} åº«å­˜ç‚ºç©ºï¼Œæˆ– Google Sheets å°šæœªç™¼å¸ƒã€‚")

# --- 6. AI å¤§é‡è¼¸å…¥ä»‹é¢ (Mass Import UI) ---
st.divider()
with st.expander("ğŸ“¥ å¤§é‡è¼¸å…¥è§£æä»‹é¢ (AI Mass Parser)"):
    st.write("è«‹å°‡æ–‡ç« æˆ–å½±ç‰‡å­—å¹•è²¼åœ¨ä¸‹é¢ï¼Œç³»çµ±å°‡è¼”åŠ©æ‚¨åˆ†é¡ã€‚")
    raw_text = st.text_area("åœ¨æ­¤è¼¸å…¥å¤§é‡å…§å®¹...", height=150)
    if st.button("ğŸª„ åŸ·è¡Œçµæ§‹åŒ–åˆ†æ"):
        st.info("åˆ†æä¸­... è«‹æ‰‹å‹•å°‡çµæœè²¼å› Google Sheets å°æ‡‰åˆ†é ã€‚")
        # æ­¤è™•ç‚ºé è¦½é‚è¼¯
        st.code(f"Category: {selected_tab}\nContent: {raw_text[:50]}...")
