import streamlit as st
import pandas as pd
import requests
import io
import re
import os
import random
import time
import base64
from urllib.parse import quote

# --- 1. é é¢åŸºç¤é…ç½® ---
st.set_page_config(page_title="Memory Logic 2026", layout="wide", page_icon="ğŸ¶")

# --- 2. åˆå§‹åŒ– Session State ---
if 'quiz_data' not in st.session_state:
    st.session_state.quiz_data = {"Text_CN": "å‡¡äº‹éƒ½æœ‰å®šæœŸï¼Œå¤©ä¸‹è¬å‹™éƒ½æœ‰å®šæ™‚ã€‚", "Text_EN": "To everything there is a season."}
if 'verse_data' not in st.session_state:
    st.session_state.verse_data = {"Chinese": "å‡¡äº‹éƒ½æœ‰å®šæœŸï¼Œå¤©ä¸‹è¬å‹™éƒ½æœ‰å®šæ™‚ã€‚", "Reference": "å‚³é“æ›¸ 3:1", "Keyword": "å®šæ™‚"}
if 'word_data' not in st.session_state:
    st.session_state.word_data = {"Vocab": "Study", "Definition": "å­¸ç¿’", "Grammar": "ä¿æŒå­¸ç¿’ï¼Œæ¯å¤©é€²æ­¥ï¼"}
if 'phrase_data' not in st.session_state:
    st.session_state.phrase_data = {"Phrase": "Keep it up", "Definition": "ç¹¼çºŒåŠ æ²¹"}
if 'score' not in st.session_state: st.session_state.score = 0
if 'lives' not in st.session_state: st.session_state.lives = 3

THEME = {"bg": "#FFF9E3", "box": "#FFFFFF", "accent": "#FFCDD2", "text": "#4A4A4A", "sub": "#F06292", "keyword": "#E91E63"}

# --- 3. è³‡æ–™æŠ“å–å‡½æ•¸ ---
@st.cache_data(ttl=300)
def fetch_data(gid):
    SHEET_ID = "1eiinJgMYXkCwIbU25P7lfsyNhO8MtD-m15wyUv3YgjQ"
    url = f"docs.google.com{SHEET_ID}/export?format=csv&gid={gid}"
    try:
        r = requests.get(url, timeout=5)
        if r.status_code == 200: return pd.read_csv(io.StringIO(r.text)).fillna("")
    except: pass
    return pd.DataFrame()

# --- 4. CSS æ¨£å¼ (åŒ…å«æ‰€æœ‰é«˜åº¦å°é½Šèˆ‡æ¨£å¼) ---
st.markdown(f"""
    <style>
    @import url('fonts.googleapis.com');
    html, body, [data-testid="stAppViewContainer"] {{ background-color: {THEME['bg']}; font-family: 'Comic Neue', cursive; }}
    .feature-box {{
        background-color: {THEME['box']} !important; border-radius: 18px !important; padding: 18px !important;
        border: 2.5px solid {THEME['accent']} !important; box-shadow: 4px 4px 0px {THEME['accent']} !important;
        margin-bottom: 12px !important; height: 150px !important; display: flex; flex-direction: column; justify-content: center;
    }}
    .grammar-box {{ height: 220px !important; justify-content: flex-start; }}
    .img-box {{ height: 150px !important; display: flex; justify-content: center; align-items: center; }}
    .img-box img {{ max-height: 100%; width: auto; border-radius: 15px; }}
    .img-box.grammar-img {{ height: 220px !important; }}
    .kw {{ color: {THEME['keyword']}; font-weight: bolder; font-size: 1.2em; background-color: #FFFF00; padding: 2px 4px; border-radius: 4px; }}
    .dict-btn {{ color: {THEME['sub']} !important; text-decoration: none !important; font-weight: bold; float: right; font-size: 11px; border: 1px solid {THEME['sub']}; padding: 1px 6px; border-radius: 4px; }}
    </style>
    """, unsafe_allow_html=True)

# --- 5. å®šç¾©åˆ†é æ¨™ç±¤ (è§£æ±º NameError çš„é—œéµè¡Œï¼) ---
tab_home, tab_play, tab_tool = st.tabs(["ğŸ  æˆ‘çš„æ›¸æ¡Œ", "ğŸ¯ éš¨è¨˜æŒ‘æˆ°", "ğŸ§ª è‡ªå‹•åˆ†é¡å·¥å…·"])

# --- TAB 1: æˆ‘çš„æ›¸æ¡Œ (æ’ç‰ˆå·²ç©©å®š) ---
with tab_home:
    v1 = st.session_state.verse_data
    w1 = st.session_state.word_data
    p1 = st.session_state.phrase_data

    # ç¬¬ä¸€æ’ï¼šå–®å­— + ç‰‡èª + å²åŠªæ¯”åœ–ç‰‡ 
    c1, c2, c3 = st.columns() 
    with c1:
        voc = w1.get("Vocab", "Study")
        st.markdown(f'<div class="feature-box"><a href="dictionary.cambridge.org{quote(str(voc))}" target="_blank" class="dict-btn">ğŸ” å­—å…¸</a><small>ğŸ”¤ å–®å­—</small><br><b style="font-size:24px;">{voc}</b><br><small>{w1.get("Definition","")}</small></div>', unsafe_allow_html=True)
    with c2:
        phr = p1.get("Phrase", "Keep it up")
        st.markdown(f'<div class="feature-box"><a href="www.google.com{quote(str(phr))}+meaning" target="_blank" class="dict-btn">ğŸ”— åƒè€ƒ</a><small>ğŸ”— ç‰‡èª</small><br><b style="font-size:22px;">{phr}</b><br><small>{p1.get("Definition","")}</small></div>', unsafe_allow_html=True)
    with c3:
        top_img = "f364bd220887627.67cae1bd07457.jpg"
        if os.path.exists(top_img): st.markdown(f'<div class="img-box"> <img src="data:image/jpeg;base64,{base64.b64encode(open(top_img, "rb").read()).decode()}" alt="Snoopy 1" /> </div>', unsafe_allow_html=True)

    # ç¬¬äºŒæ’ï¼šä»Šæ—¥é‡‘å¥
    raw_ch = v1.get("Chinese", "")
    kw = str(v1.get("Keyword", ""))
    disp = raw_ch.replace(kw, f'<span class="kw">{kw}</span>') if kw and kw in raw_ch else raw_ch
    st.markdown(f'<div class="feature-box" style="min-height:140px; height: auto !important;"><h3 style="color:{THEME["sub"]}; margin-top:0; font-family: "Gloria Hallelujah", cursive;">ğŸ’¡ ä»Šæ—¥é‡‘å¥</h3><div style="font-size:26px; line-height:1.4; font-weight:bold;">â€œ{disp}â€</div><div style="color:gray; margin-top:10px; text-align:right;">â€” {v1.get("Reference","")}</div></div>', unsafe_allow_html=True)

    # ç¬¬ä¸‰æ’ï¼šæ–‡æ³• (å·¦å´å¤§æ¡†) + å²åŠªæ¯”åœ–ç‰‡ (å³å´)
    c4, c5 = st.columns()
    with c4:
        st.markdown(f'<div class="feature-box grammar-box" style="background-color:#E3F2FD !important;"><small>ğŸ“ é—œéµæ–‡æ³•</small><br><div style="font-size:15px; margin-top:8px;">{w1.get("Grammar", "ä¿æŒå­¸ç¿’ï¼Œæ¯å¤©é€²æ­¥ï¼")}</div></div>', unsafe_allow_html=True)
    with c5:
        bottom_img = "183ebb183330643.Y3JvcCw4MDgsNjMyLDAsMA.jpg"
        if os.path.exists(bottom_img): st.markdown(f'<div class="img-box grammar-img"> <img src="data:image/jpeg;base64,{base64.b64encode(open(bottom_img, "rb").read()).decode()}" alt="Snoopy 2" /> </div>', unsafe_allow_html=True)

# --- TAB 2: éš¨è¨˜æŒ‘æˆ° ---
with tab_play:
    col_txt, col_img = st.columns()
    with col_txt:
        st.subheader("ğŸ¯ ç¿»è­¯æŒ‘æˆ° (å¥å­å°ˆå±¬)")
        current_challenge = st.session_state.quiz_data
        st.markdown(f"è«‹ç¿»è­¯ä»¥ä¸‹å¥å­ï¼š<br><b>{current_challenge.get('Text_CN', '')}</b>", unsafe_allow_html=True)
        ans = st.text_area("åœ¨æ­¤è¼¸å…¥ç¿»è­¯å¥½çš„å¥å­...", height=150, key="play_input_sentence").strip()
        if st.button("æäº¤ç­”æ¡ˆ"):
            if len(ans) > 5 and abs(len(ans) - len(current_challenge.get('Text_EN',''))) < 20:
                st.balloons()
                st.session_state.score += 20
                st.success("ğŸ‰ å¤ªæ£’äº†ï¼ç­”å°äº†ï¼(è«‹é»æ“Šå´é‚Šæ¬„åˆ·æ–°ä¸‹ä¸€é¡Œ)")
            else:
                st.session_state.lives -= 1
                st.error(f"âŒ ç­”éŒ¯äº†ï¼ç­”æ¡ˆæ˜¯: {current_challenge.get('Text_EN','')}")
    with col_img:
        target_img = "68254faebaafed9dafb41918f74c202e.jpg"
        if os.path.exists(target_img): st.image(target_img, caption="Cheers!", width=200)

# --- TAB 3: è‡ªå‹•åˆ†é¡å·¥å…· (è¼¸å…¥æ¡†å·²ä¿®æ­£) ---
with tab_tool:
    st.markdown("### ğŸ§ª AI è‡ªå‹•åˆ†é¡èˆ‡åŒ¯å‡º")
    input_text = st.text_area("åœ¨æ­¤è²¼ä¸Šæ•´ç¯‡æ–‡ç« ã€å¤šå€‹å¥å­æˆ–ç¶“ç¯€...", height=200)
    
    def heuristic_classify(item):
        item = item.strip()
        if re.search(r'\b\d{1,3}:\d{1,3}\b', item): return "Verses"
        tokens = item.split()
        if len(tokens) <= 1: return "Words"
        if 2 <= len(tokens) <= 6: return "Phrases"
        return "Verses"

    if st.button("ğŸš€ é–‹å§‹åˆ†æåˆ†é¡"):
        lines = re.split(r'\n+|(?<=[ã€‚ï¼ï¼Ÿ\.\?\!;ï¼›])\s*', input_text)
        results = [{"å…§å®¹": l.strip(), "å»ºè­°åˆ†é¡": heuristic_classify(l)} for l in lines if l.strip()]
        if results:
            st.dataframe(pd.DataFrame(results), use_container_width=True)

            # åŒ¯å‡º Excel åŠŸèƒ½ (æ‹¬è™Ÿå·²ä¿®æ­£)
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                pd.DataFrame(results).to_excel(writer, index=False)
                writer.close()
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è¼‰ç‚º Excel (.xlsx)", 
                data=output.getvalue(), 
                file_name="classified_items.xlsx", 
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
            st.success("åˆ†é¡å®Œæˆï¼æ‚¨å¯ä»¥ä¸‹è¼‰æª”æ¡ˆã€‚")

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.markdown("### ğŸ¾ ç³»çµ±æ§åˆ¶å°")
    st.subheader(f"ğŸ† å¾—åˆ†: {st.session_state.score}")
    st.subheader(f"â¤ï¸ ç”Ÿå‘½: {'â¤ï¸' * max(0, st.session_state.lives)}")
    if st.button("â™»ï¸ åˆ·æ–°å…§å®¹"):
        df_w = fetch_data("1400979824")
        df_v = fetch_data("1454083804")
        df_p = fetch_data("1657258260")
        source_df = pd.concat([df_v, df_p.rename(columns={'Phrase': 'Chinese', 'Definition': 'English'})], ignore_index=True)
        if not source_df.empty:
            new_quiz_item = source_df.sample(1).iloc
            st.session_state.quiz_data = {"Text_CN": new_quiz_item.get("Chinese", ""), "Text_EN": new_quiz_item.get("English", "") or new_quiz_item.get("Vocab", "") or new_quiz_item.get("Phrase", "")}
        if not df_w.empty: st.session_state.word_data = df_w.sample(1).iloc.to_dict()
        if not df_v.empty: st.session_state.verse_data = df_v.sample(1).iloc.to_dict()
        if not df_p.empty: st.session_state.phrase_data = df_p.sample(1).iloc.to_dict()
        st.rerun()
