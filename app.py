# ===================================================================
# 0. å¥—ä»¶ & å…¨åŸŸå‡½å¼ï¼ˆä¸€å®šæ”¾æœ€é ‚ï¼‰
# ===================================================================
import streamlit as st  # â† é€™è£¡å·²ç¶“æœ‰äº†
import subprocess, sys, os, datetime as dt, pandas as pd, io, json, re, tomli, tomli_w
from streamlit_calendar import calendar
import streamlit.components.v1 as components
import requests

token = "secret_ntn_j43799613399XOBBQtD54MQzAvMvU2CMzpZKwrLfg8M0Vx"
database_id = "2f910510e7fb80c4a67ff8735ea90cdf"

headers = {
    "Authorization": f"Bearer {token}",
    "Notion-Version": "2022-06-28"
}

response = requests.get(
    f"{{<https://api.notion.com/v1/databases/{database_id}>}}",
    headers=headers
)

print(f"ç‹€æ…‹ç¢¼: {response.status_code}")
print(f"å›æ‡‰å…§å®¹: {response.json()}")

# åœ¨æ–‡ä»¶æœ€é–‹å§‹åˆå§‹åŒ–æ‰€æœ‰ session state è®Šé‡
def init_session_state():
    defaults = {
        "is_prompt_generated": False,
        # å…¶ä»–è®Šé‡...
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

init_session_state()
   
# ---------- å…¨åŸŸå·¥å…·å‡½å¼ ----------
def save_analysis_result(result, input_text):
    if "analysis_history" not in st.session_state:
        st.session_state.analysis_history = []
    st.session_state.analysis_history.append({
        "date": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
        "input_preview": input_text[:50] + "..." if len(input_text) > 50 else input_text,
        "result": result
    })
    if len(st.session_state.analysis_history) > 10:
        st.session_state.analysis_history.pop(0)

def to_excel(result: dict) -> bytes:
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        for sheet, key in [("Words", "words"), ("Phrases", "phrases"), ("Grammar", "grammar")]:
            if key in result and result[key]:
                pd.DataFrame(result[key]).to_excel(writer, sheet_name=sheet, index=False)
        stats = pd.DataFrame({
            "é …ç›®": ["ç¸½å­—å½™æ•¸", "ç¸½ç‰‡èªæ•¸", "æ–‡æ³•é»æ•¸", "åˆ†ææ—¥æœŸ"],
            "æ•¸å€¼": [
                len(result.get("words", [])),
                len(result.get("phrases", [])),
                len(result.get("grammar", [])),
                dt.date.today().strftime("%Y-%m-%d")
            ]
        })
        stats.to_excel(writer, sheet_name="çµ±è¨ˆ", index=False)
    buffer.seek(0)
    return buffer.getvalue()

# ===================================================================
# 1. å´é‚Šæ¬„ï¼ˆä¸€æ¬¡ 4 é€£çµï¼Œç„¡é‡è¤‡ï¼‰
# ===================================================================
with st.sidebar:
    st.divider()
    c1, c2 = st.columns(2)
    c1.link_button("âœ¨ Google AI", "https://gemini.google.com/")
    c2.link_button("ğŸ¤– Kimi K2",   "https://kimi.moonshot.cn/")
    c3, c4 = st.columns(2)
    c3.link_button("ESV Bible", "https://wd.bible/bible/gen.1.cunps?parallel=esv.klb.jcb")
    c4.link_button("THSV11",    "https://www.bible.com/zh-TW/bible/174/GEN.1.THSV11")
    
    # âœ… åŠ åœ¨é€™è£¡ï¼ˆä»åœ¨ with st.sidebar: å…§éƒ¨ï¼‰
    st.divider()
    st.markdown("### ğŸ–¼ï¸ åº•éƒ¨èƒŒæ™¯è¨­å®š")
    
    bg_options = {
        "ğŸ¶ Snoopy": "Snoopy.jpg",
        "ğŸ° Mashimaro 1": "Mashimaro1.jpg",
        "ğŸ° Mashimaro 2": "Mashimaro2.jpg",
        "ğŸ° Mashimaro 3": "Mashimaro3.jpg",
        "ğŸ° Mashimaro 4": "Mashimaro4.jpg",
        "ğŸ° Mashimaro 5": "Mashimaro5.jpg",
        "ğŸ° Mashimaro 6": "Mashimaro6.jpg"
    }
    
    if 'selected_bg' not in st.session_state:
        st.session_state.selected_bg = list(bg_options.keys())[0]
    if 'bg_size' not in st.session_state:
        st.session_state.bg_size = 15
    if 'bg_bottom' not in st.session_state:
        st.session_state.bg_bottom = 30
    
    selected_bg = st.selectbox(
        "é¸æ“‡è§’è‰²", 
        list(bg_options.keys()), 
        index=list(bg_options.keys()).index(st.session_state.selected_bg),
        key="selected_bg"
    )
    
    col1, col2 = st.columns(2)
    with col1:
        bg_size = st.slider("åœ–ç‰‡å¤§å°", 5, 50, st.session_state.bg_size, format="%d%%", key="bg_size")
    with col2:
        bg_bottom = st.slider("åº•éƒ¨é–“è·", 0, 100, st.session_state.bg_bottom, format="%dpx", key="bg_bottom")

# âœ… æ³¨æ„é€™è£¡å·²ç¶“ä¸åœ¨ with st.sidebar: è£¡é¢äº†ï¼
# èƒŒæ™¯ CSS è¦æ”¾åœ¨é€™è£¡ï¼ˆsidebar å¤–é¢ï¼Œä½†åœ¨ tabs å‰é¢ï¼‰
selected_img_file = bg_options[st.session_state.selected_bg]
current_bg_size = st.session_state.bg_size
current_bg_bottom = st.session_state.bg_bottom

# ---------- èƒŒæ™¯åœ–ç‰‡å¥—ç”¨ï¼ˆè£œä¸Šé€™æ®µï¼ï¼‰----------
try:
    if os.path.exists(selected_img_file):
        with open(selected_img_file, "rb") as f:
            img_b64 = base64.b64encode(f.read()).decode()
        st.markdown(f"""
        <style>
        .stApp {{
            background-image: url("data:image/jpeg;base64,{img_b64}");
            background-size: {current_bg_size}% auto;
            background-position: center bottom {current_bg_bottom}px;
            background-attachment: fixed;
            background-repeat: no-repeat;
            z-index: 0;
        }}
        .main .block-container {{
            position: relative;
            z-index: 1;
            padding-bottom: {current_bg_bottom + 100}px;
        }}
        </style>
        """, unsafe_allow_html=True)
except:
    pass  # èƒŒæ™¯åœ–å¤±æ•—æ™‚éœé»˜è™•ç†

# ===================================================================
# 2. é é¢é…ç½® & Session åˆå€¼ï¼ˆåªç•™å…¨åŸŸæœƒç”¨åˆ°çš„ï¼‰
# ===================================================================
st.set_page_config(layout="wide", page_title="Bible Study AI App 2026")

# é€™äº›è®Šæ•¸åªæœ‰ TAB2 æœƒç”¨åˆ°ï¼Œä½†ç‚ºäº†é¿å…å¾ŒçºŒ TAB å¼•ç”¨å‡ºéŒ¯ï¼Œå…ˆçµ¦ç©ºå€¼
if 'analysis_history' not in st.session_state: st.session_state.analysis_history = []

# ---------- CSS ----------
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Gamja+Flower&display=swap ');
.cute-korean { font-family: 'Gamja Flower', cursive; font-size: 20px; color: #FF8C00; text-align: center; }
.small-font { font-size: 13px; color: #555555; margin-top: 5px !important; }
.grammar-box-container {
    background-color: #f8f9fa; border-radius: 8px; padding: 12px;
    border-left: 5px solid #FF8C00; text-align: left; margin-top: 0px;
}
.fc-daygrid-day-frame:hover {background-color: #FFF3CD !important; cursor: pointer; transform: scale(1.03); transition: .2s}
.fc-daygrid-day-frame:active {transform: scale(0.98); background-color: #FFE69C !important}
</style>
""", unsafe_allow_html=True)

# ---------- åœ–ç‰‡ & ç¾æˆ TAB ----------
IMG_URLS = {
    "A": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/183ebb183330643.Y3JvcCw4MDgsNjMyLDAsMA.jpg ",
    "B": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/f364bd220887627.67cae1bd07457.jpg ",
    "C": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/68254faebaafed9dafb41918f74c202e.jpg ",
    "M1": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro1.jpg ",
    "M2": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro2.jpg ",
    "M3": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro3.jpg ",
    "M4": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro4.jpg "
}
with st.sidebar:
    st.markdown('<p class="cute-korean">ë‹¹ì‹ ì€ í•˜ë‚˜ë‹˜ì˜ ì†Œì¤‘í•œ ë³´ë¬¼ì…ë‹ˆë‹¤</p>', unsafe_allow_html=True)
    st.image(IMG_URLS["M3"], width=250)
    st.divider()

tabs = st.tabs(["ğŸ  æ›¸æ¡Œ", "ğŸ““ ç­†è¨˜", "âœï¸ æŒ‘æˆ°", "ğŸ“‚ è³‡æ–™åº«"])

# ===================================================================
# 3. TAB1 â”€ æ›¸æ¡Œï¼ˆå–®å­—/ç‰‡èª/é‡‘å¥/æ–‡æ³•ï¼Œæ¯å°æ™‚è‡ªå‹•è¼ªæ›ï¼‰
# ===================================================================
with tabs[0]:
    import csv
    from io import StringIO
    import random
    import re
    
    # åˆå§‹åŒ–è¼ªæ›æ™‚é–“
    if 'tab1_last_update' not in st.session_state:
        st.session_state.tab1_last_update = dt.datetime.now()
        st.session_state.tab1_random_seed = random.randint(1, 1000)
    
    # æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¶…é1å°æ™‚ï¼‰
    time_diff = (dt.datetime.now() - st.session_state.tab1_last_update).total_seconds()
    if time_diff > 3600:
        st.session_state.tab1_last_update = dt.datetime.now()
        st.session_state.tab1_random_seed = random.randint(1, 1000)
        st.rerun()
    
    sentences = st.session_state.get('sentences', {})
    
    if not sentences:
        st.warning("è³‡æ–™åº«ç‚ºç©ºï¼Œè«‹å…ˆåœ¨ TAB4 å„²å­˜è³‡æ–™")
    else:
        random.seed(st.session_state.tab1_random_seed)
        selected_ref = random.choice(list(sentences.keys()))
        selected_data = sentences[selected_ref]
        
        v1_content = selected_data.get('v1_content', '')
        v1_rows = []
        if v1_content:
            try:
                lines = v1_content.strip().split('\n')
                if lines:
                    reader = csv.DictReader(lines)
                    v1_rows = list(reader)
            except:
                pass
        
        selected_verse = random.choice(v1_rows) if v1_rows else {}
        
        col_content, col_info = st.columns([0.65, 0.35])
        
        with col_content:
            ref = selected_verse.get('Ref.', 'Pro 17:7')
            english = selected_verse.get('English (ESV)', '')
            chinese = selected_verse.get('Chinese', '')
            
            st.info(f"**{ref}** / ğŸ‡¯ğŸ‡µ ãµã•ã‚ã—ã„ | ğŸ‡°ğŸ‡· ì–´ìš¸ë¦¬ëŠ” | ğŸ‡¹ğŸ‡­ à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ | ğŸ‡¨ğŸ‡³ ç›¸ç¨±")
            st.success(f"""
                ğŸŒŸ **{ref}** {english}  
                ğŸ‡¨ğŸ‡³ {chinese}
                """, icon="ğŸ“–")
            
            st.divider()
            
            # ===== å–®å­—æå–ï¼ˆå¾ Syn/Antï¼‰=====
            syn_ant = selected_verse.get('Syn/Ant', '')
            word_pair = syn_ant.split('/') if '/' in syn_ant else [syn_ant, '']
            
            word_1 = word_pair[0].strip() if len(word_pair) > 0 else ''
            match_1 = re.match(r'(.+?)\s*\((.+?)\)', word_1)
            if match_1:
                word_en = match_1.group(1).strip()
                word_cn = match_1.group(2).strip()
            else:
                word_en = word_1
                word_cn = ''
            
            word_2 = word_pair[1].strip() if len(word_pair) > 1 else ''
            match_2 = re.match(r'(.+?)\s*\((.+?)\)', word_2)
            if match_2:
                ant_en = match_2.group(1).strip()
                ant_cn = match_2.group(2).strip()
            else:
                ant_en = word_2
                ant_cn = ''
            
            st.markdown("### ğŸ“ ä»Šæ—¥å–®å­—")
            col_word1, col_word2 = st.columns(2)
            with col_word1:
                st.markdown(f"**{word_en}**")
                st.caption(f"{word_cn}")
            with col_word2:
                if ant_en:
                    st.markdown(f"<span style='color:#dc3545;'>**{ant_en}**</span>", unsafe_allow_html=True)
                    st.caption(f"{ant_cn} (åç¾©)")
            
            # ===== ç‰‡èª/æ–‡æ³•çµæ§‹ =====
            grammar = selected_verse.get('Grammar', '')
            structure = ''
            if '2ï¸âƒ£[' in grammar:
                structure_match = re.search(r'2ï¸âƒ£\[(.+?)\]', grammar)
                if structure_match:
                    structure = structure_match.group(1)
            else:
                structure = grammar[:80]
            
            st.markdown("### ğŸ”¤ æ–‡æ³•çµæ§‹")
            st.markdown(f"`{structure}`")
        
        with col_info:
            st.markdown("### ğŸ“š æ–‡æ³•è§£æ")
            analysis = ''
            if '1ï¸âƒ£[' in grammar:
                analysis_match = re.search(r'1ï¸âƒ£\[(.+?)\]', grammar)
                if analysis_match:
                    analysis = analysis_match.group(1)
            
            st.markdown(f"""
                <div style="background-color:#f8f9fa;border-radius:8px;padding:12px;border-left:5px solid #FF8C00;">
                    <p style="margin:2px 0;font-size:13px;font-weight:bold;color:#333;">{analysis[:100]}</p>
                    <hr style="margin:8px 0;">
                    <p style="margin:2px 0;font-size:11px;color:#666;">ä¾†æº: {selected_ref}</p>
                    <p style="margin:2px 0;font-size:11px;color:#666;">ä¸‹æ¬¡æ›´æ–°: {((3600 - time_diff) / 60):.0f} åˆ†é˜å¾Œ</p>
                </div>
            """, unsafe_allow_html=True)
        
        st.divider()
        
        # ===== æ–‡æ³•é‹ç”¨ä¾‹å¥ï¼ˆå¾ 3ï¸âƒ£Ex. æå–ï¼Œè‹¥ç„¡å‰‡ç”¨è–ç¶“ç¶“æ–‡ï¼‰=====
        st.markdown("### âœï¸ æ–‡æ³•é‹ç”¨ä¾‹å¥")
        
        example_sentences = []
        if '3ï¸âƒ£Ex.' in grammar:
            ex_part = grammar.split('3ï¸âƒ£Ex.')[-1].strip()
            ex_sentences = re.split(r'[;ï¼›]', ex_part)
            for ex in ex_sentences[:2]:
                ex = ex.strip()
                if ex:
                    ex = re.sub(r'[\[\]]', '', ex)
                    example_sentences.append(ex)
        
        # è‹¥ç„¡ Ex.ï¼Œç”¨è–ç¶“ç¶“æ–‡ä½œç‚ºé è¨­ä¾‹å¥
        if len(example_sentences) < 2:
            example_sentences = [
                english,
                chinese
            ]
        
        cl1, cl2 = st.columns(2)
        with cl1:
            st.markdown(f"**Ex 1:** *{example_sentences[0][:120]}*")
        with cl2:
            if len(example_sentences) > 1:
                st.markdown(f"**Ex 2:** *{example_sentences[1][:120]}*")
            else:
                st.markdown(f"**Ex 2:** *{chinese}*")
# ===================================================================
# 4. TAB2 â”€ æœˆæ›†å¾…è¾¦ + 14å¤©æ»‘å‹•é‡‘å¥ï¼ˆåˆä½µç‰ˆï¼‰
# ===================================================================
with tabs[1]:
    import datetime as dt, re, os, json
    from streamlit_calendar import calendar

    # ==========================================
    # ä¸ŠåŠéƒ¨ï¼šæœˆæ›†å¾…è¾¦ï¼ˆåŸæœ‰åŠŸèƒ½å®Œæ•´ä¿ç•™ï¼‰
    # ==========================================
    
    # ---------- 0. æª”æ¡ˆæŒä¹…åŒ– ----------
    DATA_DIR = "data"
    os.makedirs(DATA_DIR, exist_ok=True)
    TODO_FILE = os.path.join(DATA_DIR, "todos.json")

    def load_todos():
        if os.path.exists(TODO_FILE):
            try:
                with open(TODO_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                print("è¼‰å…¥å¾…è¾¦å¤±æ•—:", e)
        return {}

    def save_todos():
        try:
            with open(TODO_FILE, "w", encoding="utf-8") as f:
                json.dump(st.session_state.todo, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print("å„²å­˜å¾…è¾¦å¤±æ•—:", e)

    # ---------- 1. åˆå§‹åŒ– ----------
    if "todo" not in st.session_state:
        st.session_state.todo = load_todos()
    if "sel_date" not in st.session_state:
        st.session_state.sel_date = str(dt.date.today())
    if "cal_key" not in st.session_state:
        st.session_state.cal_key = 0
    if "active_del_id" not in st.session_state:
        st.session_state.active_del_id = None

    # ---------- 2. Emoji æ¸…æ´—å·¥å…· ----------
    _EMOJI_RE = re.compile(
        r'[\U0001F300-\U0001FAFF\U00002700-\U000027BF]+',
        flags=re.UNICODE
    )

    def get_clean_title(text: str) -> tuple:
        found = _EMOJI_RE.search(text)
        emoji = found.group(0)[0] if found else ""
        clean_text = _EMOJI_RE.sub('', text).strip()
        return emoji, clean_text

    # ---------- 3. æœˆæ›†äº‹ä»¶ ----------
    def build_events():
        ev = []
        for d, items in st.session_state.todo.items():
            if not isinstance(items, list):
                continue
            for t in items:
                emo, pure_title = get_clean_title(t.get("title", ""))
                ev.append({
                    "title": f"{emo} {pure_title}".strip(),
                    "start": f"{d}T{t.get('time','00:00:00')}",
                    "backgroundColor": "#FFE4E1",
                    "borderColor": "#FFE4E1",
                    "textColor": "#333"
                })
        return ev

    # ---------- 4. æœˆæ›† ----------
    with st.expander("ğŸ“… è–ç¶“å­¸ç¿’ç”Ÿæ´»æœˆæ›†", expanded=True):
        cal_options = {
            "headerToolbar": {
                "left": "prev,next today",
                "center": "title",
                "right": ""
            },
            "initialView": "dayGridMonth",
            "displayEventTime": False,
            "height": "auto"
        }

        state = calendar(
            events=build_events(),
            options=cal_options,
            key=f"calendar_{st.session_state.cal_key}"
        )

        if state.get("dateClick"):
            st.session_state.sel_date = state["dateClick"]["date"][:10]
            st.rerun()

    # ---------- 5. ä¸‹æ–¹ä¸‰æ—¥æ¸…å–® ----------
    st.markdown("##### ğŸ“‹ å¾…è¾¦äº‹é …")

    try:
        base_date = dt.datetime.strptime(st.session_state.sel_date, "%Y-%m-%d").date()
    except:
        base_date = dt.date.today()

    for offset in range(3):
        d_obj = base_date + dt.timedelta(days=offset)
        d_str = str(d_obj)
        if d_str in st.session_state.todo:
            for idx, item in enumerate(st.session_state.todo[d_str]):
                item_id = f"{d_str}_{idx}"
                emo, pure_title = get_clean_title(item.get("title", ""))

                c1, c2, c3 = st.columns([0.25, 7.75, 2], vertical_alignment="top")

                with c1:
                    if st.button("ğŸ’Ÿ", key=f"h_{item_id}"):
                        st.session_state.active_del_id = (
                            None if st.session_state.active_del_id == item_id else item_id
                        )
                        st.rerun()

                with c2:
                    st.write(
                        f"{d_obj.month}/{d_obj.day} "
                        f"{item['time'][:5]} "
                        f"{emo} {pure_title}".strip()
                    )

                with c3:
                    if st.session_state.active_del_id == item_id:
                        if st.button("ğŸ—‘ï¸", key=f"d_{item_id}"):
                            st.session_state.todo[d_str].pop(idx)
                            save_todos()
                            st.session_state.cal_key += 1
                            st.session_state.active_del_id = None
                            st.rerun()

    # ---------- 6. æ–°å¢å¾…è¾¦ ----------
    st.divider()
    with st.expander("â• æ–°å¢å¾…è¾¦", expanded=True):
        with st.form("todo_form", clear_on_submit=True):
            col1, col2 = st.columns(2)
            with col1:
                in_date = st.date_input("æ—¥æœŸ", base_date)
            with col2:
                in_time = st.time_input("æ™‚é–“", dt.time(9, 0))

            in_title = st.text_input("å¾…è¾¦äº‹é …ï¼ˆå¯å« Emojiï¼‰")

            if st.form_submit_button("ğŸ’¾ å„²å­˜"):
                if in_title:
                    k = str(in_date)
                    if k not in st.session_state.todo:
                        st.session_state.todo[k] = []
                    st.session_state.todo[k].append({
                        "title": in_title,
                        "time": str(in_time)
                    })
                    save_todos()
                    st.session_state.cal_key += 1
                    st.rerun()

    # ==========================================
    # ä¸‹åŠéƒ¨ï¼š14å¤©æ»‘å‹•é‡‘å¥ï¼ˆæª”æ¡ˆæŒä¹…åŒ– + ç¾è§€äº’å‹•ï¼‰
    # ==========================================
    st.divider()
    st.markdown("### âœ¨ 14å¤©æ»‘å‹•é‡‘å¥")
    
    # æª”æ¡ˆæŒä¹…åŒ–è¨­å®š
    SENTENCES_FILE = os.path.join(DATA_DIR, "daily_sentences.json")
    
    def load_daily_sentences():
        """å¾æª”æ¡ˆè¼‰å…¥é‡‘å¥"""
        if os.path.exists(SENTENCES_FILE):
            try:
                with open(SENTENCES_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                print("è¼‰å…¥é‡‘å¥å¤±æ•—:", e)
        return {}
    
    def save_daily_sentences():
        """å„²å­˜é‡‘å¥åˆ°æª”æ¡ˆ"""
        try:
            with open(SENTENCES_FILE, "w", encoding="utf-8") as f:
                json.dump(st.session_state.daily_sentences_tab2, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print("å„²å­˜é‡‘å¥å¤±æ•—:", e)
            st.error(f"å„²å­˜å¤±æ•—: {e}")
    
    # åƒæ•¸
    DAYS_KEEP = 14
    today = dt.date.today()
    
    # Session åˆå§‹åŒ–
    if "daily_sentences_tab2" not in st.session_state:
        # å…ˆå¾æª”æ¡ˆè¼‰å…¥
        loaded = load_daily_sentences()
        
        # å¦‚æœæ˜¯ç©ºçš„ï¼Œæ”¾å…¥é è¨­5å¥é‡‘å¥
        if not loaded:
            loaded = {}
            default_sentences = [
                "é®æ©äººéçš„ï¼Œå°‹æ±‚äººæ„›ï¼›å±¢æ¬¡æŒ‘éŒ¯çš„ï¼Œé›¢é–“å¯†å‹ã€‚ ç®´è¨€ 17:9\nWhoever covers an offense seeks love, but he who repeats a matter separates close friends. (Proverbs 17:9 ESV)",
                "å› ç‚ºè€¶å’Œè¯æ˜¯ä½ æ‰€å€šé çš„ï¼›ä»–å¿…ä¿å®ˆä½ çš„è…³ä¸é™·å…¥ç¶²ç¾…ã€‚(ç®´è¨€ 3:26)\nfor the LORD will be your confidence and will keep your foot from being caught. (Proverbs 3:26 ESV)",
                "ç®´è¨€ 17:27 å¯¡å°‘è¨€èªçš„ï¼Œæœ‰çŸ¥è­˜ï¼›æ€§æƒ…æº«è‰¯çš„ï¼Œæœ‰è°æ˜ã€‚\nWhoever restrains his words has knowledge, and he who has a cool spirit is a man of understanding. (Proverbs 17:27 ESV)",
                "ç®´è¨€ 17:28 æ„šæ˜§äººè‹¥éœé»˜ä¸è¨€ä¹Ÿå¯ç®—ç‚ºæ™ºæ…§ï¼Œé–‰å£ä¸èªªä¹Ÿå¯ç®—ç‚ºè°æ˜\nEven a fool who keeps silent is considered wise; when he closes his lips, he is deemed intelligent. (Proverbs 17:28 ESV)",
                "è©© 50:23 å‡¡ä»¥æ„Ÿè¬ç»ä¸Šç‚ºç¥­çš„ä¾¿æ˜¯æ¦®è€€æˆ‘ï¼›é‚£æŒ‰æ­£è·¯è€Œè¡Œçš„ï¼Œæˆ‘å¿…ä½¿ä»–å¾—ç€æˆ‘çš„æ•‘æ©ã€‚\nWhoever offers praise glorifies Me; And to him who orders his conduct aright I will show the salvation of God. (Psalms 50:23 NKJV)"
            ]
            for i, sentence in enumerate(default_sentences):
                date_key = str(today - dt.timedelta(days=i))
                loaded[date_key] = sentence
        
        st.session_state.daily_sentences_tab2 = loaded
    
    # åˆå§‹åŒ–åˆªé™¤ç‹€æ…‹
    if "active_sentence_del" not in st.session_state:
        st.session_state.active_sentence_del = None
    
    # æ¯æ—¥æ¸…ç†ï¼šåªä¿ç•™æœ€è¿‘14å¤©
    dates_keep = [today - dt.timedelta(days=i) for i in range(DAYS_KEEP)]
    
    # åˆªé™¤è¶…é14å¤©çš„èˆŠè³‡æ–™
    for d in list(st.session_state.daily_sentences_tab2.keys()):
        try:
            if dt.datetime.strptime(d, "%Y-%m-%d").date() not in dates_keep:
                del st.session_state.daily_sentences_tab2[d]
        except:
            pass
    
    # æ¸…ç†å¾Œç«‹å³å­˜æª”
    save_daily_sentences()

    # æ‘ºç–Šï¼šæ–°å¢/æ›´æ–°é‡‘å¥ï¼ˆå¯é¸ä»»æ„æ—¥æœŸï¼‰
    with st.expander("âœï¸ æ–°å¢æˆ–æ›´æ–°é‡‘å¥"):
        col1, col2, col3 = st.columns([2, 5, 1])
        with col1:
            selected_date = st.date_input("é¸æ“‡æ—¥æœŸ", today, key="sentence_date_tab2")
        with col2:
            new_sentence = st.text_input("é‡‘å¥ï¼ˆä¸­è‹±ä¸¦åˆ—ï¼‰", key="new_sentence_tab2")
        with col3:
            st.write("")
            st.write("")
            if st.button("å„²å­˜", type="primary", key="save_sentence_tab2"):
                if new_sentence:
                    date_key = str(selected_date)
                    st.session_state.daily_sentences_tab2[date_key] = new_sentence
                    save_daily_sentences()
                    st.success(f"å·²å„²å­˜åˆ° {selected_date}ï¼")
                    st.rerun()
                else:
                    st.error("è«‹è¼¸å…¥é‡‘å¥")

    # 14å¤©æ¢åˆ—ï¼ˆæœ€æ–°åœ¨ä¸Šï¼‰
    st.markdown("##### ğŸ“– æœ€è¿‘14å¤©é‡‘å¥åˆ—è¡¨")
    
    for d in sorted(dates_keep, reverse=True):
        date_str = str(d)
        sentence = st.session_state.daily_sentences_tab2.get(date_str, "")
        
        # ç”¢ç”Ÿå”¯ä¸€ ID
        item_id = f"sent_{date_str}"
        
        # ä¸‰æ¬„å¸ƒå±€ï¼šæ—¥æœŸã€å…§å®¹ã€æ“ä½œ
        c1, c2, c3 = st.columns([1, 8, 1.5], vertical_alignment="top")
        
        with c1:
            # æ¨™è¨˜ä»Šå¤©
            if d == today:
                st.markdown(f"**{d.strftime('%m/%d')}** ğŸŒŸ")
            else:
                st.caption(f"{d.strftime('%m/%d')}")
        
        with c2:
            if sentence:
                # é¡¯ç¤ºé‡‘å¥å…§å®¹
                st.info(sentence)
            else:
                # ç„¡é‡‘å¥æ™‚é¡¯ç¤ºæç¤º
                st.caption("ï¼ˆå°šç„¡é‡‘å¥ï¼‰")
        
        with c3:
            # åªæœ‰æœ‰é‡‘å¥çš„æ‰é¡¯ç¤º ğŸ’ å’Œåƒåœ¾æ¡¶
            if sentence:
                # ğŸ’ é»æ“Šåˆ‡æ›åˆªé™¤æ¨¡å¼
                if st.button("ğŸ’", key=f"heart_{item_id}"):
                    if st.session_state.active_sentence_del == item_id:
                        st.session_state.active_sentence_del = None
                    else:
                        st.session_state.active_sentence_del = item_id
                    st.rerun()
                
                # åƒåœ¾æ¡¶ï¼ˆæ¢ä»¶é¡¯ç¤ºï¼‰
                if st.session_state.active_sentence_del == item_id:
                    if st.button("ğŸ—‘ï¸", key=f"del_{item_id}"):
                        del st.session_state.daily_sentences_tab2[date_str]
                        save_daily_sentences()
                        st.session_state.active_sentence_del = None
                        st.rerun()
            else:
                # ç„¡é‡‘å¥æ™‚é¡¯ç¤ºä½”ä½ç¬¦
                st.caption("â€”")

    # çµ±è¨ˆèˆ‡åŒ¯å‡º
    st.divider()
    total_sentences = len([s for s in st.session_state.daily_sentences_tab2.values() if s])
    st.caption(f"å·²å„²å­˜ {total_sentences} / 14 å¤©é‡‘å¥")
    
    col_export, col_clear = st.columns([1, 1])
    with col_export:
        if st.button("ğŸ“‹ åŒ¯å‡ºå…¨éƒ¨é‡‘å¥", key="export_tab2"):
            export_lines = []
            for d in sorted(dates_keep, reverse=True):
                date_str = str(d)
                sent = st.session_state.daily_sentences_tab2.get(date_str, "")
                if sent:
                    export_lines.append(f"{d.strftime('%m/%d')}  {sent}")
            
            if export_lines:
                export = "\n\n".join(export_lines)
                st.code(export, language="text")
            else:
                st.info("å°šç„¡é‡‘å¥å¯åŒ¯å‡º")
    
    with col_clear:
        if st.button("ğŸ§¹ æ¸…ç©ºå…¨éƒ¨", key="clear_all_tab2"):
            st.session_state.daily_sentences_tab2 = {}
            save_daily_sentences()
            st.success("å·²æ¸…ç©ºï¼")
            st.rerun()
                    
# ===================================================================
# 5. TAB3 â”€ æŒ‘æˆ°ï¼ˆç°¡åŒ–ç‰ˆï¼šç›´æ¥çµ¦é¡Œç›®ï¼Œæœ€å¾Œçµ¦ç­”æ¡ˆï¼‰
# ===================================================================
with tabs[2]:
    import csv
    from io import StringIO
    import random
    
    if 'tab3_quiz_seed' not in st.session_state:
        st.session_state.tab3_quiz_seed = random.randint(1, 1000)
        st.session_state.tab3_show_answers = False
    
    sentences = st.session_state.get('sentences', {})
    
    if not sentences:
        st.warning("è³‡æ–™åº«ç‚ºç©ºï¼Œè«‹å…ˆåœ¨ TAB4 å„²å­˜è³‡æ–™")
    else:
        # æ’åºè³‡æ–™
        sorted_refs = sorted(sentences.keys(), 
                           key=lambda x: sentences[x].get('date_added', ''), 
                           reverse=True)
        total = len(sorted_refs)
        
        new_refs = sorted_refs[:int(total*0.6)] if total >= 5 else sorted_refs
        mid_refs = sorted_refs[int(total*0.6):int(total*0.9)] if total >= 10 else []
        old_refs = sorted_refs[int(total*0.9):] if total >= 10 else []
        
        weighted_pool = (new_refs * 6) + (mid_refs * 3) + (old_refs * 1)
        if not weighted_pool:
            weighted_pool = sorted_refs
        
        random.seed(st.session_state.tab3_quiz_seed)
        
        # æ”¶é›†æ‰€æœ‰ç¶“æ–‡è³‡æ–™
        all_verses = []
        for ref in weighted_pool[:10]:  # å–å‰10ç­†è³‡æ–™
            data = sentences[ref]
            v1_content = data.get('v1_content', '')
            if v1_content:
                try:
                    lines = v1_content.strip().split('\n')
                    if lines:
                        reader = csv.DictReader(lines)
                        for row in reader:
                            all_verses.append({
                                'ref': row.get('Ref.', ''),
                                'english': row.get('English (ESV)', ''),
                                'chinese': row.get('Chinese', '')
                            })
                except:
                    pass
        
        # éš¨æ©Ÿé¸6é¡Œï¼ˆ3é¡Œä¸­ç¿»è‹±ï¼Œ3é¡Œè‹±ç¿»ä¸­ï¼‰
        random.shuffle(all_verses)
        selected = all_verses[:6] if len(all_verses) >= 6 else all_verses
        
        # åˆ†é…é¡Œç›®
        zh_to_en = selected[:3]  # ä¸­ç¿»è‹±
        en_to_zh = selected[3:6] if len(selected) > 3 else []  # è‹±ç¿»ä¸­
        
        st.subheader("ğŸ“ ç¿»è­¯æŒ‘æˆ°")
        
        # ===== é¡Œç›® 1-3ï¼šä¸­ç¿»è‹± =====
        for i, q in enumerate(zh_to_en, 1):
            st.markdown(f"**{i}.** {q['chinese'][:60]}")
            st.text_input("", key=f"quiz_zh_en_{i}", placeholder="è«‹ç¿»è­¯æˆè‹±æ–‡...", label_visibility="collapsed")
            st.write("")
        
        # ===== é¡Œç›® 4-6ï¼šè‹±ç¿»ä¸­ =====
        for i, q in enumerate(en_to_zh, 4):
            st.markdown(f"**{i}.** {q['english'][:100]}")
            st.text_input("", key=f"quiz_en_zh_{i}", placeholder="è«‹ç¿»è­¯æˆä¸­æ–‡...", label_visibility="collapsed")
            st.write("")
        
        # ===== å–®å­—é¡Œï¼ˆ3é¡Œï¼‰=====
        # å¾ Syn/Ant æå–å–®å­—
        word_pool = []
        for ref in weighted_pool[:5]:
            data = sentences[ref]
            v1_content = data.get('v1_content', '')
            if v1_content:
                try:
                    lines = v1_content.strip().split('\n')
                    if lines:
                        reader = csv.DictReader(lines)
                        for row in reader:
                            syn_ant = row.get('Syn/Ant', '')
                            if '/' in syn_ant:
                                parts = syn_ant.split('/')
                                for p in parts:
                                    match = re.match(r'(.+?)\s*\((.+?)\)', p.strip())
                                    if match:
                                        word_pool.append({
                                            'en': match.group(1).strip(),
                                            'cn': match.group(2).strip()
                                        })
                except:
                    pass
        
        random.shuffle(word_pool)
        selected_words = word_pool[:3] if len(word_pool) >= 3 else word_pool
        
        for i, w in enumerate(selected_words, 7):
            st.markdown(f"**{i}.** {w['cn']}ï¼ˆè«‹å¯«å‡ºè‹±æ–‡ï¼‰")
            st.text_input("", key=f"quiz_word_{i}", placeholder="English word...", label_visibility="collapsed")
            st.write("")
        
        # ===== ç‰‡èªé¡Œï¼ˆ3é¡Œï¼‰=====
        # å¾ Grammar æå–çµæ§‹
        phrase_pool = []
        for ref in weighted_pool[:5]:
            data = sentences[ref]
            v1_content = data.get('v1_content', '')
            if v1_content:
                try:
                    lines = v1_content.strip().split('\n')
                    if lines:
                        reader = csv.DictReader(lines)
                        for row in reader:
                            grammar = row.get('Grammar', '')
                            if '2ï¸âƒ£[' in grammar:
                                match = re.search(r'2ï¸âƒ£\[(.+?)\]', grammar)
                                if match:
                                    phrase_pool.append({
                                        'structure': match.group(1),
                                        'ref': row.get('Ref.', '')
                                    })
                except:
                    pass
        
        random.shuffle(phrase_pool)
        selected_phrases = phrase_pool[:3] if len(phrase_pool) >= 3 else phrase_pool
        
        for i, p in enumerate(selected_phrases, 10):
            st.markdown(f"**{i}.** è«‹ç”¨ã€Œ{p['structure'][:50]}ã€é€ ä¸€å€‹å¥å­")
            st.text_area("", key=f"quiz_phrase_{i}", placeholder="Make a sentence...", label_visibility="collapsed", height=68)
            st.write("")
        
        st.divider()
        
        # ===== ç¿»çœ‹ç­”æ¡ˆæŒ‰ =====
        col_btn, col_answer = st.columns([1, 3])
        with col_btn:
            if st.button("ğŸ‘ï¸ ç¿»çœ‹æ­£ç¢ºç­”æ¡ˆ", use_container_width=True, type="primary"):
                st.session_state.tab3_show_answers = True
                st.rerun()
        
        with col_answer:
            if st.session_state.tab3_show_answers:
                with st.expander("ğŸ“– æ­£ç¢ºç­”æ¡ˆ", expanded=True):
                    # é¡¯ç¤ºä¸­ç¿»è‹±ç­”æ¡ˆ
                    st.markdown("**ä¸­ç¿»è‹±ï¼š**")
                    for i, q in enumerate(zh_to_en, 1):
                        st.caption(f"{i}. {q['english'][:100]}")
                    
                    # é¡¯ç¤ºè‹±ç¿»ä¸­ç­”æ¡ˆ
                    st.markdown("**è‹±ç¿»ä¸­ï¼š**")
                    for i, q in enumerate(en_to_zh, 4):
                        st.caption(f"{i}. {q['chinese'][:60]}")
                    
                    # é¡¯ç¤ºå–®å­—ç­”æ¡ˆ
                    st.markdown("**å–®å­—ï¼š**")
                    for i, w in enumerate(selected_words, 7):
                        st.caption(f"{i}. {w['en']}")
                    
                    # é¡¯ç¤ºç‰‡èªç­”æ¡ˆ
                    st.markdown("**ç‰‡èªåƒè€ƒï¼š**")
                    for i, p in enumerate(selected_phrases, 10):
                        st.caption(f"{i}. {p['ref']}: {p['structure'][:50]}...")
                
                if st.button("ğŸ”„ æ›ä¸€æ‰¹é¡Œç›®", use_container_width=True):
                    st.session_state.tab3_quiz_seed = random.randint(1, 1000)
                    st.session_state.tab3_show_answers = False
                    st.rerun()
            
# ===================================================================
# 6. TAB4 â”€AI æ§åˆ¶å° + Notion Database æ•´åˆï¼ˆä¿®æ­£ç‰ˆï¼‰
# ===================================================================
with tabs[3]:
    import os, json, datetime as dt, pandas as pd, urllib.parse, base64, re, csv
    from io import StringIO
    import streamlit.components.v1 as components

    # ---------- 1. Notion API è¨­å®š ----------
    NOTION_TOKEN = ""
    try:
        NOTION_TOKEN = st.secrets["notion"]["token"]
    except:
        try:
            NOTION_TOKEN = st.secrets.get("notion", {}).get("token", "")
        except:
            pass
    
    DATABASE_ID = "2f910510e7fb80c4a67ff8735ea90cdf"
    
    # é¡¯ç¤º Token ç‹€æ…‹ï¼ˆé™¤éŒ¯ç”¨ï¼‰
    with st.sidebar:
        st.write("=== Notion é™¤éŒ¯ ===")
        if NOTION_TOKEN:
            st.success(f"Token é•·åº¦: {len(NOTION_TOKEN)}")
            st.write(f"Token å‰20: {NOTION_TOKEN[:20]}...")
        else:
            st.error("Token æœªè®€å–")
            st.write(f"Secrets keys: {list(st.secrets.keys())}")
            try:
                st.write(f"notion å…§å®¹: {st.secrets.get('notion', {})}")
            except:
                pass

    # ---------- 2. æ¸¬è©¦ API é€£ç·šï¼ˆè©³ç´°ç‰ˆï¼‰----------
    if NOTION_TOKEN:
        import requests
        
        # æ¸¬è©¦ 1: é©—è­‰ Token
        try:
            test_response = requests.get(
                "https://api.notion.com/v1/users/me",
                headers={
                    "Authorization": f"Bearer {NOTION_TOKEN}",
                    "Notion-Version": "2022-06-28"
                },
                timeout=10
            )
            
            with st.sidebar:
                st.write(f"Token æ¸¬è©¦ç‹€æ…‹ç¢¼: {test_response.status_code}")
                
                if test_response.status_code == 200:
                    user_name = test_response.json().get('name', 'Unknown')
                    st.success(f"âœ… Token æœ‰æ•ˆ: {user_name}")
                else:
                    st.error(f"âŒ Token ç„¡æ•ˆ: {test_response.text[:200]}")
                    
        except Exception as e:
            with st.sidebar:
                st.error(f"âŒ Token æ¸¬è©¦å¤±æ•—: {str(e)}")
        
        # æ¸¬è©¦ 2: é©—è­‰ Database
        try:
            db_response = requests.get(
                f"https://api.notion.com/v1/databases/{DATABASE_ID}",
                headers={
                    "Authorization": f"Bearer {NOTION_TOKEN}",
                    "Notion-Version": "2022-06-28"
                },
                timeout=10
            )
            
            with st.sidebar:
                st.write(f"Database æ¸¬è©¦ç‹€æ…‹ç¢¼: {db_response.status_code}")
                
                if db_response.status_code == 200:
                    db_title = db_response.json().get('title', [{}])[0].get('text', {}).get('content', 'Unknown')
                    st.success(f"âœ… Database å¯å­˜å–: {db_title}")
                elif db_response.status_code == 404:
                    st.error("âŒ Database ä¸å­˜åœ¨æˆ– ID éŒ¯èª¤")
                elif db_response.status_code == 403:
                    st.error("âŒ ç„¡æ¬Šé™å­˜å– Databaseï¼ˆIntegration æœªé€£çµï¼‰")
                else:
                    st.error(f"âŒ Database éŒ¯èª¤: {db_response.text[:200]}")
                    
        except Exception as e:
            with st.sidebar:
                st.error(f"âŒ Database æ¸¬è©¦å¤±æ•—: {str(e)}")

    # ---------- 3. Notion å‡½æ•¸ ----------
    def save_to_notion(data_dict):
        """å„²å­˜åˆ° Notion"""
        if not NOTION_TOKEN:
            return False, "Token æœªè¨­å®š", None
        
        try:
            import requests
            
            url = "https://api.notion.com/v1/pages"
            headers = {
                "Authorization": f"Bearer {NOTION_TOKEN}",
                "Content-Type": "application/json",
                "Notion-Version": "2022-06-28"
            }
            
            # ç°¡åŒ–å…§å®¹ï¼Œé¿å…æ ¼å¼å•é¡Œ
            content_preview = data_dict.get('original', '')[:100]
            
            properties = {
                "Content": {
                    "title": [{"text": {"content": content_preview}}]
                },
                "Ref_No": {
                    "rich_text": [{"text": {"content": data_dict.get("ref", "N/A")}}]
                },
                "Type": {
                    "select": {"name": data_dict.get("type", "Scripture")}
                },
                "Source_Mode": {
                    "select": {"name": data_dict.get("mode", "Mode A")}
                },
                "Date_Added": {
                    "date": {"start": dt.datetime.now().isoformat()}
                }
            }
            
            # é¸å¡«æ¬„ä½ï¼šTranslationï¼ˆå¦‚æœå…§å®¹å¤ªé•·æœƒå¤±æ•—ï¼Œå…ˆä¸å¡«ï¼‰
            v1 = data_dict.get('v1_content', '')[:500]
            if v1:
                properties["Translation"] = {
                    "rich_text": [{"text": {"content": v1}}]
                }
            
            payload = {
                "parent": {"database_id": DATABASE_ID},
                "properties": properties
            }
            
            response = requests.post(url, headers=headers, json=payload, timeout=10)
            
            if response.status_code == 200:
                page_id = response.json().get("id")
                return True, "æˆåŠŸ", page_id
            else:
                error_detail = response.json() if response.text else "ç„¡è©³ç´°éŒ¯èª¤"
                return False, f"API éŒ¯èª¤ {response.status_code}: {error_detail}", None
                
        except Exception as e:
            return False, f"ä¾‹å¤–éŒ¯èª¤: {str(e)}", None

    # ---------- 4. æœ¬åœ°è³‡æ–™åº« ----------
    SENTENCES_FILE = "sentences.json"

    def load_sentences():
        if os.path.exists(SENTENCES_FILE):
            try:
                with open(SENTENCES_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except:
                pass
        return {}

    def save_sentences(data):
        with open(SENTENCES_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    # ---------- 5. åˆå§‹åŒ– session_state ----------
    if 'sentences' not in st.session_state:
        st.session_state.sentences = load_sentences()
    if 'is_prompt_generated' not in st.session_state:
        st.session_state.is_prompt_generated = False
    if 'main_input_value' not in st.session_state:
        st.session_state.main_input_value = ""
    if 'original_text' not in st.session_state:
        st.session_state.original_text = ""
    if 'content_mode' not in st.session_state:
        st.session_state.content_mode = ""
    if 'ref_number' not in st.session_state:
        st.session_state.ref_number = ""
    if 'current_entry' not in st.session_state:
        st.session_state.current_entry = {'v1': '', 'v2': '', 'other': ''}
    if 'saved_entries' not in st.session_state:
        st.session_state.saved_entries = []

    # ---------- 6. åµæ¸¬å…§å®¹é¡å‹ ----------
    def detect_content_mode(text):
        text = text.strip()
        if not text:
            return "document"
        if text.startswith("{"):
            return "json"
        if re.search(r'[\u4e00-\u9fa5]', text):
            return "scripture"
        return "document"

    # ---------- 7. ç”¢ç”Ÿ Prompt ----------
    def generate_full_prompt():
        raw_text = st.session_state.get("raw_input_temp", "").strip()
        if not raw_text:
            st.warning("è«‹å…ˆè²¼ä¸Šå…§å®¹")
            return
        
        mode = detect_content_mode(raw_text)
        
        if mode == "scripture":
            full_prompt = f"""ä½ æ˜¯ä¸€ä½è–ç¶“å°ˆå®¶ã€‚è«‹åˆ†æä»¥ä¸‹ç¶“æ–‡ï¼Œç”¢å‡º V1 + V2 Excel æ ¼å¼ï¼ˆMarkdown è¡¨æ ¼ï¼‰ã€‚

å¾…åˆ†æç¶“æ–‡ï¼š{raw_text}"""
            st.session_state.content_mode = "A"
        else:
            full_prompt = f"""ä½ æ˜¯ä¸€ä½èªè¨€å­¸æ•™æˆã€‚è«‹åˆ†æä»¥ä¸‹æ–‡ç¨¿ï¼Œç”¢å‡º W + P + Grammar List Excel æ ¼å¼ï¼ˆMarkdown è¡¨æ ¼ï¼‰ã€‚

å¾…åˆ†ææ–‡ç¨¿ï¼š{raw_text}"""
            st.session_state.content_mode = "B"

        st.session_state.original_text = raw_text
        st.session_state.main_input_value = full_prompt
        st.session_state.is_prompt_generated = True
        st.session_state.ref_number = f"REF_{dt.datetime.now().strftime('%m%d%H%M')}"
        st.session_state.current_entry = {'v1': '', 'v2': '', 'other': ''}
        st.session_state.saved_entries = []

    # ---------- 8. UI ä»‹é¢ ----------
    st.header("ğŸ“ AI åˆ†æå·¥ä½œæµç¨‹")
    
    # æ­¥é©Ÿ 1
    with st.expander("æ­¥é©Ÿ 1ï¼šè¼¸å…¥å…§å®¹", expanded=not st.session_state.is_prompt_generated):
        st.text_area(
            "åŸå§‹è¼¸å…¥",
            height=200,
            placeholder="è²¼ä¸Šç¶“æ–‡æˆ–æ–‡ç¨¿...",
            key="raw_input_temp"
        )
        
        if not st.session_state.is_prompt_generated:
            if st.button("âš¡ ç”¢ç”Ÿåˆ†ææŒ‡ä»¤", type="primary"):
                generate_full_prompt()
                st.rerun()

    # æ­¥é©Ÿ 2
    if st.session_state.is_prompt_generated:
        with st.expander("æ­¥é©Ÿ 2ï¼šè¤‡è£½åˆ° AI"):
            st.text_area("Prompt", value=st.session_state.main_input_value, height=250, disabled=True)
            
            cols = st.columns(3)
            with cols[0]:
                encoded = urllib.parse.quote(st.session_state.main_input_value)
                st.link_button("ğŸ’¬ GPT", f"https://chat.openai.com/?q={encoded}")
            with cols[1]:
                st.link_button("ğŸŒ™ Kimi", "https://kimi.com")
            with cols[2]:
                st.link_button("ğŸ” Gemini", "https://gemini.google.com")

        # æ­¥é©Ÿ 3
        with st.expander("æ­¥é©Ÿ 3ï¼šè²¼ä¸Š AI çµæœ", expanded=True):
            sheet = st.selectbox("é¸æ“‡å·¥ä½œè¡¨", ["V1 Sheet", "V2 Sheet", "å…¶ä»–"])
            content = st.text_area("å…§å®¹", height=200)
            
            if st.button("â• æš«å­˜"):
                key_map = {"V1 Sheet": "v1", "V2 Sheet": "v2", "å…¶ä»–": "other"}
                key = key_map.get(sheet, "other")
                st.session_state.current_entry[key] = content
                if sheet not in st.session_state.saved_entries:
                    st.session_state.saved_entries.append(sheet)
                st.success(f"âœ… {sheet} å·²æš«å­˜")
                st.rerun()
            
            if st.session_state.saved_entries:
                st.write("å·²æš«å­˜ï¼š", " | ".join(st.session_state.saved_entries))

        # æ­¥é©Ÿ 4
        with st.expander("æ­¥é©Ÿ 4ï¼šå„²å­˜", expanded=True):
            ref_input = st.text_input("Ref_No", value=st.session_state.ref_number)
            
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ğŸ’¾ å­˜æœ¬åœ°"):
                    ref = ref_input or st.session_state.ref_number
                    data = {
                        "ref": ref,
                        "original": st.session_state.original_text,
                        "v1_content": st.session_state.current_entry['v1'],
                        "v2_content": st.session_state.current_entry['v2'],
                        "saved_sheets": st.session_state.saved_entries,
                        "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M")
                    }
                    st.session_state.sentences[ref] = data
                    save_sentences(st.session_state.sentences)
                    st.success(f"âœ… å·²å­˜æœ¬åœ°ï¼š{ref}")
            
            with col2:
                if NOTION_TOKEN:
                    if st.button("ğŸš€ å­˜ Notion", type="primary"):
                        data = {
                            "original": st.session_state.original_text,
                            "v1_content": st.session_state.current_entry['v1'],
                            "ref": ref_input or st.session_state.ref_number,
                            "type": "Scripture",
                            "mode": f"Mode {st.session_state.content_mode}"
                        }
                        success, msg, page_id = save_to_notion(data)
                        if success:
                            st.success(f"âœ… å·²å­˜ Notionï¼š{page_id[:8]}...")
                        else:
                            st.error(f"âŒ å¤±æ•—ï¼š{msg}")
                else:
                    st.button("ğŸš€ å­˜ Notion", disabled=True)

    # é¡¯ç¤ºçµ±è¨ˆ
    st.divider()
    st.write(f"ğŸ’¾ æœ¬åœ°è³‡æ–™ï¼š{len(st.session_state.sentences)} ç­†")
