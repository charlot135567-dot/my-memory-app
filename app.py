# ===================================================================
# 0. å¥—ä»¶ & å…¨åŸŸå‡½å¼ï¼ˆä¸€å®šæ”¾æœ€é ‚ï¼‰
# ===================================================================
import streamlit as st
import subprocess, sys, os, datetime as dt, pandas as pd, io, json, re, tomli, tomli_w
from streamlit_calendar import calendar

# ========== é™¤éŒ¯æ¸¬è©¦ ==========
st.sidebar.markdown("## ğŸ”§ é™¤éŒ¯è³‡è¨Š")

api_key = os.getenv("GEMINI_API_KEY")

if api_key:
    st.sidebar.success("âœ… GEMINI_API_KEY å·²è¨­å®š")
    st.sidebar.write(f"é•·åº¦: {len(api_key)} å­—å…ƒ")
else:
    st.sidebar.error("âŒ GEMINI_API_KEY æœªè¨­å®š")
    st.sidebar.info("è«‹åˆ° Settings â†’ Secrets è¨­å®š")
    
# ---------- å…¨åŸŸå·¥å…·å‡½å¼ ----------
def save_analysis_result(result, input_text):
    if "analysis_history" not in st.session_state:
        st.session_state.analysis_history = []
    st.session_state.analysis_history.append({
        "date": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
        "input_preview": input_text[:50] + "..." if len(input_text) > 50 else input_text,
        "result": result
    })
    if len(st.session_state.analysis_history) > 10:
        st.session_state.analysis_history.pop(0)

def to_excel(result: dict) -> bytes:
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        for sheet, key in [("Words", "words"), ("Phrases", "phrases"), ("Grammar", "grammar")]:
            if key in result and result[key]:
                pd.DataFrame(result[key]).to_excel(writer, sheet_name=sheet, index=False)
        stats = pd.DataFrame({
            "é …ç›®": ["ç¸½å­—å½™æ•¸", "ç¸½ç‰‡èªæ•¸", "æ–‡æ³•é»æ•¸", "åˆ†ææ—¥æœŸ"],
            "æ•¸å€¼": [
                len(result.get("words", [])),
                len(result.get("phrases", [])),
                len(result.get("grammar", [])),
                dt.date.today().strftime("%Y-%m-%d")
            ]
        })
        stats.to_excel(writer, sheet_name="çµ±è¨ˆ", index=False)
    buffer.seek(0)
    return buffer.getvalue()

# ===================================================================
# 1. å´é‚Šæ¬„ï¼ˆä¸€æ¬¡ 4 é€£çµï¼Œç„¡é‡è¤‡ï¼‰
# ===================================================================
with st.sidebar:
    st.divider()
    c1, c2 = st.columns(2)
    c1.link_button("âœ¨ Google AI", "https://gemini.google.com/ ")
    c2.link_button("ğŸ¤– Kimi K2",   "https://kimi.moonshot.cn/ ")
    c3, c4 = st.columns(2)
    c3.link_button("ESV Bible", "https://wd.bible/bible/gen.1.cunps?parallel=esv.klb.jcb ")
    c4.link_button("THSV11",    "https://www.bible.com/zh-TW/bible/174/GEN.1.THSV11 ")

# ===================================================================
# 2. é é¢é…ç½® & Session åˆå€¼ï¼ˆåªç•™å…¨åŸŸæœƒç”¨åˆ°çš„ï¼‰
# ===================================================================
st.set_page_config(layout="wide", page_title="Bible Study AI App 2026")

# é€™äº›è®Šæ•¸åªæœ‰ TAB2 æœƒç”¨åˆ°ï¼Œä½†ç‚ºäº†é¿å…å¾ŒçºŒ TAB å¼•ç”¨å‡ºéŒ¯ï¼Œå…ˆçµ¦ç©ºå€¼
if 'analysis_history' not in st.session_state: st.session_state.analysis_history = []

# ---------- CSS ----------
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Gamja+Flower&display=swap ');
.cute-korean { font-family: 'Gamja Flower', cursive; font-size: 20px; color: #FF8C00; text-align: center; }
.small-font { font-size: 13px; color: #555555; margin-top: 5px !important; }
.grammar-box-container {
    background-color: #f8f9fa; border-radius: 8px; padding: 12px;
    border-left: 5px solid #FF8C00; text-align: left; margin-top: 0px;
}
.fc-daygrid-day-frame:hover {background-color: #FFF3CD !important; cursor: pointer; transform: scale(1.03); transition: .2s}
.fc-daygrid-day-frame:active {transform: scale(0.98); background-color: #FFE69C !important}
</style>
""", unsafe_allow_html=True)

# ---------- åœ–ç‰‡ & ç¾æˆ TAB ----------
IMG_URLS = {
    "A": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/183ebb183330643.Y3JvcCw4MDgsNjMyLDAsMA.jpg ",
    "B": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/f364bd220887627.67cae1bd07457.jpg ",
    "C": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/68254faebaafed9dafb41918f74c202e.jpg ",
    "M1": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro1.jpg ",
    "M2": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro2.jpg ",
    "M3": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro3.jpg ",
    "M4": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro4.jpg "
}
with st.sidebar:
    st.markdown('<p class="cute-korean">ë‹¹ì‹ ì€ í•˜ë‚˜ë‹˜ì˜ ì†Œì¤‘í•œ ë³´ë¬¼ì…ë‹ˆë‹¤</p>', unsafe_allow_html=True)
    st.image(IMG_URLS["M3"], width=250)
    st.divider()

tabs = st.tabs(["ğŸ  æ›¸æ¡Œ", "ğŸ““ ç­†è¨˜", "âœï¸ æŒ‘æˆ°", "ğŸ“‚ è³‡æ–™åº«"])

# ===================================================================
# 3. TAB1 â”€ æ›¸æ¡Œï¼ˆå–®ç´”ç¶“æ–‡èˆ‡ä¾‹å¥ï¼Œç„¡æœˆæ›†ï¼‰
# ===================================================================
with tabs[0]:
    col_content, col_m1 = st.columns([0.65, 0.35])
    with col_content:
        st.info("**Becoming** / ğŸ‡¯ğŸ‡µ ãµã•ã‚ã—ã„ | ğŸ‡°ğŸ‡· ì–´ìš¸ë¦¬ëŠ” | ğŸ‡¹ğŸ‡­ à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ | ğŸ‡¨ğŸ‡³ ç›¸ç¨±")
        st.success("""
            ğŸŒŸ **Pro 17:07** Fine speech is not becoming to a fool; still less is false speech to a prince.   
            ğŸ‡¯ğŸ‡µ ã™ãã‚ŒãŸè¨€è‘‰ã¯æ„šã‹è€…ã«ã¯ãµã•ã‚ã—ããªã„ã€‚å½ã‚Šã®è¨€è‘‰ã¯å›ä¸»ã«ã¯ãªãŠã•ã‚‰ãµã•ã‚ã—ããªã„ã€‚   
            ğŸ‡¨ğŸ‡³ æ„šé ‘äººèªªç¾è¨€æœ¬ä¸ç›¸ç¨±ï¼Œä½•æ³å›ç‹èªªè¬Šè©±å‘¢ï¼Ÿ
            """, icon="ğŸ“–")
    with col_m1:
        st.markdown(f"""
            <div style="display:flex;flex-direction:column;justify-content:space-between;height:100%;min-height:250px;text-align:center;">
                <div style="flex-grow:1;display:flex;align-items:center;justify-content:center;">
                    <img src="{IMG_URLS['M1']}" style="width:200px;margin-bottom:10px;">
                </div>
                <div class="grammar-box-container" style="margin-top:auto;">
                    <p style="margin:2px 0;font-size:14px;font-weight:bold;color:#333;">æ™‚æ…‹: ç¾åœ¨ç°¡å–®å¼</p>
                    <p style="margin:2px 0;font-size:14px;font-weight:bold;color:#333;">æ ¸å¿ƒç‰‡èª:</p>
                    <ul style="margin:0;padding-left:18px;font-size:13px;line-height:1.4;color:#555;">
                        <li>Fine speech (å„ªç¾è¨€è¾­)</li>
                        <li>Becoming to (ç›¸ç¨±)</li>
                        <li>Still less (ä½•æ³)</li>
                        <li>False speech (è™›å‡è¨€è¾­)</li>
                    </ul>
                </div>
            </div>
        """, unsafe_allow_html=True)
    st.divider()
    st.markdown("### âœï¸ æ–‡æ³•é‹ç”¨ä¾‹å¥")
    cl1, cl2 = st.columns(2)
    with cl1:
        st.markdown("**Ex 1:** *Casual attire is not becoming to a CEO; still less is unprofessional language.* <p class='small-font'>ä¾¿æœå°åŸ·è¡Œé•·ä¸ç›¸ç¨±ï¼›æ›´ä¸ç”¨èªªä¸å°ˆæ¥­çš„è¨€èªäº†ã€‚</p>", unsafe_allow_html=True)
    with cl2:
        st.markdown("**Ex 2:** *Wealth is not becoming to a man without virtue; still less is power.* <p class='small-font'>è²¡å¯Œå°æ–¼ç„¡å¾·ä¹‹äººä¸ç›¸ç¨±ï¼›æ›´ä¸ç”¨èªªæ¬ŠåŠ›äº†ã€‚</p>", unsafe_allow_html=True)

# ===================================================================
# TAB2 â”€ æœˆæ›†å¾…è¾¦ï¼ˆæ•´ç†ç‰ˆï¼šç§»é™¤ âœï¸ã€æ¢å¾©æœˆæ›†æŠ˜ç–Šæ¬„ï¼‰
# ===================================================================
with tabs[1]:
    import datetime as dt, re, os, json

    # ---------- 0. è³‡æ–™æŒä¹…åŒ– ----------
    TODO_FILE = "todos.json"

    def load_todos():
        if os.path.exists(TODO_FILE):
            try:
                with open(TODO_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except:
                pass
        return {}

    def save_todos():
        with open(TODO_FILE, "w", encoding="utf-8") as f:
            json.dump(st.session_state.todo, f, ensure_ascii=False, indent=2)

    # ---------- 1. åˆå§‹åŒ– ----------
    if "todo" not in st.session_state:
        st.session_state.todo = load_todos()
    if "sel_date" not in st.session_state:
        st.session_state.sel_date = str(dt.date.today())
    if "cal_key" not in st.session_state:
        st.session_state.cal_key = 0
    if "active_id" not in st.session_state:
        st.session_state.active_id = None

    # ---------- 2. Emoji å·¥å…· ----------
    _EMOJI_RE = re.compile(
        r"[\U0001F300-\U0001FAFF\U00002700-\U000027BF]+",
        flags=re.UNICODE,
    )

    def first_emoji(text):
        m = _EMOJI_RE.search(text)
        return m.group(0) if m else ""

    # ---------- 3. CSSï¼ˆéš±è—æ™‚é–“ã€ç§»é™¤åœ“é»ï¼‰ ----------
    st.markdown(
        """
        <style>
        .fc-event-time { display: none !important; }
        .fc-daygrid-event-dot { display: none !important; }
        .fc-event { border: none !important; }
        </style>
        """,
        unsafe_allow_html=True,
    )

    # ---------- 4. æœˆæ›†äº‹ä»¶ ----------
    def build_events():
        events = []
        for d, items in st.session_state.todo.items():
            for t in items:
                events.append(
                    {
                        "title": f"{t.get('emoji','')} {t['title']}",
                        "start": f"{d}T{t.get('time','00:00')}",
                    }
                )
        return events

    # ---------- 5. ğŸ“… æœˆæ›†ï¼ˆæŠ˜ç–Šæ¬„ï¼‰ ----------
    with st.expander("ğŸ“… è–ç¶“å­¸ç¿’ç”Ÿæ´»æœˆæ›†", expanded=True):
        cal_options = {
            "headerToolbar": {
                "left": "prev,next",
                "center": "title",
                "right": "",
            },
            "initialView": "dayGridWeek",
            "dayGridWeek": {"dayCount": 14},
            "displayEventTime": False,
            "height": 420,
        }

        state = calendar(
            events=build_events(),
            options=cal_options,
            key=f"cal_{st.session_state.cal_key}",
        )

        if state.get("dateClick"):
            st.session_state.sel_date = state["dateClick"]["date"][:10]
            st.rerun()

    # ---------- 6. ä¸‰æ—¥æ¸…å–®ï¼ˆğŸ’Ÿ â†’ åªå‰© ğŸ—‘ï¸ï¼‰ ----------
    st.divider()
    base_date = dt.datetime.strptime(
        st.session_state.sel_date, "%Y-%m-%d"
    ).date()

    st.markdown(f"##### ğŸ“‹ {st.session_state.sel_date} èµ·ä¸‰æ—¥é è¦½")

    for offset in range(3):
        d = base_date + dt.timedelta(days=offset)
        d_str = str(d)

        for idx, item in enumerate(st.session_state.todo.get(d_str, [])):
            item_id = f"{d_str}_{idx}"

            col_h, col_t, col_a = st.columns([1, 8, 2])

            with col_h:
                if st.button("ğŸ’Ÿ", key=f"h_{item_id}"):
                    st.session_state.active_id = (
                        None
                        if st.session_state.active_id == item_id
                        else item_id
                    )
                    st.rerun()

            with col_t:
                st.write(
                    f"**{item['time'][:5]}** {item.get('emoji','')} {item['title']}"
                )

            if st.session_state.active_id == item_id:
                with col_a:
                    if st.button("ğŸ—‘ï¸", key=f"d_{item_id}"):
                        st.session_state.todo[d_str].pop(idx)
                        save_todos()
                        st.session_state.cal_key += 1
                        st.session_state.active_id = None
                        st.rerun()

    # ---------- 7. æ–°å¢äº‹é … ----------
    with st.expander("â• æ–°å¢äº‹é …", expanded=True):
        with st.form("new_todo", clear_on_submit=True):
            col_d, col_t = st.columns(2)
            with col_d:
                in_date = st.date_input("æ—¥æœŸ", base_date)
            with col_t:
                in_time = st.time_input("æ™‚é–“", dt.time(9, 0))

            title = st.text_input("å¾…è¾¦äº‹é …ï¼ˆå¯å« Emojiï¼‰")

            if st.form_submit_button("ğŸ’¾ å„²å­˜"):
                if title:
                    k = str(in_date)
                    st.session_state.todo.setdefault(k, []).append(
                        {
                            "title": title,
                            "time": str(in_time),
                            "emoji": first_emoji(title) or "ğŸ“Œ",
                        }
                    )
                    save_todos()
                    st.session_state.cal_key += 1
                    st.rerun()

# ===================================================================
# 5. TAB3 â”€ æŒ‘æˆ°ï¼ˆå–®ç´”ç¿»è­¯é¡Œï¼Œç„¡æœˆæ›†ï¼‰
# ===================================================================
with tabs[2]:
    col_challenge, col_deco = st.columns([0.7, 0.3])
    with col_challenge:
        st.subheader("ğŸ“ ç¿»è­¯æŒ‘æˆ°")
        st.write("é¡Œç›® 1: æ„šé ‘äººèªªç¾è¨€æœ¬ä¸ç›¸ç¨±...")
        st.text_input("è«‹è¼¸å…¥è‹±æ–‡ç¿»è­¯", key="ans_1_final", placeholder="Type your translation here...")
    with col_deco:
        st.image(IMG_URLS.get("B"), width=150, caption="Keep Going!")

# ===================================================================
# 6. TAB4 â”€ AI æ§åˆ¶å°ï¼ˆé›¶å¾ªç’° + æ°¸ä¹…å­˜æª” + è¼¸å…¥ç”Ÿæ•ˆï¼‰
# ===================================================================
with tabs[3]:
    import os, subprocess, sys, pandas as pd, io, json

    # ---------- 0. è³‡æ–™åº«æŒä¹…åŒ–å·¥å…· ----------
    SENTENCES_FILE = "sentences.json"
    
    def load_sentences():
        """è¼‰å…¥è³‡æ–™åº«"""
        if os.path.exists(SENTENCES_FILE):
            try:
                with open(SENTENCES_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except:
                pass
        return {}
    
    def save_sentences():
        """å­˜æª”è³‡æ–™åº«"""
        with open(SENTENCES_FILE, "w", encoding="utf-8") as f:
            json.dump(st.session_state.sentences, f, ensure_ascii=False, indent=2)

    # ---------- 1. åˆå€¼èˆ‡è‡ªå‹•è®€æª” ----------
    if 'sentences' not in st.session_state:
        st.session_state.sentences = load_sentences()

    API_KEY = os.getenv("GEMINI_API_KEY") or os.getenv("KIMI_API_KEY")
    if not API_KEY:
        st.warning("âš ï¸ å°šæœªè¨­å®š GEMINI_API_KEY æˆ– KIMI_API_KEYï¼Œè«‹è‡³ Streamlit-Secrets åŠ å…¥é‡‘é‘°å¾Œé‡æ–°å•Ÿå‹•ã€‚")
        st.stop()

    with st.expander("ğŸ“šâ‘  è²¼ç¶“æ–‡/è¬›ç¨¿ â†’ â‘¡ ä¸€éµåˆ†æ â†’ â‘¢ ç›´æ¥æª¢è¦– â†’ â‘£ é›¢ç·šä½¿ç”¨", expanded=True):
        input_text = st.text_area("", height=300, key="input_text")

        # -------------- å¸ƒå±€ï¼šæ“ä½œ + è¼¸å…¥æ¡† + AI åˆ†æéµï¼ˆç¨ç«‹ï¼‰ + å·¨é‡åˆªé™¤é å³ --------------
        col1, col2, col3, col4 = st.columns([2.5, 3.5, 2, 2])
        
        with col1:
            search_type = st.selectbox("æ“ä½œ", ["AI åˆ†æ", "Ref. åˆªé™¤", "é—œéµå­—åˆªé™¤"])
        
        with col2:
            query_box = None
            if search_type == "Ref. åˆªé™¤":
                query_box = st.text_input("è¼¸å…¥ Ref.ï¼ˆä¾‹ï¼š2Ti 3:10ï¼‰", key="ref_del")
            elif search_type == "é—œéµå­—åˆªé™¤":
                query_box = st.text_input("è¼¸å…¥é—œéµå­—", key="kw_del")
            else:
                st.empty()  # ä¿æŒé«˜åº¦ä¸€è‡´
        
        with col3:
            # AI åˆ†æéµï¼šç¨ç«‹é‹ä½œ
            if st.button("ğŸ¤– AI åˆ†æ", type="primary", key="ai_analyze_btn"):
                if not input_text:
                    st.error("è«‹å…ˆè²¼ç¶“æ–‡")
                    st.stop()
                if search_type != "AI åˆ†æ":
                    st.warning("è«‹å…ˆé¸æ“‡ã€ŒAI åˆ†æã€æ“ä½œ")
                    st.stop()
                with st.spinner("AI åˆ†æä¸­ï¼Œç´„ 10 ç§’â€¦"):
                    try:
                        subprocess.run([sys.executable, "analyze_to_excel.py", "--file", "temp_input.txt"],
                                       check=True, timeout=30)
                        with open("temp_result.json", "r", encoding="utf-8") as f:
                            data = json.load(f)
                        save_analysis_result(data, input_text)
                        st.session_state["analysis"] = data
                        
                        # è‡ªå‹•å­˜å…¥è³‡æ–™åº«ï¼ˆsentencesï¼‰
                        ref_no = data.get("ref_no", "")
                        st.session_state.sentences[ref_no] = {
                            "ref": ref_no,
                            "en": data.get("ref_article", ""),
                            "zh": "",
                            "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M")
                        }
                        save_sentences()  # å­˜æª”
                        
                        st.success("åˆ†æå®Œæˆï¼å·²å­˜å…¥è³‡æ–™åº«")
                        current_count = len(st.session_state.get("analysis_history", []))
                        if current_count >= 800:
                            st.warning("ğŸ”” åˆ†æç´€éŒ„å·²é” 800 ç­†ï¼Œå»ºè­°ä½¿ç”¨ã€Œå£“ç¸®èˆŠç´€éŒ„ã€åŠŸèƒ½ï¼Œé¿å…ç€è¦½å™¨å¡é “ï¼")
                        if st.checkbox("åˆ†æå®Œè‡ªå‹•å±•é–‹", value=True):
                            st.session_state["show_result"] = True
                    except Exception as e:
                        st.error(f"åˆ†æéç¨‹éŒ¯èª¤ï¼š{e}")
        
        with col4:
            st.write("")  # å°é½Šç•™ç™½
            # å·¨é‡åˆªé™¤éµï¼šé å³å°é½Š
            if search_type in ["Ref. åˆªé™¤", "é—œéµå­—åˆªé™¤"]:
                if st.button("ğŸ—‘ï¸ å·¨é‡åˆªé™¤", type="primary", key="bulk_delete_btn"):
                    if query_box is None or not query_box.strip():
                        st.error("è«‹å…ˆè¼¸å…¥åˆªé™¤æ¢ä»¶")
                        st.stop()
                    hits = []
                    for d, v in st.session_state.sentences.items():
                        txt = f"{v.get('ref', '')} {v.get('en', '')} {v.get('zh', '')}".lower()
                        if search_type == "Ref. åˆªé™¤" and query_box.lower() in v.get('ref', '').lower():
                            hits.append((d, v))
                        elif search_type == "é—œéµå­—åˆªé™¤" and query_box.lower() in txt:
                            hits.append((d, v))
                    if hits:
                        st.write(f"å…± {len(hits)} ç­†ï¼ˆå«è–ç¶“ç¶“ç¯€ï¼‰")
                        selected_keys = st.multiselect("å‹¾é¸è¦åˆªé™¤çš„é …ç›®", [d for d, _ in hits])
                        if st.button("ç¢ºèªåˆªé™¤", type="secondary"):
                            for k in selected_keys:
                                st.session_state.sentences.pop(k, None)
                            save_sentences()  # åˆªé™¤å¾Œå­˜æª”
                            st.success(f"å·²åˆªé™¤ {len(selected_keys)} ç­†ï¼")
                    else:
                        st.info("ç„¡ç¬¦åˆæ¢ä»¶")

    # ---------- 2. çµæœå‘ˆç¾ ----------
    if st.session_state.get("show_result", False):
        data = st.session_state["analysis"]
        st.session_state["ref_no"] = data.get("ref_no", "")
        st.session_state["ref_article"] = data.get("ref_article", "")
        st.markdown(f"**Ref. No.** `{st.session_state['ref_no']}`")
        c_jump, c_copy = st.columns(2)
        with c_jump:
            if st.button("ğŸ“„ æª¢è¦–åŸæ–‡"):
                st.session_state["show_article"] = True
        with c_copy:
            ref_no = st.session_state.get("ref_no", "")
            if ref_no:
                st.code(ref_no)
            else:
                st.text("å°šç„¡ Ref.")

        if st.session_state.get("show_article", False):
            with st.expander("ğŸ“˜ ä¸­è‹±ç²¾ç…‰æ–‡ç« ", expanded=True):
                st.markdown(st.session_state["ref_article"])

        col_w, col_p, col_g = st.tabs(["å–®å­—", "ç‰‡èª", "æ–‡æ³•"])
        with col_w:
            if data.get("words"):
                df = pd.DataFrame(data["words"])
                df.insert(0, "Ref.", data.get("ref_no", ""))
                df["ğŸ”"] = "ğŸ”"
                st.dataframe(df, use_container_width=True)
            else:
                st.info("æœ¬æ¬¡ç„¡å–®å­—åˆ†æ")
        with col_p:
            if data.get("phrases"):
                df = pd.DataFrame(data["phrases"])
                df.insert(0, "Ref.", data.get("ref_no", ""))
                df["ğŸ”"] = "ğŸ”"
                st.dataframe(df, use_container_width=True)
            else:
                st.info("æœ¬æ¬¡ç„¡ç‰‡èªåˆ†æ")
        with col_g:
            if data.get("grammar"):
                df = pd.DataFrame(data["grammar"])
                df.insert(0, "Ref.", data.get("ref_no", ""))
                df["ğŸ”"] = "ğŸ”"
                st.table(df)
            else:
                st.info("æœ¬æ¬¡ç„¡æ–‡æ³•é»")

    # ---------- 3. å®¹é‡ç®¡ç† ----------
    with st.expander("âš™ï¸ å®¹é‡ç®¡ç†", expanded=True):
        max_keep = st.number_input("æœ€å¤šä¿ç•™æœ€è¿‘å¹¾ç­†åˆ†æç´€éŒ„", min_value=10, max_value=1000, value=50)
        if st.button("âœ‚ï¸ å£“ç¸®èˆŠç´€éŒ„"):
            hist = st.session_state.get("analysis_history", [])
            if len(hist) > max_keep:
                st.session_state.analysis_history = hist[-max_keep:]
                st.success(f"å·²å£“ç¸®è‡³æœ€è¿‘ {max_keep} ç­†ï¼")
            else:
                st.info("æœªé”å£“ç¸®é–€æª»")

    # ---------- 4. åŒ¯å‡º ----------
    if st.button("ğŸ“‹ åŒ¯å‡ºå«å›æº¯æ¬„ä½"):
        export = []
        for k, v in st.session_state.sentences.items():
            export.append(f"{k}\t{v.get('ref', '')}\t{v.get('en', '')}\t{v.get('zh', '')}")
        st.code("\n".join(export), language="text")
