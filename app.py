import streamlit as st
import pandas as pd
import requests
import re
import os
import base64
import random

# --- 1. é é¢é…ç½® (2026 æœ€æ–°æ¨™æº–) ---
st.set_page_config(page_title="Memory Logic 2026", layout="wide", page_icon="ğŸ¶")

# --- 2. åˆå§‹åŒ– Session State (ç¢ºä¿åŠŸèƒ½ä¸æ¶ˆå¤±çš„æ ¸å¿ƒ) ---
if 'final_df' not in st.session_state:
    st.session_state.final_df = pd.DataFrame(columns=["Reference", "English", "Chinese", "Key word", "Grammar", "Japanese", "Korean", "Thai"])

# åˆå§‹åŒ– 5 é¡ŒæŒ‘æˆ°é¡Œç›® (260103 æ–°å¢éœ€æ±‚)
if 'quiz_data' not in st.session_state:
    st.session_state.quiz_data = [
        {"q": "å‡¡äº‹éƒ½æœ‰å®šæœŸï¼Œå¤©ä¸‹è¬å‹™éƒ½æœ‰å®šæ™‚ã€‚", "a": "To everything there is a season, and a time to every purpose under the heaven.", "lang": "English (WEB)"},
        {"q": "ç¥æ„›ä¸–äººï¼Œç”šè‡³å°‡ä»–çš„ç¨ç”Ÿå­è³œçµ¦ä»–å€‘ã€‚", "a": "For God so loved the world, that he gave his only begotten Son.", "lang": "English (WEB)"},
        {"q": "èµ·åˆï¼Œç¥å‰µé€ å¤©åœ°ã€‚", "a": "ã¯ã˜ã‚ã«ã€ç¥ã¯å¤©ã¨åœ°ã‚’å‰µé€ ã•ã‚ŒãŸã€‚", "lang": "Japanese (JPN)"},
        {"q": "è€¶å’Œè¯æ˜¯æˆ‘çš„ç‰§è€…ï¼Œæˆ‘å¿…ä¸è‡³ç¼ºä¹ã€‚", "a": "ì—¬í˜¸ì™€ëŠ” ë‚˜ì˜ ëª©ìì‹œë‹ˆ ë‚´ê²Œ ë¶€ì¡±í•¨ì´ ì—†ìœ¼ë¦¬ë¡œë‹¤.", "lang": "Korean (KOR)"},
        {"q": "ä½ è¦å°ˆå¿ƒä»°è³´è€¶å’Œè¯ã€‚", "a": "à¸ˆà¸‡à¸§à¸²à¸‡à¹ƒà¸ˆà¹ƒà¸™à¸à¸£à¸°à¸¢à¸²à¸«à¹Œà¹€à¸§à¸«à¹Œà¸”à¹‰à¸§à¸¢à¸ªà¸¸à¸”à¹ƒà¸ˆà¸‚à¸­à¸‡à¹€à¸ˆà¹‰à¸²", "lang": "Thai (THA)"}
    ]

# --- 3. æ ¸å¿ƒå·¥å…·é¡åˆ¥ ---
class BibleAutomator:
    def __init__(self):
        self.api_base = "bible-api.com"
        self.lang_map = {"CN": "cuv", "EN": "web", "JA": "jpn", "KO": "kor", "TH": "tha"}

    @st.cache_data(ttl=3600)
    def fetch_data(_self, ref, lang_key):
        trans = _self.lang_map.get(lang_key, "web")
        try:
            clean_ref = ref.replace(" ", "+")
            r = requests.get(f"{_self.api_base}{clean_ref}?translation={trans}", timeout=10)
            if r.status_code == 200:
                data = r.json()
                return {v['verse']: v['text'].strip() for v in data.get('verses', [])} if 'verses' in data else {data.get('verse', 0): data.get('text', '').strip()}
        except: pass
        return {}

    def extract_keywords(self, text):
        if not text: return ""
        words = re.findall(r'\b[A-Za-z]{6,}\b', text)
        return ", ".join(list(dict.fromkeys(words))[:2])

    def process_range(self, ref_input, manual_grammar_map=None):
        en_map = self.fetch_data(ref_input, "EN")
        cn_map = self.fetch_data(ref_input, "CN")
        ja_map = self.fetch_data(ref_input, "JA")
        ko_map = self.fetch_data(ref_input, "KO")
        th_map = self.fetch_data(ref_input, "TH")
        book_part = re.sub(r':\d+.*$', '', ref_input)
        rows = []
        for v_num in sorted(en_map.keys()):
            rows.append({
                "Reference": f"{book_part}:{v_num}", "English": en_map.get(v_num, ""),
                "Chinese": cn_map.get(v_num, ""), "Key word": self.extract_keywords(en_map.get(v_num, "")),
                "Grammar": manual_grammar_map.get(v_num, "AI å¾…åˆ†æ") if manual_grammar_map else "AI å¾…åˆ†æ",
                "Japanese": ja_map.get(v_num, "-"), "Korean": ko_map.get(v_num, "-"), "Thai": th_map.get(v_num, "-")
            })
        return pd.DataFrame(rows)

auto_tool = BibleAutomator()

# --- 4. è³‡æºå®šç¾© (è§£æ±ºåœ–ç‰‡ä¸è¦‹çš„å•é¡Œ) ---
@st.cache_data
def get_img_64(file):
    # å¦‚æœæœ¬åœ°æœ‰åœ–è®€æœ¬åœ°ï¼Œæ²’åœ–é¡¯ç¤º Placeholder ç¢ºä¿ UI ä¸è·‘ç‰ˆ
    if os.path.exists(file):
        with open(file, "rb") as f:
            return f"data:image/jpeg;base64,{base64.b64encode(f.read()).decode()}"
    return "via.placeholder.com"

st.markdown("""
    <style>
    .stApp { background-color: #FFFDF5; }
    .feature-box { background: white; border-radius: 12px; padding: 18px; border: 1px solid #E0E0E0; margin-bottom: 15px; }
    .grammar-box { min-height: 310px; background-color: #F8FBFF !important; border-left: 5px solid #64B5F6 !important; }
    .snoopy-container img { width: 100%; border-radius: 10px; margin-bottom: 10px; border: 1px solid #DDD; }
    </style>
""", unsafe_allow_html=True)

# --- 5. UI å‘ˆç¾ ---
tab_home, tab_play, tab_tool = st.tabs(["ğŸ  æˆ‘çš„æ›¸æ¡Œ", "ğŸ¯ ç¿»è­¯æŒ‘æˆ°", "ğŸ§ª è‡ªå‹•å·¥å…·"])

with tab_home:
    col_l, col_r = st.columns([2.5, 1])
    with col_l:
        st.markdown('<div class="feature-box"><h3>ğŸ’¡ ä»Šæ—¥é‡‘å¥</h3>å‚³é“æ›¸ 3:1<br>å‡¡äº‹éƒ½æœ‰å®šæœŸï¼Œå¤©ä¸‹è¬å‹™éƒ½æœ‰å®šæ™‚ã€‚</div>', unsafe_allow_html=True)
        st.markdown('<div class="feature-box grammar-box">ğŸ“ <b>æ–‡æ³•é‡é»èªªæ˜</b><br>æ­¤æ¡†é«˜åº¦èˆ‡å³å´å²åŠªæ¯”åœ–æ¡ˆé½Šå¹³ã€‚</div>', unsafe_allow_html=True)
    with col_r:
        # ç¢ºä¿å…©å¼µå²åŠªæ¯”åœ–é¡¯ç¤º
        for img_name in ["f364bd220887627.67cae1bd07457.jpg", "183ebb183330643.Y3JvcCw4MDgsNjMyLDAsMA.jpg"]:
            img_data = get_img_64(img_name)
            st.markdown(f'<div class="snoopy-container"><img src="{img_data}"></div>', unsafe_allow_html=True)

with tab_play:
    st.subheader("ğŸ¯ å¤šåœ‹èªè¨€ç¿»è­¯æŒ‘æˆ° (5 é¡Œç‰ˆ)")
    for i, item in enumerate(st.session_state.quiz_data):
        with st.expander(f"ç¬¬ {i+1} é¡Œï¼š{item['q'][:10]}...", expanded=(i==0)):
            st.write(f"**é¡Œç›®ï¼š** {item['q']}")
            st.write(f"**ç›®æ¨™èªè¨€ï¼š** {item['lang']}")
            ans = st.text_input(f"åœ¨æ­¤è¼¸å…¥ç¿»è­¯...", key=f"ans_{i}")
            if st.button(f"æª¢æŸ¥ç¬¬ {i+1} é¡Œç­”æ¡ˆ"):
                if ans:
                    st.info(f"ğŸ’¡ åƒè€ƒç­”æ¡ˆï¼š{item['a']}")
                    st.balloons()
                else:
                    st.warning("è«‹å…ˆè¼¸å…¥ç­”æ¡ˆå–”ï¼")

with tab_tool:
    st.subheader("ğŸ§ª è–ç¶“è‡ªå‹•å·¥å…·")
    ref_in = st.text_input("è¼¸å…¥ç¯„åœ", "Psalm 20:1-3")
    if st.button("ğŸ” é–‹å§‹ç”Ÿæˆ"):
        st.session_state.final_df = auto_tool.process_range(ref_in)
    st.dataframe(st.session_state.final_df, width="stretch")
