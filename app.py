# ===================================================================
# 0. å¥—ä»¶ & å…¨åŸŸå‡½å¼ï¼ˆä¸€å®šæ”¾æœ€é ‚ï¼‰
# ===================================================================
import streamlit as st
import subprocess, sys, os, datetime as dt, pandas as pd, io, json, re, tomli, tomli_w
from streamlit_calendar import calendar

# ========== é™¤éŒ¯æ¸¬è©¦ ==========
st.sidebar.markdown("## ğŸ”§ é™¤éŒ¯è³‡è¨Š")

api_key = os.getenv("GEMINI_API_KEY")

if api_key:
    st.sidebar.success("âœ… GEMINI_API_KEY å·²è¨­å®š")
    st.sidebar.write(f"é•·åº¦: {len(api_key)} å­—å…ƒ")
else:
    st.sidebar.error("âŒ GEMINI_API_KEY æœªè¨­å®š")
    st.sidebar.info("è«‹åˆ° Settings â†’ Secrets è¨­å®š")
    
# ---------- å…¨åŸŸå·¥å…·å‡½å¼ ----------
def save_analysis_result(result, input_text):
    if "analysis_history" not in st.session_state:
        st.session_state.analysis_history = []
    st.session_state.analysis_history.append({
        "date": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
        "input_preview": input_text[:50] + "..." if len(input_text) > 50 else input_text,
        "result": result
    })
    if len(st.session_state.analysis_history) > 10:
        st.session_state.analysis_history.pop(0)

def to_excel(result: dict) -> bytes:
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        for sheet, key in [("Words", "words"), ("Phrases", "phrases"), ("Grammar", "grammar")]:
            if key in result and result[key]:
                pd.DataFrame(result[key]).to_excel(writer, sheet_name=sheet, index=False)
        stats = pd.DataFrame({
            "é …ç›®": ["ç¸½å­—å½™æ•¸", "ç¸½ç‰‡èªæ•¸", "æ–‡æ³•é»æ•¸", "åˆ†ææ—¥æœŸ"],
            "æ•¸å€¼": [
                len(result.get("words", [])),
                len(result.get("phrases", [])),
                len(result.get("grammar", [])),
                dt.date.today().strftime("%Y-%m-%d")
            ]
        })
        stats.to_excel(writer, sheet_name="çµ±è¨ˆ", index=False)
    buffer.seek(0)
    return buffer.getvalue()

# ===================================================================
# 1. å´é‚Šæ¬„ï¼ˆä¸€æ¬¡ 4 é€£çµï¼Œç„¡é‡è¤‡ï¼‰
# ===================================================================
with st.sidebar:
    st.divider()
    c1, c2 = st.columns(2)
    c1.link_button("âœ¨ Google AI", "https://gemini.google.com/ ")
    c2.link_button("ğŸ¤– Kimi K2",   "https://kimi.moonshot.cn/ ")
    c3, c4 = st.columns(2)
    c3.link_button("ESV Bible", "https://wd.bible/bible/gen.1.cunps?parallel=esv.klb.jcb ")
    c4.link_button("THSV11",    "https://www.bible.com/zh-TW/bible/174/GEN.1.THSV11 ")

# ===================================================================
# 2. é é¢é…ç½® & Session åˆå€¼ï¼ˆåªç•™å…¨åŸŸæœƒç”¨åˆ°çš„ï¼‰
# ===================================================================
st.set_page_config(layout="wide", page_title="Bible Study AI App 2026")

# é€™äº›è®Šæ•¸åªæœ‰ TAB2 æœƒç”¨åˆ°ï¼Œä½†ç‚ºäº†é¿å…å¾ŒçºŒ TAB å¼•ç”¨å‡ºéŒ¯ï¼Œå…ˆçµ¦ç©ºå€¼
if 'analysis_history' not in st.session_state: st.session_state.analysis_history = []

# ---------- CSS ----------
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Gamja+Flower&display=swap ');
.cute-korean { font-family: 'Gamja Flower', cursive; font-size: 20px; color: #FF8C00; text-align: center; }
.small-font { font-size: 13px; color: #555555; margin-top: 5px !important; }
.grammar-box-container {
    background-color: #f8f9fa; border-radius: 8px; padding: 12px;
    border-left: 5px solid #FF8C00; text-align: left; margin-top: 0px;
}
.fc-daygrid-day-frame:hover {background-color: #FFF3CD !important; cursor: pointer; transform: scale(1.03); transition: .2s}
.fc-daygrid-day-frame:active {transform: scale(0.98); background-color: #FFE69C !important}
</style>
""", unsafe_allow_html=True)

# ---------- åœ–ç‰‡ & ç¾æˆ TAB ----------
IMG_URLS = {
    "A": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/183ebb183330643.Y3JvcCw4MDgsNjMyLDAsMA.jpg ",
    "B": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/f364bd220887627.67cae1bd07457.jpg ",
    "C": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/68254faebaafed9dafb41918f74c202e.jpg ",
    "M1": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro1.jpg ",
    "M2": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro2.jpg ",
    "M3": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro3.jpg ",
    "M4": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro4.jpg "
}
with st.sidebar:
    st.markdown('<p class="cute-korean">ë‹¹ì‹ ì€ í•˜ë‚˜ë‹˜ì˜ ì†Œì¤‘í•œ ë³´ë¬¼ì…ë‹ˆë‹¤</p>', unsafe_allow_html=True)
    st.image(IMG_URLS["M3"], width=250)
    st.divider()

tabs = st.tabs(["ğŸ  æ›¸æ¡Œ", "ğŸ““ ç­†è¨˜", "âœï¸ æŒ‘æˆ°", "ğŸ“‚ è³‡æ–™åº«"])

# ===================================================================
# 3. TAB1 â”€ æ›¸æ¡Œï¼ˆå–®ç´”ç¶“æ–‡èˆ‡ä¾‹å¥ï¼Œç„¡æœˆæ›†ï¼‰
# ===================================================================
with tabs[0]:
    col_content, col_m1 = st.columns([0.65, 0.35])
    with col_content:
        st.info("**Becoming** / ğŸ‡¯ğŸ‡µ ãµã•ã‚ã—ã„ | ğŸ‡°ğŸ‡· ì–´ìš¸ë¦¬ëŠ” | ğŸ‡¹ğŸ‡­ à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ | ğŸ‡¨ğŸ‡³ ç›¸ç¨±")
        st.success("""
            ğŸŒŸ **Pro 17:07** Fine speech is not becoming to a fool; still less is false speech to a prince.   
            ğŸ‡¯ğŸ‡µ ã™ãã‚ŒãŸè¨€è‘‰ã¯æ„šã‹è€…ã«ã¯ãµã•ã‚ã—ããªã„ã€‚å½ã‚Šã®è¨€è‘‰ã¯å›ä¸»ã«ã¯ãªãŠã•ã‚‰ãµã•ã‚ã—ããªã„ã€‚   
            ğŸ‡¨ğŸ‡³ æ„šé ‘äººèªªç¾è¨€æœ¬ä¸ç›¸ç¨±ï¼Œä½•æ³å›ç‹èªªè¬Šè©±å‘¢ï¼Ÿ
            """, icon="ğŸ“–")
    with col_m1:
        st.markdown(f"""
            <div style="display:flex;flex-direction:column;justify-content:space-between;height:100%;min-height:250px;text-align:center;">
                <div style="flex-grow:1;display:flex;align-items:center;justify-content:center;">
                    <img src="{IMG_URLS['M1']}" style="width:200px;margin-bottom:10px;">
                </div>
                <div class="grammar-box-container" style="margin-top:auto;">
                    <p style="margin:2px 0;font-size:14px;font-weight:bold;color:#333;">æ™‚æ…‹: ç¾åœ¨ç°¡å–®å¼</p>
                    <p style="margin:2px 0;font-size:14px;font-weight:bold;color:#333;">æ ¸å¿ƒç‰‡èª:</p>
                    <ul style="margin:0;padding-left:18px;font-size:13px;line-height:1.4;color:#555;">
                        <li>Fine speech (å„ªç¾è¨€è¾­)</li>
                        <li>Becoming to (ç›¸ç¨±)</li>
                        <li>Still less (ä½•æ³)</li>
                        <li>False speech (è™›å‡è¨€è¾­)</li>
                    </ul>
                </div>
            </div>
        """, unsafe_allow_html=True)
    st.divider()
    st.markdown("### âœï¸ æ–‡æ³•é‹ç”¨ä¾‹å¥")
    cl1, cl2 = st.columns(2)
    with cl1:
        st.markdown("**Ex 1:** *Casual attire is not becoming to a CEO; still less is unprofessional language.* <p class='small-font'>ä¾¿æœå°åŸ·è¡Œé•·ä¸ç›¸ç¨±ï¼›æ›´ä¸ç”¨èªªä¸å°ˆæ¥­çš„è¨€èªäº†ã€‚</p>", unsafe_allow_html=True)
    with cl2:
        st.markdown("**Ex 2:** *Wealth is not becoming to a man without virtue; still less is power.* <p class='small-font'>è²¡å¯Œå°æ–¼ç„¡å¾·ä¹‹äººä¸ç›¸ç¨±ï¼›æ›´ä¸ç”¨èªªæ¬ŠåŠ›äº†ã€‚</p>", unsafe_allow_html=True)

# ===================================================================
# 4. TAB2 â”€ æœˆæ›†å¾…è¾¦ï¼ˆç©©å®šæœ€çµ‚ç‰ˆï¼‰
# ===================================================================
with tabs[1]:
    import datetime as dt, re, os, json
    from streamlit_calendar import calendar

    # ---------- èƒŒæ™¯åœ–ï¼ˆåƒ… TAB2ï¼Œæ·¡åŒ–ï¼‰ ----------
    st.markdown("""
    <style>
    section[data-testid="stSidebar"] + div [data-testid="stVerticalBlock"] {
        background-image: url("assets/68254faebaafed9dafb41918f74c202e.jpg");
        background-size: cover;
        background-position: center;
        background-repeat: no-repeat;
    }
    section[data-testid="stSidebar"] + div [data-testid="stVerticalBlock"]::before {
        content: "";
        position: fixed;
        inset: 0;
        background: rgba(255,255,255,0.82);
        z-index: -1;
    }
    </style>
    """, unsafe_allow_html=True)

    # ---------- 0. æª”æ¡ˆæŒä¹…åŒ– ----------
    TODO_FILE = "todos.json"

    def load_todos():
        if os.path.exists(TODO_FILE):
            try:
                with open(TODO_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except:
                pass
        return {}

    def save_todos():
        with open(TODO_FILE, "w", encoding="utf-8") as f:
            json.dump(st.session_state.todo, f, ensure_ascii=False, indent=2)

    # ---------- 1. åˆå§‹åŒ– ----------
    if "todo" not in st.session_state:
        st.session_state.todo = load_todos()
    if "sel_date" not in st.session_state:
        st.session_state.sel_date = str(dt.date.today())
    if "cal_key" not in st.session_state:
        st.session_state.cal_key = 0
    if "active_del_id" not in st.session_state:
        st.session_state.active_del_id = None

    # ---------- 2. Emoji å·¥å…· ----------
    _EMOJI_RE = re.compile(
        r'[\U0001F300-\U0001FAFF\U00002700-\U000027BF]+', flags=re.UNICODE
    )
    def first_emoji(text: str) -> str:
        m = _EMOJI_RE.search(text)
        return m.group(0) if m else ""

    # ---------- 3. æœˆæ›†äº‹ä»¶ï¼ˆæ ¼å­åªé¡¯ç¤ºæ–‡å­— + Emojiï¼‰ ----------
    def build_events():
        ev = []
        for d, items in st.session_state.todo.items():
            if not isinstance(items, list):
                continue
            for t in items:
                ev.append({
                    "title": f"{t.get('emoji','')}{t['title']}",
                    "start": f"{d}T{t.get('time','00:00:00')}",
                    "backgroundColor": "#FFE4E1",
                    "borderColor": "#FFE4E1",
                    "textColor": "#333"
                })
        return ev

    # ---------- 4. æœˆæ›†ï¼ˆæŠ˜ç–Šæ¬„ï¼‰ ----------
    with st.expander("ğŸ“… è–ç¶“å­¸ç¿’ç”Ÿæ´»æœˆæ›†", expanded=True):
        cal_options = {
            "headerToolbar": {
                "left": "prev,next today",
                "center": "title",
                "right": ""
            },
            "initialView": "dayGridMonth",
            "displayEventTime": False,
            "height": "auto"
        }

        state = calendar(
            events=build_events(),
            options=cal_options,
            key=f"calendar_{st.session_state.cal_key}"
        )

        if state.get("dateClick"):
            st.session_state.sel_date = state["dateClick"]["date"][:10]
            st.rerun()

    # ---------- 5. ä¸‹æ–¹ä¸‰æ—¥æ¸…å–®ï¼ˆğŸ’Ÿ â†’ ğŸ—‘ï¸ï¼‰ ----------
    st.markdown("##### ğŸ“‹ å¾…è¾¦äº‹é …")

    try:
        base_date = dt.datetime.strptime(
            st.session_state.sel_date, "%Y-%m-%d"
        ).date()
    except:
        base_date = dt.date.today()

    for offset in range(3):
        d_obj = base_date + dt.timedelta(days=offset)
        d_str = str(d_obj)
        if d_str in st.session_state.todo:
            for idx, item in enumerate(st.session_state.todo[d_str]):
                item_id = f"{d_str}_{idx}"

                c1, c2, c3 = st.columns([1, 7, 2], vertical_alignment="top")

                with c1:
                    if st.button("ğŸ’Ÿ", key=f"h_{item_id}"):
                        st.session_state.active_del_id = (
                            None if st.session_state.active_del_id == item_id else item_id
                        )
                        st.rerun()

                with c2:
                    st.write(
                        f"{d_obj.month}/{d_obj.day} "
                        f"{item['time'][:5]} "
                        f"{item.get('emoji','')}{item['title']}"
                    )

                with c3:
                    if st.session_state.active_del_id == item_id:
                        if st.button("ğŸ—‘ï¸", key=f"d_{item_id}"):
                            st.session_state.todo[d_str].pop(idx)
                            save_todos()
                            st.session_state.cal_key += 1
                            st.session_state.active_del_id = None
                            st.rerun()

    # ---------- 6. æ–°å¢å¾…è¾¦ ----------
    st.divider()
    with st.expander("â• æ–°å¢å¾…è¾¦", expanded=True):
        with st.form("todo_form", clear_on_submit=True):
            col1, col2 = st.columns(2)
            with col1:
                in_date = st.date_input("æ—¥æœŸ", base_date)
            with col2:
                in_time = st.time_input("æ™‚é–“", dt.time(9, 0))

            in_title = st.text_input("å¾…è¾¦äº‹é …ï¼ˆå¯å« Emojiï¼‰")

            if st.form_submit_button("ğŸ’¾ å„²å­˜"):
                if in_title:
                    k = str(in_date)
                    if k not in st.session_state.todo:
                        st.session_state.todo[k] = []
                    st.session_state.todo[k].append({
                        "title": in_title,
                        "time": str(in_time),
                        "emoji": first_emoji(in_title)
                    })
                    save_todos()
                    st.session_state.cal_key += 1
                    st.rerun()

# ===================================================================
# 5. TAB3 â”€ æŒ‘æˆ°ï¼ˆå–®ç´”ç¿»è­¯é¡Œï¼Œç„¡æœˆæ›†ï¼‰
# ===================================================================
with tabs[2]:
    col_challenge, col_deco = st.columns([0.7, 0.3])
    with col_challenge:
        st.subheader("ğŸ“ ç¿»è­¯æŒ‘æˆ°")
        st.write("é¡Œç›® 1: æ„šé ‘äººèªªç¾è¨€æœ¬ä¸ç›¸ç¨±...")
        st.text_input("è«‹è¼¸å…¥è‹±æ–‡ç¿»è­¯", key="ans_1_final", placeholder="Type your translation here...")
    with col_deco:
        st.image(IMG_URLS.get("B"), width=150, caption="Keep Going!")

# ===================================================================
# 5. TAB4 â”€ AI æ§åˆ¶å°ï¼ˆå…±ç”¨æ¬„ä½ + ChatGPT API / ä»»æ„ LLM UIï¼‰
# ===================================================================
with tabs[3]:
    import os
    import pandas as pd
    import io
    import json
    import datetime as dt
    import streamlit as st
    import base64  # ä¿ç•™ï¼Œé›–ç„¶ç›®å‰æœªä½¿ç”¨ä½†å¯èƒ½æœªä¾†éœ€è¦

    # ---------- 0. å·¥å…·å‡½å¼ï¼ˆæ”¾åœ¨æœ€ä¸Šæ–¹ï¼‰----------
    
    def copy_and_open_chatgpt(prompt: str):
        """
        å°‡ Prompt è¤‡è£½åˆ°å‰ªè²¼ç°¿ï¼Œä¸¦å˜—è©¦é–‹å•Ÿ ChatGPT UI
        ï¼ˆè‹¥å½ˆçª—è¢«æ””æˆªï¼Œé¡¯ç¤ºæ‰‹å‹•é€£çµå‚™æ¡ˆï¼‰
        """
        import json
        js_code = f"""
        <script>
        (async function() {{
            try {{
                // è¤‡è£½åˆ°å‰ªè²¼ç°¿ï¼ˆä¸»è¦åŠŸèƒ½ï¼Œé€šå¸¸æˆåŠŸï¼‰
                await navigator.clipboard.writeText({json.dumps(prompt)});
                console.log('Prompt copied to clipboard');
                
                // å˜—è©¦é–‹å•Ÿæ–°åˆ†é ï¼ˆå¾ˆå¯èƒ½è¢«æ””æˆªï¼‰
                const newWindow = window.open("https://chat.openai.com/", "_blank");
                
                // æª¢æŸ¥æ˜¯å¦è¢«æ””æˆª
                if (!newWindow || newWindow.closed || typeof newWindow.closed == 'undefined') {{
                    // é¡¯ç¤ºæ‰‹å‹•å‚™æ¡ˆé€£çµ
                    const fallback = document.getElementById('chatgpt-fallback');
                    if(fallback) fallback.style.display = 'block';
                }}
            }} catch (err) {{
                console.error('Copy failed:', err);
                const errorDiv = document.getElementById('copy-error');
                if(errorDiv) errorDiv.style.display = 'block';
            }}
        }})();
        </script>
        
        <div id="chatgpt-fallback" style="display:none; padding:12px; background:#fff3cd; border:1px solid #ffeaa7; border-radius:6px; margin-top:10px; color:#856404;">
            âš ï¸ <b>å½ˆçª—è¢«ç€è¦½å™¨æ””æˆªäº†ï¼</b><br>
            ğŸ‘‰ <a href="https://chat.openai.com/" target="_blank" style="color:#856404; text-decoration:underline; font-weight:bold;">é»æ“Šé€™è£¡æ‰‹å‹•é–‹å•Ÿ ChatGPT</a><br>
            <small>Prompt å·²è¤‡è£½åˆ°å‰ªè²¼ç°¿ï¼Œè«‹åœ¨ ChatGPT è¦–çª—æŒ‰ Ctrl+V / Cmd+V è²¼ä¸Š</small>
        </div>
        
        <div id="copy-error" style="display:none; padding:12px; background:#f8d7da; border:1px solid #f5c6cb; border-radius:6px; margin-top:10px; color:#721c24;">
            âŒ <b>è¤‡è£½å¤±æ•—</b><br>
            <small>è«‹æ‰‹å‹•è¤‡è£½ä¸Šæ–¹ç¨‹å¼ç¢¼å€å¡Šçš„å…§å®¹</small>
        </div>
        """
        st.components.v1.html(js_code, height=120)
    
    def export_csv(df: pd.DataFrame) -> bytes:
        """åŒ¯å‡º CSVï¼ˆå¸¶ BOMï¼ŒExcel é–‹å•Ÿä¸­æ–‡ä¸äº‚ç¢¼ï¼‰"""
        return df.to_csv(index=False).encode("utf-8-sig")
    
    def export_excel(sheets: dict) -> bytes:
        """åŒ¯å‡ºå¤šå·¥ä½œè¡¨ Excelï¼ˆä½¿ç”¨ openpyxlï¼Œèˆ‡ä½ ç¾æœ‰å¥—ä»¶ç›¸å®¹ï¼‰"""
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            for sheet_name, df in sheets.items():
                if df is not None and not df.empty:
                    # å·¥ä½œè¡¨åç¨±é•·åº¦é™åˆ¶ï¼ˆExcel é™åˆ¶ 31 å­—å…ƒï¼‰
                    safe_name = str(sheet_name)[:31]
                    df.to_excel(writer, sheet_name=safe_name, index=False)
        return output.getvalue()

    # ---------- 1. AI Prompt å®šç¾© ----------
    PROMPT_BIBLE_MASTER = """
ä½ æ˜¯ä¸€ä½ç²¾é€šå¤šåœ‹èªè¨€çš„è–ç¶“å°ˆå®¶èˆ‡èªè¨€å­¸æ•™æˆã€‚è«‹æ ¹æ“šä½¿ç”¨è€…è¼¸å…¥çš„å…§å®¹é¡å‹ï¼Œé¸æ“‡å°æ‡‰çš„æ¨¡å¼è¼¸å‡ºã€‚

---
### æ¨¡å¼ Aï¼šã€è–ç¶“ç¶“æ–‡æ¨¡å¼ã€‘
ç•¶ä½¿ç”¨è€…è¼¸å…¥ç‚ºã€Œä¸­æ–‡è–ç¶“ç¶“æ–‡ã€æ™‚ï¼Œè«‹åš´æ ¼ç”¢å‡ºä»¥ä¸‹ V1 èˆ‡ V2 è¡¨æ ¼æ•¸æ“šï¼Œç¦æ­¢ç”¢å‡ºè¬›ç« ã€‚

è¼¸å…¥ç¶“æ–‡ï¼š
[[TEXT]]

ğŸ”¹ V1 Sheet è¦æ±‚ï¼š
1. Ref.ï¼šè‡ªå‹•æ‰¾å°‹ç¶“å·ç« ç¯€ä¸¦ç”¨ç¸®å¯« (å¦‚: Pro, Rom, Gen)ã€‚
2. English (ESV)ï¼šæª¢ç´¢å°æ‡‰çš„ ESV è‹±æ–‡ç¶“æ–‡ã€‚
3. Chineseï¼šå¡«å…¥æˆ‘æä¾›çš„ä¸­æ–‡åŸæ–‡ã€‚
4. Syn/Antï¼šæŒ‘é¸é«˜ç´šâ†’ä¸­é«˜ç´šâ†’ä¸­ç´šâ†’ä¸­ç´šä»¥ä¸‹ï¼ˆç„¡å‰è€…æ‰åˆ—ï¼‰å­—è©ï¼Œå«ä¸­/è‹±ç¿»è­¯ã€‚
5. Grammarï¼šåš´æ ¼ç¬¦è™ŸåŒ–æ ¼å¼ 1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£Ex.

ğŸ”¹ V2 Sheet è¦æ±‚ï¼š
1. Ref.ï¼šåŒ V1ã€‚
2. å£èªè¨³ï¼šæ—¥æ–‡ã€Šå£èªè¨³è–ç¶“ã€‹(1955)ã€‚
3. Grammarï¼šè§£ææ—¥æ–‡æ–‡æ³•ï¼ˆæ ¼å¼åŒ V1ï¼‰ã€‚
4. Noteï¼šè£œå……æ—¥æ–‡æ–‡æ³•æˆ–èªå¢ƒã€‚
5. KRFï¼šéŸ“æ–‡ã€ŠKorean Revised Versionã€‹ã€‚
6. Syn/Antï¼šéŸ“æ–‡é«˜/ä¸­é«˜ç´šå­—ï¼ˆå«æ—¥/éŸ“/ä¸­ç¿»è­¯ï¼‰ã€‚
7. THSV11ï¼šæ³°æ–‡ã€ŠTHSV11ã€‹ã€‚

è«‹ä»¥ JSON æ ¼å¼å›å‚³ï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
- ref_no: ç·¨è™Ÿ
- ref_article: è‹±æ–‡ç¶“æ–‡
- ref_article_zh: ä¸­æ–‡ç¶“æ–‡
- words: [{{word, level, translation_zh, translation_en, example}}]
- phrases: [{{phrase, meaning, example}}]
- grammar: [{{structure, explanation, example}}]
- v2_data: {{japanese, korean, thai}}

---
### æ¨¡å¼ Bï¼šã€è‹±æ–‡æ–‡ç¨¿æ¨¡å¼ã€‘
ç•¶ä½¿ç”¨è€…è¼¸å…¥ç‚ºã€Œè‹±æ–‡è¬›é“åˆç¨¿ã€æ™‚ï¼š
1ï¸âƒ£ ç´”è‹±æ–‡æ®µè½ â†’ æµæš¢ï¼‹æ–‡æ³•æ­£ç¢ºï¼Œä¿ç•™é«˜ç´š/ä¸­é«˜ç´šå­—è©ï¼Œä¿æŒç¥å­¸ç”¨è©ç²¾ç¢ºã€‚
2ï¸âƒ£ ä¸­è‹±å¤¾é›œæ®µè½ â†’ ä¸­æ–‡æ•˜è¿°ï¼‹å°æ‡‰è‹±æ–‡è©å½™æ’å…¥æ‹¬è™Ÿã€‚
3ï¸âƒ£ æ’ç‰ˆ â†’ å¤§ç¶±æ¨™é¡Œèˆ‡å…§å®¹é–“ç©ºè¡Œã€‚

ğŸ”¹ ç¬¬äºŒæ­¥ï½œèªè¨€ç´ æï¼š
Vocabulary (20å€‹) & Phrases (15å€‹): é«˜ç´š/ä¸­é«˜ç´šå­—è©ï¼‹ç‰‡èªï¼Œä¸­è‹±å°ç…§è–ç¶“ä¾‹å¥ã€‚
Grammar List (6å€‹): åŸæ–‡+çµæ§‹é‚„åŸ+é‚è¼¯è§£æ+ä¸­è‹±ä¾‹å¥ã€‚
"""

    # ---------- 2. é›²ç«¯ JSON æŒä¹…åŒ–å·¥å…· ----------
    if 'sentences' not in st.session_state:
        st.session_state.sentences = {}

    def save_sentences():
        """JSON å„²å­˜è‡³ session_state"""
        st.session_state.sentences = st.session_state.sentences

    # ---------- 3. å…±ç”¨è¼¸å…¥æ¬„ä½ ----------
    st.markdown("ğŸ“šâ‘  è²¼ç¶“æ–‡/è¬›ç¨¿ â†’ â‘¡ ä¸€éµåˆ†æ â†’ â‘¢ ç›´æ¥æª¢è¦– â†’ â‘£ é›¢ç·šä½¿ç”¨")
    input_text = st.text_area("è²¼ä¸Šç¶“æ–‡æˆ–è‹±æ–‡è¬›ç¨¿", height=300, key="input_text")

    # ---------- 4. æ“ä½œæ–¹å¼é¸æ“‡ ----------
    col1, col2 = st.columns([2,3])
    with col1:
        operation = st.selectbox("æ“ä½œæ–¹å¼", ["ChatGPT API ç”Ÿæˆ", "ä»»æ„ LLM UI ç”Ÿæˆ Prompt"])
    with col2:
        st.write("èªªæ˜ï¼šChatGPT API å¯ä¸€éµç”Ÿæˆ Excel/CSVï¼›ä»»æ„ LLM éœ€æ‰‹å‹•è²¼ Prompt ä¸¦è²¼å›çµæœ")

    # ---------- 5. æŒ‰éˆ•ï¼šç”Ÿæˆæˆ–å–å¾— Prompt ----------
    if operation == "ä»»æ„ LLM UI ç”Ÿæˆ Prompt":
        if st.button("ğŸ¤– ç”Ÿæˆ LLM Prompt", type="primary"):
            if not input_text.strip():
                st.error("è«‹å…ˆè²¼ç¶“æ–‡æˆ–è¬›ç¨¿")
                st.stop()
            
            # æ›¿æ› [[TEXT]] ç‚ºå¯¦éš›è¼¸å…¥
            final_prompt = PROMPT_BIBLE_MASTER.replace("[[TEXT]]", input_text.strip())
            st.session_state["generated_prompt"] = final_prompt
            
            st.success("âœ… Prompt å·²ç”Ÿæˆï¼")
            
            # é¡¯ç¤º Promptï¼ˆå¯æŠ˜ç–Šï¼Œé è¨­å±•é–‹ï¼‰
            with st.expander("ğŸ“ æª¢è¦–ç”Ÿæˆçš„ Promptï¼ˆé»æ“Šå³ä¸Šè§’ã€Œè¤‡è£½ã€åœ–ç¤ºï¼‰", expanded=True):
                st.code(final_prompt, language="markdown")
            
            # è‡ªå‹•è¤‡è£½ + é–‹å•Ÿ ChatGPTï¼ˆå«å‚™æ¡ˆæ©Ÿåˆ¶ï¼‰
            st.markdown("---")
            st.markdown("#### ğŸš€ å¿«é€Ÿå‚³é€åˆ° ChatGPT")
            
            col_copy, col_hint = st.columns([1, 2])
            with col_copy:
                if st.button("ğŸ“‹ è¤‡è£½ä¸¦é–‹å•Ÿ ChatGPT", use_container_width=True):
                    copy_and_open_chatgpt(final_prompt)
                    st.toast("âœ… å·²å˜—è©¦è¤‡è£½ä¸¦é–‹å•Ÿæ–°åˆ†é ", icon="ğŸ“‹")
            
            with col_hint:
                st.info("ğŸ’¡ **æç¤º**ï¼šè‹¥æœªè‡ªå‹•é–‹å•Ÿï¼Œè«‹æŸ¥çœ‹ä¸‹æ–¹é»ƒè‰²æç¤ºæ¡†ï¼Œæˆ–ã€Œå…è¨±ç€è¦½å™¨å½ˆçª—ã€", icon="â„¹ï¸")
            
            # é¡¯ç¤º JS é ç•™ä½ç½®ï¼ˆå¯¦éš›å…§å®¹ç”± copy_and_open_chatgpt æ³¨å…¥ï¼‰
            st.caption("è‹¥ä¸Šæ–¹æŒ‰éˆ•ç„¡æ•ˆï¼Œè«‹ç›´æ¥è¤‡è£½ä¸Šæ–¹ç°è‰²å€å¡Šçš„å…§å®¹ï¼Œæ‰‹å‹•è²¼åˆ° ChatGPT")

    elif operation == "ChatGPT API ç”Ÿæˆ":
        if st.button("ğŸ¤– ChatGPT ç”Ÿæˆ Excel/CSV", type="primary"):
            if not input_text.strip():
                st.error("è«‹å…ˆè²¼ç¶“æ–‡æˆ–è¬›ç¨¿")
                st.stop()
            
            # é€™è£¡æ”¾ ChatGPT API å‘¼å«é‚è¼¯ (å‡è¨­ä½ å·²æœ‰ API function)
            # result = call_chatgpt_api(input_text)
            
            # æ¨¡æ“¬çµæœï¼ˆå¯¦éš›ä½¿ç”¨æ™‚è«‹æ›¿æ›ç‚ºçœŸå¯¦ API å›å‚³ï¼‰
            result = {
                "ref_no": f"AI{dt.datetime.now().strftime('%Y%m%d%H%M')}",
                "ref_article": "For God so loved the world... (ESV)",
                "ref_article_zh": "ç¥æ„›ä¸–äººï¼Œç”šè‡³å°‡ä»–çš„ç¨ç”Ÿå­è³œçµ¦ä»–å€‘...",
                "words": [
                    {"word": "loved", "level": "ä¸­ç´š", "translation_zh": "æ„›", "translation_en": "to love affectionately", "example": "For God so loved the world"},
                    {"word": "world", "level": "ä¸­ç´š", "translation_zh": "ä¸–ç•Œ", "translation_en": "the world system", "example": "loved the world"}
                ],
                "phrases": [
                    {"phrase": "so...that", "meaning": "å¦‚æ­¤...ä»¥è‡³æ–¼", "example": "so loved the world that He gave"}
                ],
                "grammar": [
                    {"structure": "1ï¸âƒ£ S+V+O", "explanation": "ä¸»è©+å‹•è©+å—è©çµæ§‹", "example": "God (S) loved (V) the world (O)"}
                ]
            }
            
            ref_no = result["ref_no"]
            st.session_state.sentences[ref_no] = {
                "ref": ref_no,
                "en": result.get("ref_article", ""),
                "zh": result.get("ref_article_zh", ""),
                "data": result,
                "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M")
            }
            save_sentences()
            st.success(f"âœ… å·²ç”Ÿæˆä¸¦å­˜æª”ï¼Ref: {ref_no}")
            st.session_state["analysis"] = result
            st.session_state["show_result"] = True

    # ---------- 6. AI å›å‚³çµæœå…±ç”¨æ¬„ä½ ----------
    st.divider()
    st.markdown("ğŸ“¥ æ­¥é©Ÿ â‘¡ï¼šè²¼ä¸Šä»»æ„ LLM UI å›å‚³çš„åˆ†æçµæœï¼ˆJSONæ ¼å¼ï¼‰")
    ai_result = st.text_area("AI å›å‚³çµæœ", height=250, key="ai_result", 
                             placeholder='è«‹è²¼ä¸Š AI å›å‚³çš„ JSONï¼Œä¾‹å¦‚ï¼š\n{\n  "ref_no": "AI001",\n  "words": [...],\n  "phrases": [...]\n}')
    
    if st.button("ğŸ’¾ å„²å­˜ AI çµæœ", type="secondary"):
        if not ai_result.strip():
            st.error("è«‹å…ˆè²¼ä¸Š AI åˆ†æçµæœ")
            st.stop()
        try:
            cleaned = ai_result.replace("```json", "").replace("```", "").strip()
            data = json.loads(cleaned)
            ref_no = data.get("ref_no", f"AI{dt.datetime.now().strftime('%Y%m%d%H%M')}")
            st.session_state.sentences[ref_no] = {
                "ref": ref_no,
                "en": data.get("ref_article",""),
                "zh": data.get("ref_article_zh",""),
                "data": data,
                "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M")
            }
            save_sentences()
            st.success(f"âœ… AI çµæœå·²å­˜æª”ï¼Ref: {ref_no}")
            st.session_state["analysis"] = data
            st.session_state["show_result"] = True
        except json.JSONDecodeError as e:
            st.error(f"JSON æ ¼å¼éŒ¯èª¤ï¼š{e}ã€‚å·²æ”¹å­˜ç‚ºç´”æ–‡å­—ã€‚")
            ref_no = f"TXT{dt.datetime.now().strftime('%Y%m%d%H%M')}"
            st.session_state.sentences[ref_no] = {
                "ref": ref_no,
                "raw_text": ai_result,
                "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M")
            }
            save_sentences()
            st.success(f"âœ… å·²å­˜ç‚ºç´”æ–‡å­—ï¼Ref: {ref_no}")

    # ---------- 7. çµæœå‘ˆç¾ + åŒ¯å‡ºåŠŸèƒ½ï¼ˆæ•´åˆç‰ˆï¼‰ ----------
    if st.session_state.get("show_result", False) and st.session_state.get("analysis"):
        data = st.session_state["analysis"]
        
        st.divider()
        st.markdown(f"## ğŸ“‹ åˆ†æçµæœï¼š{data.get('ref_no','N/A')}")
        
        # é¡¯ç¤ºç²¾ç…‰æ–‡ç« 
        if data.get("ref_article") or data.get("ref_article_zh"):
            with st.expander("ğŸ“„ æª¢è¦–ç²¾ç…‰æ–‡ç« ", expanded=True):
                if data.get("ref_article"):
                    st.markdown("**English:**")
                    st.markdown(data["ref_article"])
                if data.get("ref_article_zh"):
                    st.markdown("**ä¸­æ–‡:**")
                    st.markdown(data["ref_article_zh"])
        
        # è©³ç´°è³‡æ–™åˆ†é 
        col_w, col_p, col_g = st.tabs(["å–®å­— (Words)","ç‰‡èª (Phrases)","æ–‡æ³• (Grammar)"])
        
        words_df = pd.DataFrame()
        phrases_df = pd.DataFrame()
        grammar_df = pd.DataFrame()
        
        with col_w:
            if data.get("words"):
                words_df = pd.DataFrame(data["words"])
                st.dataframe(words_df, use_container_width=True)
            else:
                st.info("æœ¬æ¬¡ç„¡å–®å­—åˆ†æ")
        
        with col_p:
            if data.get("phrases"):
                phrases_df = pd.DataFrame(data["phrases"])
                st.dataframe(phrases_df, use_container_width=True)
            else:
                st.info("æœ¬æ¬¡ç„¡ç‰‡èªåˆ†æ")
        
        with col_g:
            if data.get("grammar"):
                grammar_df = pd.DataFrame(data["grammar"])
                st.dataframe(grammar_df, use_container_width=True)
            else:
                st.info("æœ¬æ¬¡ç„¡æ–‡æ³•é»")
        
        # â¬‡ï¸ æ–°å¢ï¼šåŒ¯å‡ºåŠŸèƒ½å€ ----------
        st.divider()
        st.markdown("## â¬‡ï¸ åŒ¯å‡ºåˆ†æçµæœ")
        
        # é è¦½çµ±è¨ˆ
        preview_cols = st.columns(3)
        with preview_cols[0]:
            st.metric("å–®å­—æ•¸", len(words_df))
        with preview_cols[1]:
            st.metric("ç‰‡èªæ•¸", len(phrases_df))
        with preview_cols[2]:
            st.metric("æ–‡æ³•é»", len(grammar_df))
        
        # ä¸‹è¼‰æŒ‰éˆ•æ’ç‰ˆ
        dl_col1, dl_col2, dl_col3 = st.columns(3)
        
        with dl_col1:
            if not words_df.empty:
                st.download_button(
                    label="ğŸ“„ ä¸‹è¼‰ Words.csv",
                    data=export_csv(words_df),
                    file_name=f"{data.get('ref_no','analysis')}_words.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            else:
                st.button("ğŸ“„ ç„¡ Words", disabled=True, use_container_width=True)
        
        with dl_col2:
            if not phrases_df.empty:
                st.download_button(
                    label="ğŸ“„ ä¸‹è¼‰ Phrases.csv",
                    data=export_csv(phrases_df),
                    file_name=f"{data.get('ref_no','analysis')}_phrases.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            else:
                st.button("ğŸ“„ ç„¡ Phrases", disabled=True, use_container_width=True)
        
        with dl_col3:
            # Excel å¤šå·¥ä½œè¡¨ï¼ˆç¸½æ˜¯æä¾›ï¼Œå³ä½¿ç‚ºç©ºä¹Ÿä¿ç•™çµæ§‹ï¼‰
            excel_data = export_excel({
                "Words": words_df,
                "Phrases": phrases_df,
                "Grammar": grammar_df
            })
            st.download_button(
                label="ğŸ“Š ä¸‹è¼‰å®Œæ•´ Excel (.xlsx)",
                data=excel_data,
                file_name=f"{data.get('ref_no','analysis')}_å®Œæ•´åˆ†æ.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="primary",
                use_container_width=True
            )
        
        # é¡å¤–ï¼šJSON åŸå§‹è³‡æ–™ï¼ˆå‚™ä»½ç”¨ï¼‰
        with st.expander("ğŸ’¾ é€²éšï¼šåŒ¯å‡ºåŸå§‹ JSONï¼ˆä¾›å‚™ä»½æˆ–è·¨è£ç½®è½‰ç§»ï¼‰"):
            json_str = json.dumps(data, ensure_ascii=False, indent=2)
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰ JSON",
                data=json_str.encode('utf-8'),
                file_name=f"{data.get('ref_no','analysis')}.json",
                mime="application/json"
            )
            st.json(data)

    # ---------- 8. åŒ¯å‡ºèˆ‡å®¹é‡ç®¡ç†ï¼ˆä¿ç•™åŸåŠŸèƒ½ï¼‰ ----------
    st.divider()
    col_mgr1, col_mgr2 = st.columns(2)
    
    with col_mgr1:
        if st.button("ğŸ“‹ åŒ¯å‡ºå«å›æº¯æ¬„ä½"):
            export = []
            for k,v in st.session_state.sentences.items():
                export.append(f"{k}\t{v.get('ref','')}\t{v.get('en','')}\t{v.get('raw_text','')[:100]}")
            st.code("\n".join(export), language="text")
    
    with col_mgr2:
        max_keep = st.number_input("æœ€å¤šä¿ç•™æœ€è¿‘å¹¾ç­†åˆ†æç´€éŒ„", min_value=10, max_value=1000, value=50)
        if st.button("âœ‚ï¸ å£“ç¸®èˆŠç´€éŒ„"):
            hist = list(st.session_state.sentences.items())
            if len(hist) > max_keep:
                st.session_state.sentences = dict(hist[-max_keep:])
                st.success(f"å·²å£“ç¸®è‡³æœ€è¿‘ {max_keep} ç­†ï¼")
            else:
                st.info("æœªé”å£“ç¸®é–€æª»")
