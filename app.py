# ===================================================================
# 0. å¥—ä»¶ & å…¨åŸŸå‡½å¼ï¼ˆä¸€å®šæ”¾æœ€é ‚ï¼‰
# ===================================================================
import streamlit as st  

# âœ… ä¿®æ­£ï¼šset_page_config å¿…é ˆæ˜¯ç¬¬ä¸€å€‹ Streamlit æŒ‡ä»¤
st.set_page_config(layout="wide", page_title="Bible Study AI App 2026")

import subprocess, sys, os, datetime as dt, pandas as pd, io, json, re, tomli, tomli_w
from streamlit_calendar import calendar
import streamlit.components.v1 as components
import requests
import base64
import csv
import random
import urllib.parse
from io import StringIO
import gspread
from google.oauth2.service_account import Credentials

# åœ¨æ–‡ä»¶æœ€é–‹å§‹åˆå§‹åŒ–æ‰€æœ‰ session state è®Šé‡
def init_session_state():
    defaults = {
        "is_prompt_generated": False,
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

init_session_state()

# ---------- å…¨åŸŸå·¥å…·å‡½å¼ ----------
def save_analysis_result(result, input_text):
    if "analysis_history" not in st.session_state:
        st.session_state.analysis_history = []
    st.session_state.analysis_history.append({
        "date": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
        "input_preview": input_text[:50] + "..." if len(input_text) > 50 else input_text,
        "result": result
    })
    if len(st.session_state.analysis_history) > 10:
        st.session_state.analysis_history.pop(0)

def to_excel(result: dict) -> bytes:
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        for sheet, key in [("Words", "words"), ("Phrases", "phrases"), ("Grammar", "grammar")]:
            if key in result and result[key]:
                pd.DataFrame(result[key]).to_excel(writer, sheet_name=sheet, index=False)
        stats = pd.DataFrame({
            "é …ç›®": ["ç¸½å­—å½™æ•¸", "ç¸½ç‰‡èªæ•¸", "æ–‡æ³•é»æ•¸", "åˆ†ææ—¥æœŸ"],
            "æ•¸å€¼": [
                len(result.get("words", [])),
                len(result.get("phrases", [])),
                len(result.get("grammar", [])),
                dt.date.today().strftime("%Y-%m-%d")
            ]
        })
        stats.to_excel(writer, sheet_name="çµ±è¨ˆ", index=False)
    buffer.seek(0)
    return buffer.getvalue()

# ===================================================================
# âœ… ä¿®æ­£ï¼šè³‡æ–™åº«è¨­å®š - çµ±ä¸€ä½¿ç”¨ data ç›®éŒ„ï¼Œä¸¦åŠ å…¥ Google Sheets å‚™æ´
# ===================================================================
DATA_DIR = "data"
SENTENCES_FILE = os.path.join(DATA_DIR, "sentences.json")
TODO_FILE = os.path.join(DATA_DIR, "todos.json")
FAVORITE_FILE = os.path.join(DATA_DIR, "favorite_sentences.json")

# ç¢ºä¿è³‡æ–™ç›®éŒ„å­˜åœ¨
os.makedirs(DATA_DIR, exist_ok=True)

# ---------- Google Sheets è¨­å®š ----------
def init_google_sheets():
    """åˆå§‹åŒ– Google Sheets é€£ç·š"""
    try:
        if "gcp_service_account" not in st.secrets:
            return None, None
        if "sheets" not in st.secrets or "spreadsheet_id" not in st.secrets["sheets"]:
            return None, None
            
        gcp_sa = st.secrets["gcp_service_account"]
        sheet_id = st.secrets["sheets"]["spreadsheet_id"]
        
        creds = Credentials.from_service_account_info(
            gcp_sa,
            scopes=["https://www.googleapis.com/auth/spreadsheets"]
        )
        gc = gspread.authorize(creds)
        return gc, sheet_id
    except Exception as e:
        st.sidebar.error(f"Google Sheets åˆå§‹åŒ–å¤±æ•—: {e}")
        return None, None

# å…¨åŸŸåˆå§‹åŒ–
GC, SHEET_ID = init_google_sheets()

def get_or_create_worksheet(sheet_name, rows=1000, cols=20):
    """å–å¾—æˆ–å»ºç«‹å·¥ä½œè¡¨"""
    if not GC or not SHEET_ID:
        return None
    try:
        sh = GC.open_by_key(SHEET_ID)
        try:
            return sh.worksheet(sheet_name)
        except gspread.WorksheetNotFound:
            return sh.add_worksheet(title=sheet_name, rows=rows, cols=cols)
    except Exception as e:
        st.error(f"å·¥ä½œè¡¨æ“ä½œå¤±æ•—: {e}")
        return None

def save_to_google_sheets(data_dict):
    """å„²å­˜è³‡æ–™åˆ° Google Sheetsï¼ˆä¸»è¦å„²å­˜ï¼‰"""
    if not GC or not SHEET_ID:
        return False, "Google Sheets æœªé€£ç·š"
    
    try:
        mode = data_dict.get('mode', 'A')
        sheet_name = f"Mode_{mode}_Data"
        worksheet = get_or_create_worksheet(sheet_name)
        
        if not worksheet:
            return False, "ç„¡æ³•å–å¾—å·¥ä½œè¡¨"
        
        # æº–å‚™è³‡æ–™åˆ—
        ref = data_dict.get('ref', 'N/A')
        row_data = [
            ref,
            data_dict.get('type', 'Unknown'),
            data_dict.get('original', '')[:200],
            data_dict.get('v1_content', '')[:2000] if data_dict.get('v1_content') else "",
            data_dict.get('v2_content', '')[:2000] if data_dict.get('v2_content') else "",
            data_dict.get('w_sheet', '')[:2000] if data_dict.get('w_sheet') else "",
            data_dict.get('p_sheet', '')[:2000] if data_dict.get('p_sheet') else "",
            data_dict.get('grammar_list', '')[:2000] if data_dict.get('grammar_list') else "",
            dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
            json.dumps(data_dict.get('saved_sheets', []))
        ]
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆæ›´æ–° vs æ–°å¢ï¼‰
        try:
            cell = worksheet.find(ref)
            if cell:
                worksheet.update(f"A{cell.row}:J{cell.row}", [row_data])
                return True, "updated"
        except:
            pass
        
        # æ–°å¢è¡Œ
        worksheet.append_row(row_data)
        return True, "created"
        
    except Exception as e:
        return False, str(e)

def load_from_google_sheets():
    """å¾ Google Sheets è¼‰å…¥æ‰€æœ‰è³‡æ–™"""
    if not GC or not SHEET_ID:
        return {}
    
    all_data = {}
    try:
        sh = GC.open_by_key(SHEET_ID)
        
        for mode in ['A', 'B']:
            sheet_name = f"Mode_{mode}_Data"
            try:
                worksheet = sh.worksheet(sheet_name)
                rows = worksheet.get_all_values()
                
                if len(rows) > 1:
                    headers = rows[0]
                    for row in rows[1:]:
                        if len(row) >= 10:
                            ref = row[0]
                            all_data[ref] = {
                                "ref": ref,
                                "type": row[1],
                                "original": row[2],
                                "v1_content": row[3] if len(row) > 3 else "",
                                "v2_content": row[4] if len(row) > 4 else "",
                                "w_sheet": row[5] if len(row) > 5 else "",
                                "p_sheet": row[6] if len(row) > 6 else "",
                                "grammar_list": row[7] if len(row) > 7 else "",
                                "date_added": row[8] if len(row) > 8 else "",
                                "saved_sheets": json.loads(row[9]) if len(row) > 9 and row[9] else [],
                                "mode": mode,
                                "source": "google_sheets"
                            }
            except gspread.WorksheetNotFound:
                continue
                
        return all_data
    except Exception as e:
        st.sidebar.error(f"è¼‰å…¥ Google Sheets å¤±æ•—: {e}")
        return {}

def sync_local_to_sheets():
    """åŒæ­¥æœ¬åœ°è³‡æ–™åˆ° Google Sheets"""
    if not GC or not SHEET_ID:
        return False
    
    try:
        local_data = load_sentences()
        success_count = 0
        for ref, data in local_data.items():
            success, _ = save_to_google_sheets(data)
            if success:
                success_count += 1
        return success_count
    except Exception as e:
        st.error(f"åŒæ­¥å¤±æ•—: {e}")
        return 0

# ---------- æœ¬åœ° JSON æª”æ¡ˆæ“ä½œï¼ˆä½œç‚ºå¿«å–/å‚™æ´ï¼‰----------
def load_sentences():
    """å®‰å…¨è¼‰å…¥æœ¬åœ°è³‡æ–™åº«"""
    if os.path.exists(SENTENCES_FILE):
        try:
            with open(SENTENCES_FILE, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if not content:
                    return {}
                return json.loads(content)
        except json.JSONDecodeError as e:
            backup_name = f"{SENTENCES_FILE}.backup_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}"
            try:
                os.rename(SENTENCES_FILE, backup_name)
                st.warning(f"âš ï¸ æœ¬åœ°è³‡æ–™åº«ææ¯€ï¼Œå·²å‚™ä»½ç‚º {backup_name}")
            except:
                pass
            return {}
        except Exception as e:
            st.error(f"è¼‰å…¥æœ¬åœ°è³‡æ–™åº«å¤±æ•—ï¼š{e}")
            return {}
    return {}

def save_sentences(data):
    """å®‰å…¨å„²å­˜æœ¬åœ°è³‡æ–™åº«ï¼ˆåŸå­å¯«å…¥ï¼‰"""
    try:
        temp_file = f"{SENTENCES_FILE}.tmp"
        with open(temp_file, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        if os.path.exists(SENTENCES_FILE):
            os.replace(temp_file, SENTENCES_FILE)
        else:
            os.rename(temp_file, SENTENCES_FILE)
            
        # è‡ªå‹•åŒæ­¥åˆ° Google Sheets
        if GC and SHEET_ID:
            try:
                save_to_google_sheets(data)
            except:
                pass
                
    except Exception as e:
        st.error(f"å„²å­˜æœ¬åœ°è³‡æ–™åº«å¤±æ•—ï¼š{e}")

def load_todos():
    if os.path.exists(TODO_FILE):
        try:
            with open(TODO_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            pass
    return {}

def save_todos():
    with open(TODO_FILE, "w", encoding="utf-8") as f:
        json.dump(st.session_state.todo, f, ensure_ascii=False, indent=2)

def load_favorites():
    if os.path.exists(FAVORITE_FILE):
        try:
            with open(FAVORITE_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            pass
    return []

def save_favorites():
    with open(FAVORITE_FILE, "w", encoding="utf-8") as f:
        json.dump(st.session_state.favorite_sentences, f, ensure_ascii=False, indent=2)

# âœ… ä¿®æ­£ï¼šåˆå§‹åŒ– Session Stateï¼ˆå„ªå…ˆå¾ Google Sheets è¼‰å…¥ï¼‰
if 'sentences' not in st.session_state:
    sheets_data = load_from_google_sheets()
    if sheets_data:
        st.session_state.sentences = sheets_data
        save_sentences(sheets_data)
    else:
        st.session_state.sentences = load_sentences()

if 'todo' not in st.session_state:
    st.session_state.todo = load_todos()
if 'favorite_sentences' not in st.session_state:
    st.session_state.favorite_sentences = load_favorites()
if 'sel_date' not in st.session_state:
    st.session_state.sel_date = str(dt.date.today())
if 'cal_key' not in st.session_state:
    st.session_state.cal_key = 0
if 'active_del_id' not in st.session_state:
    st.session_state.active_del_id = None
if 'active_fav_del' not in st.session_state:
    st.session_state.active_fav_del = None

# ===================================================================
# 1. å´é‚Šæ¬„
# ===================================================================
with st.sidebar:
    st.divider()
    c1, c2 = st.columns(2)
    c1.link_button("âœ¨ Google AI", "https://gemini.google.com")
    c2.link_button("ğŸ¤– Kimi K2", "https://kimi.moonshot.cn")
    c3, c4 = st.columns(2)
    c3.link_button("ESV Bible", "https://wd.bible/bible/gen.1.cunps?parallel=esv.klb.jcb")
    c4.link_button("THSV11", "https://www.bible.com/zh-TW/bible/174/GEN.1.THSV11")
    
    st.divider()
    st.markdown("### ğŸ’¾ è³‡æ–™åº«ç‹€æ…‹")
    
    if GC and SHEET_ID:
        st.success("âœ… Google Sheets å·²é€£ç·š")
        if st.button("ğŸ”„ å¼·åˆ¶åŒæ­¥åˆ°é›²ç«¯", use_container_width=True):
            count = sync_local_to_sheets()
            st.success(f"å·²åŒæ­¥ {count} ç­†è³‡æ–™åˆ° Google Sheets")
    else:
        st.error("âŒ Google Sheets æœªé€£ç·š")
        st.caption("è«‹åœ¨ secrets.toml è¨­å®š gcp_service_account")
    
    local_count = len(st.session_state.get('sentences', {}))
    st.caption(f"æœ¬åœ°å¿«å–ï¼š{local_count} ç­†")
    
    st.divider()
    st.markdown("### ğŸ–¼ï¸ åº•éƒ¨èƒŒæ™¯è¨­å®š")
    
    bg_options = {
        "ğŸ¶ Snoopy": "Snoopy.jpg",
        "ğŸ° Mashimaro 1": "Mashimaro1.jpg",
        "ğŸ° Mashimaro 2": "Mashimaro2.jpg",
        "ğŸ° Mashimaro 3": "Mashimaro3.jpg",
        "ğŸ° Mashimaro 4": "Mashimaro4.jpg",
        "ğŸ° Mashimaro 5": "Mashimaro5.jpg",
        "ğŸ° Mashimaro 6": "Mashimaro6.jpg"
    }
    
    if 'selected_bg' not in st.session_state:
        st.session_state.selected_bg = list(bg_options.keys())[0]
    if 'bg_size' not in st.session_state:
        st.session_state.bg_size = 15
    if 'bg_bottom' not in st.session_state:
        st.session_state.bg_bottom = 30
    
    selected_bg = st.selectbox(
        "é¸æ“‡è§’è‰²", 
        list(bg_options.keys()), 
        index=list(bg_options.keys()).index(st.session_state.selected_bg),
        key="selected_bg"
    )
    
    col1, col2 = st.columns(2)
    with col1:
        bg_size = st.slider("åœ–ç‰‡å¤§å°", 5, 50, st.session_state.bg_size, format="%d%%", key="bg_size")
    with col2:
        bg_bottom = st.slider("åº•éƒ¨é–“è·", 0, 100, st.session_state.bg_bottom, format="%dpx", key="bg_bottom")

# èƒŒæ™¯ CSS
selected_img_file = bg_options[st.session_state.selected_bg]
current_bg_size = st.session_state.bg_size
current_bg_bottom = st.session_state.bg_bottom

try:
    if os.path.exists(selected_img_file):
        with open(selected_img_file, "rb") as f:
            img_b64 = base64.b64encode(f.read()).decode()
        st.markdown(f"""
        <style>
        .stApp {{
            background-image: url("data:image/jpeg;base64,{img_b64}");
            background-size: {current_bg_size}% auto;
            background-position: center bottom {current_bg_bottom}px;
            background-attachment: fixed;
            background-repeat: no-repeat;
            z-index: 0;
        }}
        .main .block-container {{
            position: relative;
            z-index: 1;
            padding-bottom: {current_bg_bottom + 100}px;
        }}
        </style>
        """, unsafe_allow_html=True)
except:
    pass

# ===================================================================
# 2. é é¢é…ç½® & Session åˆå€¼
# ===================================================================
if 'analysis_history' not in st.session_state: 
    st.session_state.analysis_history = []

# ---------- CSS ----------
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Gamja+Flower&display=swap');
.cute-korean { font-family: 'Gamja Flower', cursive; font-size: 20px; color: #FF8C00; text-align: center; }
.small-font { font-size: 13px; color: #555555; margin-top: 5px !important; }
.grammar-box-container {
    background-color: #f8f9fa; border-radius: 8px; padding: 12px;
    border-left: 5px solid #FF8C00; text-align: left; margin-top: 0px;
}
.fc-daygrid-day-frame:hover {background-color: #FFF3CD !important; cursor: pointer; transform: scale(1.03); transition: .2s}
.fc-daygrid-day-frame:active {transform: scale(0.98); background-color: #FFE69C !important}
</style>
""", unsafe_allow_html=True)

# ---------- åœ–ç‰‡ & ç¾æˆ TAB ----------
IMG_URLS = {
    "A": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/183ebb183330643.Y3JvcCw4MDgsNjMyLDAsMA.jpg",
    "B": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/f364bd220887627.67cae1bd07457.jpg",
    "C": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/68254faebaafed9dafb41918f74c202e.jpg",
    "M1": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro1.jpg",
    "M2": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro2.jpg",
    "M3": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro3.jpg",
    "M4": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro4.jpg"
}
with st.sidebar:
    st.markdown('<p class="cute-korean">ë‹¹ì‹ ì€ í•˜ë‚˜ë‹˜ì˜ ì†Œì¤‘í•œ ë³´ë¬¼ì…ë‹ˆë‹¤</p>', unsafe_allow_html=True)
    st.image(IMG_URLS["M3"], width=250)
    st.divider()

tabs = st.tabs(["ğŸ  æ›¸æ¡Œ", "ğŸ““ ç­†è¨˜", "âœï¸ æŒ‘æˆ°", "ğŸ“‚ è³‡æ–™åº«"])

# ===================================================================
# 3. TAB1 â”€ æ›¸æ¡Œ (è¼ªæµé¡¯ç¤ºç‰ˆ - æ”¯æ´CSVå’ŒMarkdowné›™æ ¼å¼)
# ===================================================================
with tabs[0]:
    import csv, random, re, datetime as dt
    from io import StringIO

    # ç¢ºä¿è³‡æ–™å·²è¼‰å…¥
    if 'sentences' not in st.session_state:
        st.session_state.sentences = load_sentences()
    
    sentences = st.session_state.sentences

    # --- Session State åˆå§‹åŒ–ï¼ˆç¢ºä¿æ¯æ¬¡éƒ½æœ‰å€¼ï¼‰---
    if "tab1_vocab_index" not in st.session_state:
        st.session_state.tab1_vocab_index = 0
    if "tab1_phrase_index" not in st.session_state:
        st.session_state.tab1_phrase_index = 15
    if "tab1_grammar_index" not in st.session_state:
        st.session_state.tab1_grammar_index = 0
    if "tab1_verse_index" not in st.session_state:
        st.session_state.tab1_verse_index = 0
    if "tab1_last_update" not in st.session_state:
        st.session_state.tab1_last_update = dt.datetime.now()

    # æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¶…é1å°æ™‚ï¼‰
    current_time = dt.datetime.now()
    time_diff = (current_time - st.session_state.tab1_last_update).total_seconds()
    
    if time_diff > 3600:
        st.session_state.tab1_last_update = current_time
        st.session_state.tab1_vocab_index += 1
        st.session_state.tab1_phrase_index += 4
        st.session_state.tab1_grammar_index += 1
        st.session_state.tab1_verse_index += 1
        st.rerun()
    
    if not sentences:
        st.warning("è³‡æ–™åº«ç‚ºç©ºï¼Œè«‹å…ˆåœ¨ TAB4 è¼‰å…¥è³‡æ–™")
    else:
        def parse_csv(content):
            """è§£æCSVæ ¼å¼"""
            if not content or not content.strip(): 
                return []
            try:
                if '|' in content and '\n' in content and content.strip().startswith('|'):
                    return []
                reader = csv.DictReader(StringIO(content.strip()))
                rows = list(reader)
                return [row for row in rows if any(v.strip() for v in row.values())]
            except Exception as e:
                st.write(f"CSVè§£æéŒ¯èª¤: {e}")
                return []

        def parse_markdown_table(content):
            """è§£æMarkdownè¡¨æ ¼æ ¼å¼"""
            if not content or not content.strip():
                return []
            
            lines = content.strip().split('\n')
            rows = []
            
            table_lines = []
            for line in lines:
                line = line.strip()
                if line.startswith('|'):
                    table_lines.append(line)
            
            if len(table_lines) < 2:
                return []
            
            header_line = table_lines[0]
            headers = [h.strip() for h in header_line.split('|')[1:-1]]
            
            data_lines = table_lines[2:]
            
            for line in data_lines:
                if not line.strip() or line.strip().replace('|', '').strip() == '':
                    continue
                    
                cells = [c.strip() for c in line.split('|')[1:-1]]
                
                while len(cells) < len(headers):
                    cells.append('')
                
                row_dict = {}
                for i, header in enumerate(headers):
                    cell_value = cells[i] if i < len(cells) else ''
                    cell_value = re.sub(r'\*\*(.*?)\*\*', r'\1', cell_value)
                    row_dict[header] = cell_value
                
                if any(v.strip() for v in row_dict.values()):
                    rows.append(row_dict)
            
            return rows

        # æ”¶é›†æ‰€æœ‰æ¨¡å¼Aè³‡æ–™å’Œæ¨¡å¼Bè³‡æ–™
        all_mode_a = []
        all_mode_b = []
        all_grammar_sources = []
        
        for ref, data in sentences.items():
            v1_content = data.get('v1_content', '')
            v2_content = data.get('v2_content', '')
            w_content = data.get('w_sheet', '')
            g_content = data.get('grammar_list', '')
            
            v1_rows = parse_csv(v1_content) or parse_markdown_table(v1_content)
            v2_rows = parse_csv(v2_content) or parse_markdown_table(v2_content)
            w_rows = parse_csv(w_content) or parse_markdown_table(w_content)
            g_rows = parse_csv(g_content) or parse_markdown_table(g_content)
            
            if v1_rows:
                all_mode_a.append({
                    'ref': ref,
                    'v1': v1_rows,
                    'v2': v2_rows,
                    'v1_count': len(v1_rows)
                })
                for i, row in enumerate(v1_rows):
                    all_grammar_sources.append({
                        'type': 'A',
                        'ref': ref,
                        'row': row,
                        'v2_row': v2_rows[i] if i < len(v2_rows) else {},
                        'index': i,
                        'total_in_file': len(v1_rows)
                    })
            
            if w_rows and len(w_rows) > 0:
                all_mode_b.append({
                    'ref': ref,
                    'w': w_rows,
                    'w_count': len(w_rows)
                })
            
            if g_rows:
                for i, row in enumerate(g_rows):
                    all_grammar_sources.append({
                        'type': 'B',
                        'ref': ref,
                        'row': row,
                        'v2_row': {},
                        'index': i,
                        'total_in_file': len(g_rows)
                    })
        
        # 1) å–®å­—ï¼šV1 Syn/Ant + V2 Syn/Ant + THSV11
        vocab_display = []
        current_vocab_ref = "N/A"
        
        if all_mode_a:
            total_vocab_items = sum(f['v1_count'] for f in all_mode_a)
            if total_vocab_items > 0:
                vocab_counter = st.session_state.tab1_vocab_index % total_vocab_items
                cumulative = 0
                vocab_file = None
                row_idx = 0
                for f in all_mode_a:
                    if cumulative + f['v1_count'] > vocab_counter:
                        vocab_file = f
                        row_idx = vocab_counter - cumulative
                        break
                    cumulative += f['v1_count']
                
                if vocab_file and row_idx < len(vocab_file['v1']):
                    v1_row = vocab_file['v1'][row_idx]
                    v2_row = vocab_file['v2'][row_idx] if row_idx < len(vocab_file['v2']) else {}
                    
                    current_vocab_ref = v1_row.get('Ref.', vocab_file['ref'])
                    if not current_vocab_ref or current_vocab_ref == vocab_file['ref']:
                        # å˜—è©¦å¾å…¶ä»–æ¬„ä½å–å¾—
                        current_vocab_ref = v1_row.get('Ref', v1_row.get('ref', vocab_file['ref']))
                    
                    # V1 Syn/Ant - è§£æåŒç¾©è©å’Œåç¾©è©
                    v1_syn_ant = v1_row.get('Syn/Ant', v1_row.get('Syn/Ant.', ''))
                    v1_syn_list = []
                    v1_ant_list = []
                    
                    if v1_syn_ant and v1_syn_ant.strip():
                        v1_syn_ant_str = str(v1_syn_ant)
                        # å˜—è©¦å¤šç¨®æ ¼å¼è§£æ
                        if 'Syn:' in v1_syn_ant_str or 'Ant:' in v1_syn_ant_str:
                            syn_match = re.search(r'Syn:\s*([^/;]+)', v1_syn_ant_str, re.IGNORECASE)
                            ant_match = re.search(r'Ant:\s*([^/;]+)', v1_syn_ant_str, re.IGNORECASE)
                            if syn_match:
                                v1_syn_list = [s.strip() for s in syn_match.group(1).split(',') if s.strip()]
                            if ant_match:
                                v1_ant_list = [a.strip() for a in ant_match.group(1).split(',') if a.strip()]
                        else:
                            # å˜—è©¦ç”¨ / æˆ– | åˆ†éš”
                            parts = re.split(r'[/|]', v1_syn_ant_str)
                            if len(parts) >= 2:
                                v1_syn_list = [p.strip() for p in parts[0].split(',') if p.strip()]
                                v1_ant_list = [p.strip() for p in parts[1].split(',') if p.strip()]
                            else:
                                # å¦‚æœåªæœ‰ä¸€å€‹éƒ¨åˆ†ï¼Œå¯èƒ½æ˜¯åŒç¾©è©
                                v1_syn_list = [v1_syn_ant_str.strip()]
                    
                    # V2 Syn/Ant (éŸ“æ–‡) + THSV11 (æ³°æ–‡)
                    v2_syn_ant = v2_row.get('Syn/Ant', v2_row.get('Syn/Ant.', '')) if v2_row else ''
                    v2_th = v2_row.get('THSV11', v2_row.get('THSV11 (Key Phrases)', '')) if v2_row else ''
                    
                    vocab_items = []
                    if v1_syn_list:
                        vocab_items.append(f"<span style='color:#2E8B57;'>âœ¨{', '.join(v1_syn_list)}</span>")
                    if v1_ant_list:
                        vocab_items.append(f"<span style='color:#CD5C5C;'>â„ï¸{', '.join(v1_ant_list)}</span>")
                    if v2_syn_ant and str(v2_syn_ant).strip():
                        vocab_items.append(f"<span style='color:#4682B4;'>ğŸ‡°ğŸ‡· {v2_syn_ant}</span>")
                    if v2_th and str(v2_th).strip():
                        vocab_items.append(f"<span style='color:#9932CC;'>ğŸ‡¹ğŸ‡­ {v2_th}</span>")
                    
                    vocab_display = vocab_items
        
        # 2) ç‰‡èªï¼šåªå¾æ¨¡å¼Bçš„W Sheetè¼ªæµï¼ˆç¬¬16å€‹é–‹å§‹ï¼Œç´¢å¼•15ï¼‰
        w_phrases = []
        current_phrase_ref = "N/A"
        
        all_available_phrases = []
        
        for mb in all_mode_b:
            w_rows = mb.get('w', [])
            w_count = len(w_rows)
            
            if w_count > 15:
                for idx in range(15, w_count):
                    all_available_phrases.append({
                        'data': w_rows[idx],
                        'ref': mb['ref'],
                        'original_idx': idx + 1
                    })
        
        if len(all_available_phrases) > 0:
            total_available = len(all_available_phrases)
            start_idx = st.session_state.tab1_phrase_index % total_available
            
            for i in range(4):
                idx = (start_idx + i) % total_available
                item = all_available_phrases[idx]
                w_phrases.append(item['data'])
                if i == 0:
                    current_phrase_ref = f"{item['ref']} #{item['original_idx']}"
        
        # 3) é‡‘å¥ï¼šå¾æ¨¡å¼Açš„V1 Sheetè¼ªæµï¼ˆèˆ‡å–®å­—éŒ¯é–‹6å¥ï¼‰
        verse_lines = []
        current_verse_ref = "N/A"
        
        if all_mode_a:
            total_verse_items = sum(f['v1_count'] for f in all_mode_a)
            if total_verse_items > 0:
                # é‡‘å¥ç´¢å¼• = ç•¶å‰ç´¢å¼• + 6ï¼Œèˆ‡å–®å­—éŒ¯é–‹
                verse_counter = (st.session_state.tab1_verse_index + 6) % total_verse_items
                cumulative = 0
                verse_file = None
                row_idx = 0
                
                for f in all_mode_a:
                    if cumulative + f['v1_count'] > verse_counter:
                        verse_file = f
                        row_idx = verse_counter - cumulative
                        break
                    cumulative += f['v1_count']
                
                if verse_file and row_idx < len(verse_file['v1']):
                    v1_verse = verse_file['v1'][row_idx]
                    v2_verse = verse_file['v2'][row_idx] if row_idx < len(verse_file['v2']) else {}
                    
                    current_verse_ref = v1_verse.get('Ref.', v1_verse.get('Ref', verse_file['ref']))
                    
                    # å»ºè­°æ”¹å¯«æŠ“å–æ–¹å¼ï¼Œå¢åŠ ç›¸å®¹æ€§
                    en_text = v1_verse.get('English (ESV)', v1_verse.get('English', v1_verse.get('ESV', '')))
                    cn_text = v1_verse.get('Chinese', v1_verse.get('Chinese (CUV)', v1_verse.get('CUV', '')))
                    # å˜—è©¦æŠ“å–ä¸åŒå¯èƒ½çš„æ¨™ç±¤åç¨±
                    jp_text = ''
                    if v2_verse:
                        jp_text = v2_verse.get('å£èªè¨³ (1955)', v2_verse.get('å£èªè¨³', v2_verse.get('Japanese', '')))
                    kr_text = v2_verse.get('KRF', v2_verse.get('Korean', '')) if v2_verse else ''
                    th_text = ''
                    if v2_verse:
                        th_text = v2_verse.get('THSV11 (Key Phrases)', v2_verse.get('THSV11', v2_verse.get('Thai', '')))

                    # å¡«å……é‚è¼¯
                    verse_lines = []
                    if en_text and str(en_text).strip(): 
                        verse_lines.append(f"ğŸ‡¬ğŸ‡§ **{current_verse_ref}** {en_text}")
                    if jp_text and str(jp_text).strip(): 
                        verse_lines.append(f"ğŸ‡¯ğŸ‡µ {jp_text}")
                    if kr_text and str(kr_text).strip(): 
                        verse_lines.append(f"ğŸ‡°ğŸ‡· {kr_text}")
                    if th_text and str(th_text).strip(): 
                        verse_lines.append(f"ğŸ‡¹ğŸ‡­ {th_text}")
                    if cn_text and str(cn_text).strip(): 
                        verse_lines.append(f"ğŸ‡¨ğŸ‡³ {cn_text}")              
                    
        # 4) æ–‡æ³•ï¼šå¾å…©è™•ä¾†ï¼ŒåŠ å…¥V2å£èªè¨³+Grammar+Note
        grammar_html = "ç­‰å¾…è³‡æ–™ä¸­..."
        current_grammar_ref = "N/A"
        
        if all_grammar_sources:
            g_idx = st.session_state.tab1_grammar_index % len(all_grammar_sources)
            g_source = all_grammar_sources[g_idx]
            g_row = g_source['row']
            v2_row = g_source.get('v2_row', {})
            current_grammar_ref = f"{g_source['ref']}-{g_source['index']+1}"
            
            all_grammar = []
            
            if g_source['type'] == 'A':
                g_ref = g_row.get('Ref.', '')
                g_en = g_row.get('English (ESV)', '')
                g_cn = g_row.get('Chinese', '')
                g_syn = g_row.get('Syn/Ant', '')
                g_grammar = g_row.get('Grammar', '')
                
                if g_ref and g_en:
                    all_grammar.append(f"<b>{g_ref}</b>{g_en}")
                elif g_en:
                    all_grammar.append(g_en)
                
                if g_cn:
                    all_grammar.append(g_cn)
                
                if g_syn:
                    syn_ant_html = ""
                    syn_text = ""
                    ant_text = ""
                    
                    if 'Syn:' in g_syn or 'Ant:' in g_syn:
                        syn_match = re.search(r'Syn:\s*([^/;]+?)(?=\s*Ant:|$)', g_syn)
                        ant_match = re.search(r'Ant:\s*([^/;]+)', g_syn)
                        if syn_match:
                            syn_text = syn_match.group(1).strip()
                        if ant_match:
                            ant_text = ant_match.group(1).strip()
                    else:
                        parts = re.split(r'[/|]', g_syn)
                        if len(parts) >= 2:
                            syn_text = parts[0].strip()
                            ant_text = parts[1].strip()
                        else:
                            syn_text = g_syn.strip()
                    
                    if syn_text:
                        syn_ant_html += f'<span style="color:#2E8B57;">âœ¨Syn:{syn_text}</span>'
                    if ant_text:
                        if syn_text:
                            syn_ant_html += ' '
                        syn_ant_html += f'<span style="color:#CD5C5C;">â„ï¸Ant:{ant_text}</span>'
                    
                    if syn_ant_html:
                        all_grammar.append(syn_ant_html)
                
                if g_grammar:
                    text = str(g_grammar)
                    text = re.sub(r'\\?\*\s+', 'â€¢ ', text)
                    text = text.replace('1ï¸âƒ£[', '1ï¸âƒ£[')
                    text = text.replace('2ï¸âƒ£[', '<br>2ï¸âƒ£[')
                    text = text.replace('3ï¸âƒ£[', '<br>3ï¸âƒ£[')
                    text = text.replace('4ï¸âƒ£[', '<br>4ï¸âƒ£[')
                    text = text.replace('\n', '<br>')
                    all_grammar.append(text)
                
                v2_jp = v2_row.get('å£èªè¨³', '') if v2_row else ''
                v2_grammar = v2_row.get('Grammar', '') if v2_row else ''
                v2_note = v2_row.get('Note', '') if v2_row else ''
                
                if v2_jp:
                    v2_parts = ["<br>"]
                    v2_ref = v2_row.get('Ref.', g_ref) if v2_row else g_ref
                    v2_parts.append(f"<b>{v2_ref}</b>{v2_jp}")
                    
                    if v2_grammar:
                        v2_parts.append(f'<span style="color:#4682B4;">æ–‡æ³•ï¼š</span>{v2_grammar}')
                    if v2_note:
                        v2_parts.append(f'<span style="color:#D2691E;">å‚™è¨»ï¼š</span>{v2_note}')
                    
                    all_grammar.append("<br>".join(v2_parts))
                    
            else:
                orig = (g_row.get('Original Sentence (from text)', '') or 
                        g_row.get('Original Sentence', ''))
                rule = g_row.get('Grammar Rule', '')
                analysis = (g_row.get('Analysis & Example (1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£4ï¸âƒ£)', '') or
                           g_row.get('Analysis & Example', '') or
                           g_row.get('Analysis', ''))
                
                html_parts = []
                
                if orig:
                    html_parts.append(
                        f'<div style="margin-bottom:2px; color:#FFD700; font-size:15px; font-weight:bold;">'
                        f'{orig}</div>'
                    )
                
                if analysis:
                    af = str(analysis).strip()
                    
                    if rule:
                        af = af.replace('1ï¸âƒ£', f'ğŸ“Œ {rule}<br>1ï¸âƒ£', 1)
                    
                    af = af.replace(
                        '1ï¸âƒ£**[åˆ†æ®µè§£æ+èªæ³•æ¨™ç±¤]**ï¼š',
                        '<div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">1ï¸âƒ£[åˆ†æ®µè§£æ+èªæ³•æ¨™ç±¤]ï¼š</span>'
                    )
                    af = af.replace(
                        '2ï¸âƒ£**[è©æ€§è¾¨æ]**ï¼š',
                        '</div><div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">2ï¸âƒ£[è©æ€§è¾¨æ]ï¼š</span>'
                    )
                    af = af.replace(
                        '3ï¸âƒ£**[ä¿®è¾­èˆ‡çµæ§‹]**ï¼š',
                        '</div><div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">3ï¸âƒ£[ä¿®è¾­èˆ‡çµæ§‹]ï¼š</span>'
                    )
                    af = af.replace(
                        '4ï¸âƒ£**[èªæ„è§£é‡‹]**ï¼š',
                        '</div><div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">4ï¸âƒ£[èªæ„è§£é‡‹]ï¼š</span>'
                    )
                    
                    af = af.replace(
                        '1ï¸âƒ£[åˆ†æ®µè§£æ+èªæ³•æ¨™ç±¤]ï¼š',
                        '<div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">1ï¸âƒ£[åˆ†æ®µè§£æ+èªæ³•æ¨™ç±¤]ï¼š</span>'
                    )
                    af = af.replace(
                        '2ï¸âƒ£[è©æ€§è¾¨æ]ï¼š',
                        '</div><div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">2ï¸âƒ£[è©æ€§è¾¨æ]ï¼š</span>'
                    )
                    af = af.replace(
                        '3ï¸âƒ£[ä¿®è¾­èˆ‡çµæ§‹]ï¼š',
                        '</div><div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">3ï¸âƒ£[ä¿®è¾­èˆ‡çµæ§‹]ï¼š</span>'
                    )
                    af = af.replace(
                        '4ï¸âƒ£[èªæ„è§£é‡‹]ï¼š',
                        '</div><div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">4ï¸âƒ£[èªæ„è§£é‡‹]ï¼š</span>'
                    )
                    
                    af = af + '</div>'
                    
                    html_parts.append(af)
                
                all_grammar = html_parts
                
            if all_grammar:
                grammar_html = "<br>".join(all_grammar)        
                
        # æ¸²æŸ“ç•«é¢
        col_left, col_right = st.columns([0.67, 0.33])
        
        with col_left:
            if vocab_display:
                st.markdown(
                    "<div style='margin-bottom:4px; line-height:1.6;'>" + 
                    " ; ".join(vocab_display) + 
                    "</div>", 
                    unsafe_allow_html=True
                )
            else:
                st.caption("ç„¡å–®å­—è³‡æ–™ï¼ˆè«‹ç¢ºèªæœ‰æ¨¡å¼Aè³‡æ–™ï¼‰")
            
            st.markdown("<hr style='margin:6px 0;'>", unsafe_allow_html=True)

            if w_phrases:
                for i, row in enumerate(w_phrases):
                    p = (row.get('Word/Phrase', '') or 
                         row.get('Word/phrase', '') or 
                         row.get('words/phrases', '') or 
                         row.get('Word', '') or
                         row.get('No', ''))
                    
                    c = (row.get('Chinese', '') or 
                         row.get('Chinese Meaning', '') or
                         row.get('Meaning', ''))
                    
                    s = (row.get('Synonym+ä¸­æ–‡å°ç…§', '') or 
                         row.get('Synonym', '') or 
                         row.get('Syn', ''))
                    
                    a = (row.get('Antonym+ä¸­æ–‡å°ç…§', '') or 
                         row.get('Antonym', '') or 
                         row.get('Ant', ''))
                    
                    bible_ex = (row.get('å…¨å¥è–ç¶“ä¸­è‹±å°ç…§ä¾‹å¥', '') or 
                               row.get('Bible Example', '') or 
                               row.get('Example', '') or
                               row.get('å…¨å¥è–ç¶“ä¸­è‹±å°ç…§ä¾‹å¥ ', ''))
                    
                    if p and p != str(i+16):
                        parts = [f"ğŸ”¤ **{p}**"]
                        if c: 
                            parts.append(f"<span style='color:#666;'>{c}</span>")
                        if s or a:
                            sa_parts = []
                            if s: 
                                sa_parts.append(f"<span style='color:#2E8B57;'>âœ¨{s}</span>")
                            if a: 
                                sa_parts.append(f"<span style='color:#CD5C5C;'>â„ï¸{a}</span>")
                            parts.append("<span style='font-size:0.9em;'>" + " | ".join(sa_parts) + "</span>")
                        
                        st.markdown(
                            "<div style='margin-bottom:2px;'>" + " ".join(parts) + "</div>", 
                            unsafe_allow_html=True
                        )
                        
                        if bible_ex:
                            match = re.match(r'([^(]+)(\([^)]+\))?$', bible_ex)
                            if match:
                                eng_part = match.group(1).strip()
                                cn_part = match.group(2) if match.group(2) else ""
                                bible_html = f"<span style='font-size:1.15em; font-weight:500;'>{eng_part}</span> <span style='font-size:0.9em; color:#666;'>{cn_part}</span>"
                            else:
                                bible_html = f"<span style='font-size:1.15em;'>{bible_ex}</span>"
                            
                            st.markdown(
                                f"<div style='margin-bottom:4px; margin-left:20px;'>ğŸ“– {bible_html}</div>", 
                                unsafe_allow_html=True
                            )
                        
                        if i < len(w_phrases) - 1:
                            st.markdown("<div style='margin:4px 0;'></div>", unsafe_allow_html=True)
            else:
                st.caption(f"ç„¡ç‰‡èªè³‡æ–™ï¼ˆæ¨¡å¼B={len(all_mode_b)}å€‹ï¼‰")
                if all_mode_b:
                    for mb in all_mode_b:
                        st.caption(f"  - {mb['ref']}: {mb['w_count']}ç­†")

            st.markdown("<hr style='margin:6px 0;'>", unsafe_allow_html=True)

            if verse_lines:
                st.markdown(f"<div style='margin-bottom:4px;'>{verse_lines[0]}</div>", unsafe_allow_html=True)
                for v in verse_lines[1:]:
                    st.markdown(f"<div style='margin-bottom:2px;'>{v}</div>", unsafe_allow_html=True)
            else:
                st.caption("ğŸ“– ç„¡é‡‘å¥è³‡æ–™ï¼ˆè«‹ç¢ºèªæœ‰æ¨¡å¼Aè³‡æ–™ï¼‰")

        with col_right:
            st.markdown(f"""
                <div style="background-color:#1E1E1E; color:#FFFFFF; padding:10px; border-radius:8px; 
                            border-left:4px solid #FF8C00; font-size:13px; line-height:1.5; 
                            min-height:100%; display:flex; flex-direction:column;">
                    {grammar_html}
                </div>
                """, unsafe_allow_html=True)
            
            minutes_left = max(0, (3600 - time_diff) / 60)
            st.caption(f"å–®å­—:{current_vocab_ref} | ç‰‡èª:{current_phrase_ref} | é‡‘å¥:{current_verse_ref}")
            st.caption(f"æ–‡æ³•:{current_grammar_ref} | {minutes_left:.0f}åˆ†å¾Œæ›´æ–°")
            st.caption(f"è³‡æ–™çµ±è¨ˆ: A={len(all_mode_a)}å€‹, B={len(all_mode_b)}å€‹, æ–‡æ³•æº={len(all_grammar_sources)}å€‹")

# ===================================================================
# 4. TAB2 â”€ æœˆæ›†å¾…è¾¦ + æ™‚æ®µé‡‘å¥ + æ”¶è—é‡‘å¥ï¼ˆä¿®æ­£ç‰ˆï¼‰
# ===================================================================
with tabs[1]:
    import datetime as dt, re, os, json
    from streamlit_calendar import calendar
    from io import StringIO
    import csv

    # ç¢ºä¿è³‡æ–™å·²è¼‰å…¥
    if 'sentences' not in st.session_state:
        st.session_state.sentences = load_sentences()
    if 'todo' not in st.session_state:
        st.session_state.todo = load_todos()
    if 'favorite_sentences' not in st.session_state:
        st.session_state.favorite_sentences = load_favorites()
    if 'sel_date' not in st.session_state:
        st.session_state.sel_date = str(dt.date.today())
    if 'cal_key' not in st.session_state:
        st.session_state.cal_key = 0
    if 'active_del_id' not in st.session_state:
        st.session_state.active_del_id = None
    if 'active_fav_del' not in st.session_state:
        st.session_state.active_fav_del = None

    # å…¨å±€CSSï¼šå£“ç¸®æ‰€æœ‰é–“è·
    st.markdown("""
        <style>
        div[data-testid="stVerticalBlock"] > div {padding: 0px !important; margin: 0px !important;}
        div[data-testid="stVerticalBlock"] > div > div {padding: 0px !important; margin: 0px !important;}
        p {margin: 0px !important; padding: 0px !important; line-height: 1.2 !important;}
        .stMarkdown {margin: 0px !important; padding: 0px !important;}
        .stButton button {padding: 0px 4px !important; min-height: 24px !important; font-size: 12px !important; margin: 0px !important;}
        hr {margin: 2px 0 !important; padding: 0 !important;}
        div[data-testid="stExpander"] {margin: 2px 0 !important;}
        div[data-testid="stExpander"] > div {padding: 0px 8px !important;}
        div[data-testid="column"] {padding: 0px 2px !important;}
        </style>
    """, unsafe_allow_html=True)

    # ---------- 2. æœˆæ›† ----------
    def build_events():
        ev = []
        for d, items in st.session_state.todo.items():
            if isinstance(items, list):
                for t in items:
                    ev.append({
                        "title": t.get("title", ""),
                        "start": f"{d}T{t.get('time','00:00:00')}",
                        "backgroundColor": "#FFE4E1",
                        "borderColor": "#FFE4E1",
                        "textColor": "#333"
                    })
        return ev

    with st.expander("ğŸ“… è–ç¶“å­¸ç¿’ç”Ÿæ´»æœˆæ›†", expanded=True):
        cal_options = {
            "headerToolbar": {"left": "prev,next today", "center": "title", "right": ""},
            "initialView": "dayGridMonth",
            "displayEventTime": False,
            "height": "auto"
        }
        state = calendar(events=build_events(), options=cal_options, key=f"cal_{st.session_state.cal_key}")
        if state.get("dateClick"):
            st.session_state.sel_date = state["dateClick"]["date"][:10]
            st.rerun()

    # ---------- 3. å¾…è¾¦æ¸…å–® ----------
    st.markdown('<p style="margin:0;padding:0;font-size:14px;font-weight:bold;">ğŸ“‹ å¾…è¾¦äº‹é …</p>', unsafe_allow_html=True)

    try:
        selected_date = dt.datetime.strptime(st.session_state.sel_date, "%Y-%m-%d").date()
    except:
        selected_date = dt.date.today()

    d_str = str(selected_date)
    has_todo = False
    
    if d_str in st.session_state.todo and st.session_state.todo[d_str]:
        has_todo = True
        
        for idx, item in enumerate(st.session_state.todo[d_str]):
            item_id = f"{d_str}_{idx}"
            title = item.get("title", "") if isinstance(item, dict) else str(item)
            time_str = item.get('time', '')[:5] if isinstance(item, dict) and item.get('time') else ""

            c1, c2, c3 = st.columns([0.3, 8, 1.2])
            
            with c1:
                if st.button("ğŸ’Ÿ", key=f"h_{item_id}"):
                    st.session_state.active_del_id = None if st.session_state.active_del_id == item_id else item_id
                    st.rerun()

            with c2:
                st.markdown(f'<p style="margin:0;padding:0;line-height:1.2;font-size:13px;">{time_str} {title}</p>', unsafe_allow_html=True)

            with c3:
                if st.session_state.active_del_id == item_id:
                    if st.button("ğŸ—‘ï¸", key=f"d_{item_id}"):
                        st.session_state.todo[d_str].pop(idx)
                        if not st.session_state.todo[d_str]:
                            del st.session_state.todo[d_str]
                        save_todos()
                        st.session_state.cal_key += 1
                        st.session_state.active_del_id = None
                        st.rerun()
            st.markdown('<div style="height:1px;"></div>', unsafe_allow_html=True)
    
    if not has_todo:
        st.caption(f"{selected_date.month}/{selected_date.day} å°šç„¡å¾…è¾¦äº‹é …")
        
    # ---------- 4. æ–°å¢å¾…è¾¦ ----------
    with st.expander("â• æ–°å¢å¾…è¾¦", expanded=False):
        with st.form("todo_form", clear_on_submit=True):
            c1, c2 = st.columns(2)
            with c1:
                in_date = st.date_input("æ—¥æœŸ", selected_date)
            with c2:
                in_time = st.time_input("æ™‚é–“", dt.time(9, 0))
            in_title = st.text_input("å¾…è¾¦äº‹é …ï¼ˆå¯å« Emojiï¼‰")
            
            if st.form_submit_button("ğŸ’¾ å„²å­˜"):
                if in_title:
                    k = str(in_date)
                    if k not in st.session_state.todo:
                        st.session_state.todo[k] = []
                    st.session_state.todo[k].append({"title": in_title, "time": str(in_time)})
                    save_todos()
                    st.session_state.cal_key += 1
                    st.rerun()
    
    # ---------- 5. æ™‚æ®µé‡‘å¥ ----------
    st.markdown('<p style="margin:0;padding:0;font-size:14px;font-weight:bold;">ğŸ“– ä»Šæ—¥æ™‚æ®µé‡‘å¥</p>', unsafe_allow_html=True)
    
    sentences = st.session_state.sentences
    all_verses = []
    
    for ref, data in sentences.items():
        v1_content = data.get('v1_content', '')
        v2_content = data.get('v2_content', '')
        if v1_content and v1_content.strip():
            try:
                def parse_to_list(content):
                    content = content.strip()
                    if not content: return []
                    if content.startswith('|'):
                        lines = [l.strip() for l in content.split('\n') if l.strip()]
                        if len(lines) < 3: return []
                        headers = [h.strip() for h in lines[0].split('|') if h.strip()]
                        data_rows = []
                        for l in lines[2:]:
                            cols = [c.strip() for c in l.split('|') if c.strip()]
                            if len(cols) == len(headers):
                                data_rows.append(dict(zip(headers, cols)))
                        return data_rows
                    else:
                        reader = csv.DictReader(StringIO(content))
                        return list(reader)

                v1_rows = parse_to_list(v1_content)
                v2_rows = parse_to_list(v2_content) if v2_content else []
                
                for i, row in enumerate(v1_rows):
                    v2_row = v2_rows[i] if i < len(v2_rows) else {}
                    verse_ref = row.get('Ref.', row.get('Ref', ref))
                    en = row.get('English (ESV)', row.get('English', row.get('ESV', '')))
                    cn = row.get('Chinese', row.get('Chinese (CUV)', row.get('CUV', '')))
                    jp = v2_row.get('å£èªè¨³ (1955)', v2_row.get('å£èªè¨³', '')) if v2_row else ''
                    kr = v2_row.get('KRF', '') if v2_row else ''
                    th = v2_row.get('THSV11 (Key Phrases)', v2_row.get('THSV11', '')) if v2_row else ''
                    
                    # åªåŠ å…¥æœ‰å…§å®¹çš„ç¶“æ–‡
                    if (en and str(en).strip()) or (cn and str(cn).strip()):
                        all_verses.append({
                            'ref': verse_ref,
                            'en': en if en else '',
                            'jp': jp if jp else '',
                            'kr': kr if kr else '',
                            'th': th if th else '',
                            'cn': cn if cn else ''
                        })
            except Exception as e:
                pass

    hour = dt.datetime.now().hour
    
    if 7 <= hour < 11:
        period_name, period_idx = "æ—©æ™¨ 7-11", 0
    elif 11 <= hour < 15:
        period_name, period_idx = "åˆé–“ 11-15", 1
    elif 15 <= hour < 19:
        period_name, period_idx = "ä¸‹åˆ 15-19", 2
    elif 19 <= hour < 23:
        period_name, period_idx = "æ™šé–“ 19-23", 3
    else:
        period_name, period_idx = "æ·±å¤œ", -1

    st.markdown(f'<p style="margin:0;padding:0;font-size:11px;color:#FF8C00;">â° {period_name}</p>', unsafe_allow_html=True)

    if all_verses and period_idx >= 0:
        total = len(all_verses)
        start = (period_idx * 6) % total
        
        for i in range(6):
            idx = (start + i) % total
            v = all_verses[idx]
            
            line1_parts = []
            if v['en']: 
                line1_parts.append(f"ğŸ‡¬ğŸ‡§ <b>{v['ref']}</b> {v['en']}")
            if v['jp']: 
                line1_parts.append(f"ğŸ‡¯ğŸ‡µ {v['jp']}")
            if v['kr']: 
                line1_parts.append(f"ğŸ‡°ğŸ‡· {v['kr']}")
            if v['th']: 
                line1_parts.append(f"ğŸ‡¹ğŸ‡­ {v['th']}")
            
            line2 = f"ğŸ‡¨ğŸ‡³ <span style='color:#999;'>{v['cn']}</span>" if v['cn'] else ""
            
            if line1_parts:
                st.markdown(f'<p style="margin:0;padding:0;font-size:12px;line-height:1.1;"><b>{i+1}.</b> {" ".join(line1_parts)}</p>', unsafe_allow_html=True)
            if line2:
                st.markdown(f'<p style="margin:0;padding:0;font-size:12px;line-height:1.1;margin-left:14px;">{line2}</p>', unsafe_allow_html=True)
            
            if i < 5:
                st.markdown('<hr style="margin:1px 0;border:none;border-top:1px solid #eee;">', unsafe_allow_html=True)
    else:
        st.caption("å°šç„¡é‡‘å¥è³‡æ–™")

    # ---------- 6. æ”¶è—é‡‘å¥ ----------
    st.markdown('<p style="margin:0;padding:0;font-size:14px;font-weight:bold;">ğŸ”½ æ”¶è—é‡‘å¥</p>', unsafe_allow_html=True)

    for idx, fav in enumerate(st.session_state.favorite_sentences[:8]):
        fav_id = f"fav_{idx}"
        c1, c2, c3 = st.columns([0.3, 8.5, 1.2])
        
        with c1:
            if st.button("ğŸ’", key=f"favh_{fav_id}"):
                st.session_state.active_fav_del = None if st.session_state.active_fav_del == fav_id else fav_id
                st.rerun()
        
        with c2:
            st.markdown(f'<p style="margin:0;padding:0;font-size:12px;line-height:1.2;">{fav}</p>', unsafe_allow_html=True)
        
        with c3:
            if st.session_state.active_fav_del == fav_id:
                if st.button("ğŸ—‘ï¸", key=f"favd_{fav_id}"):
                    st.session_state.favorite_sentences.pop(idx)
                    save_favorites()
                    st.session_state.active_fav_del = None
                    st.rerun()
        st.markdown('<div style="height:1px;"></div>', unsafe_allow_html=True)

    if len(st.session_state.favorite_sentences) < 8:
        with st.form("add_fav", clear_on_submit=True):
            new_fav = st.text_area("æ–°å¢æ”¶è—", height=50)
            if st.form_submit_button("â• åŠ å…¥"):
                if new_fav:
                    st.session_state.favorite_sentences.append(new_fav)
                    save_favorites()
                    st.rerun()

    st.caption(f"æ”¶è—: {len(st.session_state.favorite_sentences)}/8")

# ===================================================================
# 5. TAB3 â”€ æŒ‘æˆ°ï¼ˆç°¡åŒ–ç‰ˆï¼šç›´æ¥çµ¦é¡Œç›®ï¼Œæœ€å¾Œçµ¦ç­”æ¡ˆï¼‰
# ===================================================================
with tabs[2]:
    # ç¢ºä¿è³‡æ–™å·²è¼‰å…¥
    if 'sentences' not in st.session_state:
        st.session_state.sentences = load_sentences()
    
    sentences = st.session_state.sentences

    # éš±è— Streamlit å…ƒä»¶é è¨­çš„éå¤§é–“è·
    st.markdown("""
        <style>
            [data-testid="stVerticalBlock"] > div {
                gap: 0rem;
            }
            .stTextInput {
                margin-top: -15px !important;
                margin-bottom: 0px !important;
            }
        </style>
    """, unsafe_allow_html=True)

    if 'tab3_quiz_seed' not in st.session_state:
        st.session_state.tab3_quiz_seed = random.randint(1, 1000)
        st.session_state.tab3_show_answers = False
    
    if not sentences:
        st.warning("è³‡æ–™åº«ç‚ºç©ºï¼Œè«‹å…ˆåœ¨ TAB4 å„²å­˜è³‡æ–™")
    else:
        # æ’åºè³‡æ–™
        sorted_refs = sorted(sentences.keys(), 
                           key=lambda x: sentences[x].get('date_added', ''), 
                           reverse=True)
        total = len(sorted_refs)
        
        new_refs = sorted_refs[:int(total*0.6)] if total >= 5 else sorted_refs
        mid_refs = sorted_refs[int(total*0.6):int(total*0.9)] if total >= 10 else []
        old_refs = sorted_refs[int(total*0.9):] if total >= 10 else []
        
        weighted_pool = (new_refs * 6) + (mid_refs * 3) + (old_refs * 1)
        if not weighted_pool:
            weighted_pool = sorted_refs
        
        random.seed(st.session_state.tab3_quiz_seed)
        
        # é›™ç›¸å®¹è§£æå‡½æ•¸
        def parse_v1_content(content):
            content = content.strip()
            if not content: return []
            if content.startswith('|'):
                lines = [l.strip() for l in content.split('\n') if l.strip()]
                if len(lines) < 3: return []
                headers = [h.strip() for h in lines[0].split('|') if h.strip()]
                data_rows = []
                for l in lines[2:]:
                    cols = [c.strip() for c in l.split('|') if c.strip()]
                    if len(cols) == len(headers):
                        data_rows.append(dict(zip(headers, cols)))
                return data_rows
            else:
                return list(csv.DictReader(StringIO(content)))

        # æ”¶é›†ç¶“æ–‡
        all_verses = []
        for ref in weighted_pool[:20]:  # å¢åŠ å–æ¨£æ•¸é‡
            data = sentences[ref]
            v1_content = data.get('v1_content', '')
            if v1_content and v1_content.strip():
                try:
                    rows = parse_v1_content(v1_content)
                    for row in rows:
                        # ç¢ºä¿æœ‰å…§å®¹æ‰åŠ å…¥
                        chinese = row.get('Chinese', row.get('Chinese (CUV)', row.get('CUV', '')))
                        english = row.get('English (ESV)', row.get('English', row.get('ESV', '')))
                        
                        if (chinese and str(chinese).strip()) or (english and str(english).strip()):
                            all_verses.append({
                                'ref': row.get('Ref.', row.get('Ref', ref)),
                                'english': english if english else '',
                                'chinese': chinese if chinese else '',
                                'syn_ant': row.get('Syn/Ant', row.get('Syn/Ant.', ''))
                            })
                except Exception as e:
                    pass
        
        # ç¢ºä¿æœ‰è¶³å¤ çš„é¡Œç›®
        if len(all_verses) < 6:
            st.warning(f"è³‡æ–™åº«ä¸­åªæœ‰ {len(all_verses)} ç­†å¯ç”¨è³‡æ–™ï¼Œéœ€è¦è‡³å°‘ 6 ç­†æ‰èƒ½ç”ŸæˆæŒ‘æˆ°é¡Œ")
            st.stop()
        
        random.shuffle(all_verses)
        # ç¢ºä¿è‡³å°‘æœ‰3å€‹ä¸­ç¿»è‹±å’Œ3å€‹è‹±ç¿»ä¸­
        zh_to_en_candidates = [v for v in all_verses if v['chinese'] and str(v['chinese']).strip()]
        en_to_zh_candidates = [v for v in all_verses if v['english'] and str(v['english']).strip()]
        
        if len(zh_to_en_candidates) < 3 or len(en_to_zh_candidates) < 3:
            st.warning("å¯ç”¨è³‡æ–™ä¸è¶³ï¼Œè«‹ç¢ºä¿è³‡æ–™åŒ…å«ä¸­è‹±æ–‡å…§å®¹")
            st.stop()
        
        zh_to_en = zh_to_en_candidates[:3]
        en_to_zh = en_to_zh_candidates[:3]
        
        st.subheader("ğŸ“ ç¿»è­¯æŒ‘æˆ°")
        
        # é¡Œç›® 1-3ï¼šä¸­ç¿»è‹±
        for i, q in enumerate(zh_to_en, 1):
            st.markdown(f'<p style="margin: 0px; font-size: 14px; font-weight: bold;">{i}. {q["chinese"][:60]}</p>', unsafe_allow_html=True)
            st.text_input("", key=f"quiz_zh_en_{i}", placeholder="è«‹ç¿»è­¯æˆè‹±æ–‡...", label_visibility="collapsed")
            st.markdown('<div style="margin-bottom: 2px;"></div>', unsafe_allow_html=True)
        
        # é¡Œç›® 4-6ï¼šè‹±ç¿»ä¸­
        for i, q in enumerate(en_to_zh, 4):
            st.markdown(f'<p style="margin: 0px; font-size: 14px; font-weight: bold;">{i}. {q["english"][:100]}</p>', unsafe_allow_html=True)
            st.text_input("", key=f"quiz_en_zh_{i}", placeholder="è«‹ç¿»è­¯æˆä¸­æ–‡...", label_visibility="collapsed")
            st.markdown('<div style="margin-bottom: 2px;"></div>', unsafe_allow_html=True)
        
        # å–®å­—é¡Œ
        word_pool = []
        for v in all_verses:
            syn_ant = v.get('syn_ant', '')
            if '/' in syn_ant:
                for p in syn_ant.split('/'):
                    match = re.match(r'(.+?)\s*\((.+?)\)', p.strip())
                    if match:
                        word_pool.append({'en': match.group(1).strip(), 'cn': match.group(2).strip()})
        
        random.shuffle(word_pool)
        selected_words = word_pool[:3] if len(word_pool) >= 3 else word_pool
        
        for i, w in enumerate(selected_words, 7):
            st.markdown(f'<p style="margin: 0px; font-size: 14px; font-weight: bold;">{i}. {w["cn"]}ï¼ˆè«‹å¯«å‡ºè‹±æ–‡ï¼‰</p>', unsafe_allow_html=True)
            st.text_input("", key=f"quiz_word_{i}", placeholder="English word...", label_visibility="collapsed")
            st.markdown('<div style="margin-bottom: 2px;"></div>', unsafe_allow_html=True)
        
        # ç¿»çœ‹ç­”æ¡ˆ
        st.markdown('<div style="margin-top: 10px;"></div>', unsafe_allow_html=True)
        col_btn, col_answer = st.columns([1, 3])
        with col_btn:
            if st.button("ğŸ‘ï¸ ç¿»çœ‹æ­£ç¢ºç­”æ¡ˆ", use_container_width=True, type="primary"):
                st.session_state.tab3_show_answers = True
                st.rerun()
        
        with col_answer:
            if st.session_state.tab3_show_answers:
                with st.expander("ğŸ“– æ­£ç¢ºç­”æ¡ˆ", expanded=True):
                    st.markdown("**ä¸­ç¿»è‹±ï¼š**")
                    for i, q in enumerate(zh_to_en, 1):
                        st.caption(f"{i}. {q['english']}")
                    st.markdown("**è‹±ç¿»ä¸­ï¼š**")
                    for i, q in enumerate(en_to_zh, 4):
                        st.caption(f"{i}. {q['chinese']}")
                    st.markdown("**å–®å­—ï¼š**")
                    for i, w in enumerate(selected_words, 7):
                        st.caption(f"{i}. {w['en']}")
                             
                if st.button("ğŸ”„ æ›ä¸€æ‰¹é¡Œç›®", use_container_width=True):
                    st.session_state.tab3_quiz_seed = random.randint(1, 1000)
                    st.session_state.tab3_show_answers = False
                    st.rerun()

# ===================================================================
# 6. TAB4 â”€ AI æ§åˆ¶å°ï¼ˆå·²ç§»é™¤ Notionï¼Œæ”¹ç”¨ Google Sheetsï¼‰
# ===================================================================
with tabs[3]:
    # ç¢ºä¿è³‡æ–™å·²è¼‰å…¥
    if 'sentences' not in st.session_state:
        sheets_data = load_from_google_sheets()
        st.session_state.sentences = sheets_data if sheets_data else load_sentences()
    
    # Session State åˆå§‹åŒ–
    if 'search_results' not in st.session_state:
        st.session_state.search_results = []
    if 'is_prompt_generated' not in st.session_state:
        st.session_state.is_prompt_generated = False
    if 'main_input_value' not in st.session_state:
        st.session_state.main_input_value = ""
    if 'original_text' not in st.session_state:
        st.session_state.original_text = ""
    if 'content_mode' not in st.session_state:
        st.session_state.content_mode = ""
    if 'raw_input_value' not in st.session_state:
        st.session_state.raw_input_value = ""
    if 'ref_number' not in st.session_state:
        st.session_state.ref_number = ""
    if 'current_entry' not in st.session_state:
        st.session_state.current_entry = {
            'v1': '', 'v2': '', 'w_sheet': '', 
            'p_sheet': '', 'grammar_list': '', 'other': ''
        }
    if 'saved_entries' not in st.session_state:
        st.session_state.saved_entries = []
    if 'edit_mode' not in st.session_state:
        st.session_state.edit_mode = False
    if 'edit_ref' not in st.session_state:
        st.session_state.edit_ref = None

    # 1. æ™ºèƒ½åµæ¸¬å…§å®¹é¡å‹
    def detect_content_mode(text):
        text = text.strip()
        if not text:
            return "document"
        if text.startswith("{"):
            return "json"
        
        has_chinese = re.search(r'[\u4e00-\u9fa5]', text)
        return "scripture" if has_chinese else "document"

    # 2. ç”¢ç”Ÿå®Œæ•´æŒ‡ä»¤
    def generate_full_prompt():
        raw_text = st.session_state.get("raw_input_temp", "").strip()
        if not raw_text:
            st.warning("è«‹å…ˆè²¼ä¸Šå…§å®¹")
            return

        mode = detect_content_mode(raw_text)
        
        if mode in ["json", "scripture"]:
            full_prompt = f"""ä½ æ˜¯ä¸€ä½ç²¾é€šå¤šåœ‹èªè¨€çš„è–ç¶“å°ˆå®¶èˆ‡èªè¨€å­¸æ•™æˆã€‚è«‹æ ¹æ“šè¼¸å…¥å…§å®¹é¸æ“‡å°æ‡‰æ¨¡å¼è¼¸å‡ºã€‚
            æ‰€æœ‰ç¿»è­¯åš´æ ¼è¦å®šæŒ‰è–ç¶“èªè¨€ç¿»è­¯ï¼Œä¸å¯ç§è‡ªäº‚ç¿»è­¯

### æ¨¡å¼ Aï¼šã€è–ç¶“ç¶“æ–‡åˆ†ææ™‚ã€‘ï¼ã€‹ä¸€å®šè¦ç”¢å‡ºV1 + V2 Excelæ ¼å¼ï¼ˆMarkdownè¡¨æ ¼ï¼‰

âš ï¸ è¼¸å‡ºæ ¼å¼è¦æ±‚ï¼šè«‹ä½¿ç”¨ **Markdown è¡¨æ ¼æ ¼å¼**ï¼ˆå¦‚ä¸‹ç¯„ä¾‹ï¼‰ï¼Œæ–¹ä¾¿æˆ‘ç›´æ¥è¤‡è£½è²¼å› Excelï¼š

ã€V1 Sheet ç¯„ä¾‹ã€‘
| Ref. | English (ESV) | Chinese | Syn/Ant | Grammar |
|------|---------------|---------|---------|---------|
| Pro 31:6 | Give strong drink... | å¯ä»¥æŠŠæ¿ƒé…’... | strong drink (çƒˆé…’) / watered down wine (æ·¡é…’) | 1ï¸âƒ£[åˆ†æ®µè§£æ+èªæ³•æ¨™ç±¤]...<br>2ï¸âƒ£[è©æ€§è¾¨æ]...<br>3ï¸âƒ£[ä¿®è¾­èˆ‡çµæ§‹æˆ–éé€²é‚è¼¯]...<br>4ï¸âƒ£[èªæ„è§£é‡‹]...<br>...|

ã€V2 Sheet ç¯„ä¾‹ã€‘
| Ref. | å£èªè¨³ | Grammar | Note | KRF | Syn/Ant | THSV11 |
|------|--------|---------|------|-----|---------|--------|

ğŸ”¹ V1 Sheet æ¬„ä½è¦æ±‚ï¼š
1. Ref.ï¼šè‡ªå‹•æ‰¾å°‹ç¶“å·ç« ç¯€ä¸¦ç”¨ç¸®å¯« (å¦‚: Pro, Rom, Gen).
2. English (ESV)ï¼šæª¢ç´¢å°æ‡‰çš„ ESV è‹±æ–‡ç¶“æ–‡.
3. Chineseï¼šå¡«å…¥æˆ‘æä¾›çš„ä¸­æ–‡åŸæ–‡.
4. Syn/Antï¼š"åŒç¾©å­—èˆ‡åç¾©å­—"ï¼Œå–è‡ªESVä¸­çš„é«˜ç´š/ä¸­é«˜ç´šå–®å­—æˆ–ç‰‡èªï¼ˆå«ä¸­/è‹±ç¿»è­¯ï¼‰
5. Grammarï¼šåš´æ ¼éµå®ˆç¬¦è™ŸåŒ–æ ¼å¼ï¼‹åš´æ ¼æä¾›è©³ç´°è¦ç¯„...

ğŸ”¹ V2 Sheet æ¬„ä½è¦æ±‚ï¼š
1. Ref.ï¼šåŒ V1.
2. å£èªè¨³ï¼šæª¢ç´¢å°æ‡‰çš„æ—¥æœ¬ã€Šå£èªè¨³è–ç¶“ã€‹(1955).
3. Grammaræ ¼å¼åŒ V1
4. Noteï¼šæ—¥æ–‡æ–‡æ³•æˆ–èªå¢ƒçš„è£œå……èªªæ˜.
5. KRFï¼šæª¢ç´¢å°æ‡‰çš„éŸ“æ–‡ã€ŠKorean Revised Versionã€‹.
6. Syn/Antï¼šéŸ“æ–‡é«˜/ ä¸­é«˜ç´šå­—ï¼ˆå«æ—¥/éŸ“/ä¸­ç¿»è­¯ï¼‰.
7. THSV11:è¼¸å‡ºæ³°æ–‡"å°æ‡‰çš„é‡è¦ç‰‡èªkey phrases"ã€ŠThai Holy Bible, Standard Version 2011ã€‹.

è«‹ä»¥ **Markdown è¡¨æ ¼æ ¼å¼**è¼¸å‡ºï¼ˆé JSONï¼‰.

å¾…åˆ†æç¶“æ–‡ï¼š{raw_text}"""
            st.session_state.content_mode = "A"
        else:
            full_prompt = f"""ä½ æ˜¯ä¸€ä½ç²¾é€šå¤šåœ‹èªè¨€çš„è–ç¶“å°ˆå®¶èˆ‡èªè¨€å­¸æ•™æˆ.

### æ¨¡å¼ Bï¼šã€è‹±æ–‡æ–‡ç¨¿åˆ†ææ™‚ã€‘ï¼ã€‹ä¸€å®šè¦ç”¢å‡ºWï¼‹P Excelæ ¼å¼ï¼ˆMarkdownè¡¨æ ¼ï¼‰
ä¸€å®šè¦å–è¶³"é«˜ç´š/ä¸­é«˜ç´šå–®å­—15å€‹ï¼‹ç‰‡èª15å€‹"ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼
âš ï¸ è¼¸å‡ºæ ¼å¼è¦æ±‚ï¼šè«‹ä½¿ç”¨ **Markdown è¡¨æ ¼æ ¼å¼**ï¼š

 ã€W Sheet - é‡é»è¦æ±‚ï¼šå–é«˜ç´š/ä¸­é«˜ç´šå–®å­—15å€‹ï¼‹ç‰‡èª15å€‹ã€‘
| No | Word/Phrase| Chinese | Synonym+ä¸­æ–‡å°ç…§ | Antonymï¼‹ä¸­æ–‡å°ç…§ | å…¨å¥è–ç¶“ä¸­è‹±å°ç…§ä¾‹å¥ |
|----|-------------|-------|---------|---------|---------|---------------|
| 1 | steadfast å …å®šä¸ç§»çš„ | firm | wavering | 1Co 15:58 Therefore... |

ã€P Sheet - æ–‡ç¨¿æ®µè½ã€‘
| Paragraph | English Refinement | ä¸­è‹±å¤¾é›œè¬›ç«  |
|-----------|-------------------|--------------|
| 1 | We need to be steadfast... | æˆ‘å€‘éœ€è¦ (**steadfast**) ... |

ã€Grammar List - é‡é»è¦æ±‚ï¼š6 å¥ Ã— æ¯å¥4å€‹è§£æã€‘
| No | Original Sentence (from text) | Grammar Rule | Analysis & Example (1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£...5ï¸âƒ£) |
|----|------------------------------|--------------|-----------------------------------|
| 1 | [æ–‡ç¨¿ä¸­çš„ç¬¬1å€‹ç²¾é¸å¥] | [æ–‡æ³•è¦å‰‡åç¨±] | 1ï¸âƒ£[åˆ†æ®µè§£æ+èªæ³•æ¨™ç±¤]...<br>2ï¸âƒ£[è©æ€§è¾¨æ]...<br>3ï¸âƒ£[ä¿®è¾­èˆ‡çµæ§‹æˆ–éé€²é‚è¼¯]...<br>4ï¸âƒ£[èªæ„è§£é‡‹]...<br>...|

å¾…åˆ†ææ–‡ç¨¿ï¼š{raw_text}"""
            st.session_state.content_mode = "B"

        st.session_state.original_text = raw_text
        st.session_state.main_input_value = full_prompt
        st.session_state.is_prompt_generated = True
        st.session_state.ref_number = f"REF_{dt.datetime.now().strftime('%m%d%H%M')}"
        st.session_state.current_entry = {
            'v1': '', 'v2': '', 'w_sheet': '', 
            'p_sheet': '', 'grammar_list': '', 'other': ''
        }
        st.session_state.saved_entries = []

    # å¿«é€ŸåŠŸèƒ½å€
    st.markdown("<h6>âš¡ å¿«é€ŸåŠŸèƒ½</h6>", unsafe_allow_html=True)
    
    quick_cols = st.columns([1, 1, 2])
    
    with quick_cols[0]:
        with st.expander("â• å»ºç«‹ç©ºç™½è³‡æ–™", expanded=False):
            blank_mode = st.selectbox("é¸æ“‡æ¨¡å¼", ["Mode A (ç¶“æ–‡)", "Mode B (æ–‡ç¨¿)"], key="blank_mode")
            blank_ref = st.text_input("åƒè€ƒç·¨è™Ÿ", value=f"BLANK_{dt.datetime.now().strftime('%m%d%H%M')}", key="blank_ref")
            
            if st.button("ğŸ†• å»ºç«‹ç©ºç™½è³‡æ–™çµæ§‹", use_container_width=True):
                if "Mode A" in blank_mode:
                    blank_structure = {
                        "ref": blank_ref,
                        "original": "[ç©ºç™½è³‡æ–™-å¾…å¡«å…¥ç¶“æ–‡]",
                        "v1_content": "Ref.\tEnglish (ESV)\tChinese\tSyn/Ant\tGrammar\n",
                        "v2_content": "Ref.\tå£èªè¨³\tGrammar\tNote\tKRF\tSyn/Ant\tTHSV11\n",
                        "w_sheet": "",
                        "p_sheet": "",
                        "grammar_list": "",
                        "other": "",
                        "saved_sheets": ["V1 Sheet", "V2 Sheet"],
                        "type": "Scripture",
                        "mode": "A",
                        "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
                        "blank_template": True
                    }
                else:
                    blank_structure = {
                        "ref": blank_ref,
                        "original": "[ç©ºç™½è³‡æ–™-å¾…å¡«å…¥æ–‡ç¨¿]",
                        "v1_content": "",
                        "v2_content": "",
                        "w_sheet": "No\tWord/Phrase\tChinese\tSynonym+ä¸­æ–‡å°ç…§\tAntonym+ä¸­æ–‡å°ç…§\tå…¨å¥è–ç¶“ä¸­è‹±å°ç…§ä¾‹å¥\n",
                        "p_sheet": "Paragraph\tEnglish Refinement\tä¸­è‹±å¤¾é›œè¬›ç« \n",
                        "grammar_list": "No\tOriginal Sentence\tGrammar Rule\tAnalysis & Example\n",
                        "other": "",
                        "saved_sheets": ["W Sheet", "P Sheet", "Grammar List"],
                        "type": "Document",
                        "mode": "B",
                        "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
                        "blank_template": True
                    }
                
                st.session_state.sentences[blank_ref] = blank_structure
                save_sentences(st.session_state.sentences)
                
                if GC and SHEET_ID:
                    save_to_google_sheets(blank_structure)
                
                st.session_state.edit_mode = True
                st.session_state.edit_ref = blank_ref
                st.session_state.current_entry = {
                    'v1': blank_structure['v1_content'],
                    'v2': blank_structure['v2_content'],
                    'w_sheet': blank_structure['w_sheet'],
                    'p_sheet': blank_structure['p_sheet'],
                    'grammar_list': blank_structure['grammar_list'],
                    'other': ''
                }
                st.session_state.saved_entries = blank_structure['saved_sheets']
                st.success(f"âœ… å·²å»ºç«‹ç©ºç™½è³‡æ–™ï¼š{blank_ref}")
                st.rerun()
    
    with quick_cols[1]:
        with st.expander("âœï¸ ç·¨è¼¯ç¾æœ‰è³‡æ–™", expanded=False):
            if st.session_state.sentences:
                edit_select = st.selectbox(
                    "é¸æ“‡è¦ç·¨è¼¯çš„è³‡æ–™",
                    list(st.session_state.sentences.keys()),
                    format_func=lambda x: f"{x} ({st.session_state.sentences[x].get('type', 'Unknown')})",
                    key="edit_select"
                )
                
                if st.button("ğŸ“ è¼‰å…¥ç·¨è¼¯", use_container_width=True):
                    item = st.session_state.sentences[edit_select]
                    st.session_state.edit_mode = True
                    st.session_state.edit_ref = edit_select
                    st.session_state.current_entry = {
                        'v1': item.get('v1_content', ''),
                        'v2': item.get('v2_content', ''),
                        'w_sheet': item.get('w_sheet', ''),
                        'p_sheet': item.get('p_sheet', ''),
                        'grammar_list': item.get('grammar_list', ''),
                        'other': item.get('other', '')
                    }
                    st.session_state.saved_entries = item.get('saved_sheets', [])
                    st.rerun()
            else:
                st.info("å°šç„¡è³‡æ–™å¯ç·¨è¼¯")
    
    with quick_cols[2]:
        if st.session_state.get('edit_mode') and st.session_state.get('edit_ref'):
            st.info(f"ğŸ“ ç›®å‰æ­£åœ¨ç·¨è¼¯ï¼š**{st.session_state.edit_ref}**")
            if st.button("âŒ çµæŸç·¨è¼¯æ¨¡å¼", use_container_width=True):
                st.session_state.edit_mode = False
                st.session_state.edit_ref = None
                st.session_state.saved_entries = []
                st.session_state.current_entry = {
                    'v1': '', 'v2': '', 'w_sheet': '', 
                    'p_sheet': '', 'grammar_list': '', 'other': ''
                }
                st.rerun()
        else:
            st.caption("ğŸ’¡ ä½¿ç”¨å·¦å´æŒ‰éˆ•å¿«é€Ÿå»ºç«‹æˆ–ç·¨è¼¯è³‡æ–™")

    st.divider()

    # ç·¨è¼¯æ¨¡å¼ä»‹é¢
    if st.session_state.get('edit_mode') and st.session_state.get('edit_ref'):
        st.markdown(f"<h6>âœï¸ ç·¨è¼¯æ¨¡å¼ï¼š{st.session_state.edit_ref}</h6>", unsafe_allow_html=True)
        
        item = st.session_state.sentences.get(st.session_state.edit_ref, {})
        current_mode = item.get('mode', 'A')
        
        if current_mode == 'A':
            edit_tabs = st.tabs(["V1 Sheet", "V2 Sheet", "å…¶ä»–è£œå……", "å„²å­˜"])
            
            with edit_tabs[0]:
                new_v1 = st.text_area("V1 Sheet å…§å®¹", value=st.session_state.current_entry['v1'], height=300, key="edit_v1")
                st.session_state.current_entry['v1'] = new_v1
            
            with edit_tabs[1]:
                new_v2 = st.text_area("V2 Sheet å…§å®¹", value=st.session_state.current_entry['v2'], height=300, key="edit_v2")
                st.session_state.current_entry['v2'] = new_v2
            
            with edit_tabs[2]:
                new_other = st.text_area("å…¶ä»–è£œå……", value=st.session_state.current_entry['other'], height=200, key="edit_other")
                st.session_state.current_entry['other'] = new_other
            
            with edit_tabs[3]:
                st.write("ç¢ºèªä¿®æ”¹å¾Œå„²å­˜ï¼š")
                if st.button("ğŸ’¾ å„²å­˜è®Šæ›´", use_container_width=True, type="primary"):
                    updated_data = {
                        'v1_content': st.session_state.current_entry['v1'],
                        'v2_content': st.session_state.current_entry['v2'],
                        'other': st.session_state.current_entry['other'],
                        'saved_sheets': ['V1 Sheet', 'V2 Sheet'] if st.session_state.current_entry['v1'] else [],
                        'date_added': dt.datetime.now().strftime("%Y-%m-%d %H:%M")
                    }
                    st.session_state.sentences[st.session_state.edit_ref].update(updated_data)
                    save_sentences(st.session_state.sentences)
                    
                    if GC and SHEET_ID:
                        full_data = st.session_state.sentences[st.session_state.edit_ref]
                        save_to_google_sheets(full_data)
                    
                    st.success("âœ… å·²å„²å­˜ä¸¦åŒæ­¥åˆ°é›²ç«¯ï¼")
        else:
            edit_tabs = st.tabs(["W Sheet", "P Sheet", "Grammar List", "å…¶ä»–è£œå……", "å„²å­˜"])
            
            with edit_tabs[0]:
                new_w = st.text_area("W Sheet å…§å®¹", value=st.session_state.current_entry['w_sheet'], height=300, key="edit_w")
                st.session_state.current_entry['w_sheet'] = new_w
            
            with edit_tabs[1]:
                new_p = st.text_area("P Sheet å…§å®¹", value=st.session_state.current_entry['p_sheet'], height=300, key="edit_p")
                st.session_state.current_entry['p_sheet'] = new_p
            
            with edit_tabs[2]:
                new_g = st.text_area("Grammar List å…§å®¹", value=st.session_state.current_entry['grammar_list'], height=300, key="edit_g")
                st.session_state.current_entry['grammar_list'] = new_g
            
            with edit_tabs[3]:
                new_other = st.text_area("å…¶ä»–è£œå……", value=st.session_state.current_entry['other'], height=200, key="edit_other_b")
                st.session_state.current_entry['other'] = new_other
            
            with edit_tabs[4]:
                st.write("ç¢ºèªä¿®æ”¹å¾Œå„²å­˜ï¼š")
                if st.button("ğŸ’¾ å„²å­˜è®Šæ›´", use_container_width=True, type="primary"):
                    updated_data = {
                        'w_sheet': st.session_state.current_entry['w_sheet'],
                        'p_sheet': st.session_state.current_entry['p_sheet'],
                        'grammar_list': st.session_state.current_entry['grammar_list'],
                        'other': st.session_state.current_entry['other'],
                        'saved_sheets': ['W Sheet', 'P Sheet', 'Grammar List'],
                        'date_added': dt.datetime.now().strftime("%Y-%m-%d %H:%M")
                    }
                    st.session_state.sentences[st.session_state.edit_ref].update(updated_data)
                    save_sentences(st.session_state.sentences)
                    
                    if GC and SHEET_ID:
                        full_data = st.session_state.sentences[st.session_state.edit_ref]
                        save_to_google_sheets(full_data)
                    
                    st.success("âœ… å·²å„²å­˜ä¸¦åŒæ­¥åˆ°é›²ç«¯ï¼")
        
        st.divider()

    # ä¸»è¦åŠŸèƒ½å€
    st.markdown("<h6>ğŸ“ AI åˆ†æå·¥ä½œæµç¨‹</h6>", unsafe_allow_html=True)
    
    # STEP 1: è¼¸å…¥å€
    with st.expander("æ­¥é©Ÿ 1ï¼šè¼¸å…¥ç¶“æ–‡æˆ–æ–‡ç¨¿", expanded=not st.session_state.is_prompt_generated):
        raw_input = st.text_area(
            "åŸå§‹è¼¸å…¥",
            height=200,
            value=st.session_state.get('raw_input_value', ''),
            placeholder="è«‹åœ¨æ­¤è²¼ä¸Šå…§å®¹ï¼š\nâ€¢ ç¶“æ–‡æ ¼å¼ï¼š31:6 å¯ä»¥æŠŠæ¿ƒé…’çµ¦å°‡äº¡çš„äººå–...\nâ€¢ æ–‡ç¨¿æ ¼å¼ï¼šç›´æ¥è²¼ä¸Šè‹±æ–‡è¬›ç¨¿",
            label_visibility="collapsed",
            key="raw_input_temp"
        )
        
        if not st.session_state.is_prompt_generated:
            if st.button("âš¡ ç”¢ç”Ÿå®Œæ•´åˆ†ææŒ‡ä»¤", use_container_width=True, type="primary"):
                generate_full_prompt()
                st.rerun()

    # STEP 2: Prompt ç”¢ç”Ÿå¾Œé¡¯ç¤º
    if st.session_state.is_prompt_generated:
        with st.expander("æ­¥é©Ÿ 2ï¼šè¤‡è£½ Prompt åˆ° AI", expanded=False):
            st.caption("è¤‡è£½ä»¥ä¸‹å…§å®¹ï¼Œè²¼åˆ° GPT/Kimi/Gemini é€²è¡Œåˆ†æ")
            
            components.html(
                f"""
                <textarea
                    readonly
                    onclick="this.select()"
                    style="
                        width:100%;
                        height:250px;
                        padding:12px;
                        font-size:14px;
                        line-height:1.5;
                        border-radius:8px;
                        border:1px solid #ccc;
                        box-sizing:border-box;
                        background-color:#f8f9fa;
                    "
                >{st.session_state.get('main_input_value','')}</textarea>
                """,
                height=280
            )
            
            cols = st.columns(3)
            with cols[0]:
                encoded = urllib.parse.quote(st.session_state.get('main_input_value', ''))
                st.link_button("ğŸ’¬ é–‹å•Ÿ GPT", f"https://chat.openai.com/?q={encoded}", use_container_width=True)
            with cols[1]:
                st.link_button("ğŸŒ™ é–‹å•Ÿ Kimi", "https://kimi.com", use_container_width=True)
            with cols[2]:
                st.link_button("ğŸ” é–‹å•Ÿ Gemini", "https://gemini.google.com", use_container_width=True)

        # STEP 3: å¤šå·¥ä½œè¡¨æ”¶é›†å€
        with st.expander("æ­¥é©Ÿ 3ï¼šåˆ†æ‰¹è²¼ä¸Š AI åˆ†æçµæœ", expanded=True):
            st.info("ğŸ’¡ å¯ä»¥åˆ†æ‰¹è²¼ä¸Š V1ã€V2ã€W Sheetã€P Sheet ç­‰ï¼Œè²¼å¥½ä¸€å€‹å­˜ä¸€å€‹")
            
            if st.session_state.content_mode == "A":
                sheet_options = ["V1 Sheet", "V2 Sheet", "å…¶ä»–è£œå……"]
            else:
                sheet_options = ["W Sheet", "P Sheet", "Grammar List", "å…¶ä»–è£œå……"]
            
            selected_sheet = st.selectbox("é¸æ“‡è¦è²¼ä¸Šçš„å·¥ä½œè¡¨", sheet_options)
            
            sheet_content = st.text_area(f"è²¼ä¸Š {selected_sheet} å…§å®¹", height=200, key=f"input_{selected_sheet.replace(' ', '_')}")
            
            col_temp, col_view = st.columns([1, 3])
            with col_temp:
                if st.button("â• æš«å­˜æ­¤å·¥ä½œè¡¨", use_container_width=True):
                    key_map = {
                        "V1 Sheet": "v1", "V2 Sheet": "v2",
                        "W Sheet": "w_sheet", "P Sheet": "p_sheet",
                        "Grammar List": "grammar_list", "å…¶ä»–è£œå……": "other"
                    }
                    key = key_map.get(selected_sheet, 'other')
                    st.session_state.current_entry[key] = sheet_content
                    if selected_sheet not in st.session_state.saved_entries:
                        st.session_state.saved_entries.append(selected_sheet)
                    st.success(f"âœ… {selected_sheet} å·²æš«å­˜ï¼")
                    st.rerun()
            
            with col_view:
                if st.session_state.saved_entries:
                    st.write("ğŸ“‹ å·²æš«å­˜ï¼š", " | ".join([f"âœ… {s}" for s in st.session_state.saved_entries]))

        # STEP 4: çµ±ä¸€å„²å­˜å€
        with st.expander("æ­¥é©Ÿ 4ï¼šå„²å­˜åˆ°è³‡æ–™åº«", expanded=True):
            st.caption("ç¢ºèªæ‰€æœ‰å·¥ä½œè¡¨éƒ½æš«å­˜å¾Œï¼Œå¡«å¯«è³‡è¨Šä¸¦å„²å­˜")
            
            def get_default_ref():
                v1_content = st.session_state.current_entry.get('v1', '')
                if v1_content:
                    lines = v1_content.strip().split('\n')
                    for line in lines[1:]:
                        cols = line.split('\t')
                        if len(cols) > 0 and cols[0].strip():
                            return cols[0].strip()
                
                w_content = st.session_state.current_entry.get('w_sheet', '')
                if w_content:
                    lines = w_content.strip().split('\n')
                    for line in lines[1:]:
                        cols = line.split('\t')
                        if len(cols) > 0 and cols[0].strip():
                            return cols[0].strip()
                
                return f"REF_{dt.datetime.now().strftime('%m%d%H%M')}"
            
            st.markdown("**ğŸ“ æª”åï¼ˆå¯æ‰‹å‹•ä¿®æ”¹ï¼‰**")
            ref_input = st.text_input("Ref / æª”å", value=get_default_ref(), key="ref_no_input")
            
            type_select = st.selectbox("é¡å‹", ["Scripture", "Document", "Vocabulary", "Grammar", "Sermon"],
                                       index=0 if st.session_state.content_mode == "A" else 1, key="type_select")
            
            btn_cols = st.columns([1, 1])
            
            with btn_cols[0]:
                if st.button("ğŸ’¾ å„²å­˜åˆ°é›²ç«¯", use_container_width=True, type="primary"):
                    if not st.session_state.saved_entries:
                        st.error("è«‹å…ˆè‡³å°‘æš«å­˜ä¸€å€‹å·¥ä½œè¡¨ï¼")
                    else:
                        try:
                            ref = ref_input
                            full_data = {
                                "ref": ref,
                                "original": st.session_state.original_text,
                                "prompt": st.session_state.main_input_value,
                                "v1_content": st.session_state.current_entry['v1'],
                                "v2_content": st.session_state.current_entry['v2'],
                                "w_sheet": st.session_state.current_entry['w_sheet'],
                                "p_sheet": st.session_state.current_entry['p_sheet'],
                                "grammar_list": st.session_state.current_entry['grammar_list'],
                                "other": st.session_state.current_entry['other'],
                                "saved_sheets": st.session_state.saved_entries,
                                "type": type_select,
                                "mode": st.session_state.content_mode,
                                "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M")
                            }
                            
                            st.session_state.sentences[ref] = full_data
                            save_sentences(st.session_state.sentences)
                            
                            if GC and SHEET_ID:
                                success, msg = save_to_google_sheets(full_data)
                                if success:
                                    st.success(f"âœ… å·²åŒæ­¥åˆ° Google Sheetsï¼({msg})")
                                else:
                                    st.warning(f"âš ï¸ Google Sheets åŒæ­¥å¤±æ•—ï¼š{msg}ï¼Œä½†å·²å„²å­˜åˆ°æœ¬åœ°")
                            else:
                                st.warning("âš ï¸ Google Sheets æœªé€£ç·šï¼Œåƒ…å„²å­˜åˆ°æœ¬åœ°")
                            
                            st.balloons()
                            
                        except Exception as e:
                            st.error(f"âŒ å„²å­˜å¤±æ•—ï¼š{str(e)}")
            
            with btn_cols[1]:
                if st.button("ğŸ”„ æ–°çš„åˆ†æ", use_container_width=True):
                    keys_to_clear = ['is_prompt_generated', 'main_input_value', 'original_text',
                                   'content_mode', 'raw_input_value', 'ref_number', 'raw_input_temp',
                                   'current_entry', 'saved_entries', 'ref_no_input']
                    for key in keys_to_clear:
                        if key in st.session_state:
                            del st.session_state[key]
                    st.rerun()

    # å„²å­˜ç‹€æ…‹é¡¯ç¤ºå€
    st.divider()
    status_cols = st.columns([1, 1, 2])
    
    with status_cols[0]:
        total_local = len(st.session_state.get('sentences', {}))
        st.markdown(f"<p style='font-size: 12px; margin: 0; color: #666;'>ğŸ’¾ æœ¬åœ°å¿«å–</p>", unsafe_allow_html=True)
        st.markdown(f"<p style='font-size: 16px; font-weight: bold; margin: 0;'>{total_local} ç­†</p>", unsafe_allow_html=True)
    
    with status_cols[1]:
        if GC and SHEET_ID:
            st.markdown(f"<p style='font-size: 12px; margin: 0; color: #666;'>â˜ï¸ Google Sheets</p>", unsafe_allow_html=True)
            st.markdown(f"<p style='font-size: 16px; font-weight: bold; margin: 0; color: #28a745;'>âœ… å·²é€£ç·š</p>", unsafe_allow_html=True)
        else:
            st.markdown(f"<p style='font-size: 12px; margin: 0; color: #666;'>â˜ï¸ Google Sheets</p>", unsafe_allow_html=True)
            st.markdown(f"<p style='font-size: 16px; font-weight: bold; margin: 0; color: #dc3545;'>âŒ æœªé€£ç·š</p>", unsafe_allow_html=True)
    
    with status_cols[2]:
        if st.session_state.get('sentences'):
            recent = list(st.session_state.sentences.values())[-3:]
            st.markdown(f"<p style='font-size: 12px; margin: 0; color: #666;'>ğŸ• æœ€è¿‘å„²å­˜ï¼š</p>", unsafe_allow_html=True)
            for item in reversed(recent):
                sheets = item.get('saved_sheets', ['æœªçŸ¥'])
                st.caption(f"â€¢ {item.get('ref', 'N/A')} ({', '.join(sheets)})")

    # å·²å­˜è³‡æ–™ç€è¦½å™¨
    with st.expander("ğŸ“‹ æŸ¥çœ‹å·²å„²å­˜çš„è³‡æ–™", expanded=False):
        if not st.session_state.get('sentences'):
            st.info("è³‡æ–™åº«æ˜¯ç©ºçš„ï¼Œè«‹å…ˆå„²å­˜è³‡æ–™")
        else:
            ref_list = list(st.session_state.sentences.keys())
            selected_ref = st.selectbox("é¸æ“‡è³‡æ–™é …ç›®", ref_list,
                                        format_func=lambda x: f"{x} - {st.session_state.sentences[x].get('date_added', 'ç„¡æ—¥æœŸ')}")
            
            if selected_ref:
                item = st.session_state.sentences[selected_ref]
                st.subheader(f"ğŸ“„ {selected_ref}")
                
                cols = st.columns(3)
                with cols[0]:
                    st.write(f"**é¡å‹ï¼š** {item.get('type', 'N/A')}")
                with cols[1]:
                    st.write(f"**æ¨¡å¼ï¼š** {item.get('mode', 'N/A')}")
                with cols[2]:
                    st.write(f"**æ—¥æœŸï¼š** {item.get('date_added', 'N/A')}")
                
                with st.expander("ğŸ“ åŸå§‹è¼¸å…¥"):
                    st.text(item.get('original', 'ç„¡'))
                
                saved_sheets = item.get('saved_sheets', [])
                if saved_sheets:
                    st.write(f"**å·²å„²å­˜å·¥ä½œè¡¨ï¼š** {', '.join(saved_sheets)}")
                    tabs_sheets = st.tabs(saved_sheets)
                    for i, sheet in enumerate(saved_sheets):
                        with tabs_sheets[i]:
                            key_map = {"V1 Sheet": "v1_content", "V2 Sheet": "v2_content",
                                      "W Sheet": "w_sheet", "P Sheet": "p_sheet",
                                      "Grammar List": "grammar_list", "å…¶ä»–è£œå……": "other"}
                            content = item.get(key_map.get(sheet, 'other'), '')
                            if content:
                                st.text_area("å…§å®¹", value=content, height=250, disabled=True)
                            else:
                                st.info("ç„¡å…§å®¹")
                
                st.divider()
                btn_cols = st.columns([1, 1, 2])
                
                with btn_cols[0]:
                    if st.button("âœï¸ è¼‰å…¥ç·¨è¼¯", key=f"edit_{selected_ref}"):
                        st.session_state.raw_input_value = item.get('original', '')
                        st.session_state.current_entry = {
                            'v1': item.get('v1_content', ''), 'v2': item.get('v2_content', ''),
                            'w_sheet': item.get('w_sheet', ''), 'p_sheet': item.get('p_sheet', ''),
                            'grammar_list': item.get('grammar_list', ''), 'other': item.get('other', '')
                        }
                        st.session_state.saved_entries = saved_sheets
                        st.session_state.ref_number = selected_ref
                        st.session_state.is_prompt_generated = True
                        st.session_state.original_text = item.get('original', '')
                        st.session_state.main_input_value = item.get('prompt', '')
                        st.session_state.content_mode = item.get('mode', 'A')
                        st.rerun()
                
                with btn_cols[1]:
                    if st.button("ğŸ—‘ï¸ åˆªé™¤", key=f"del_{selected_ref}"):
                        del st.session_state.sentences[selected_ref]
                        save_sentences(st.session_state.sentences)
                        st.rerun()

    # ç°¡æ˜“æœå°‹
    with st.expander("ğŸ” æœå°‹è³‡æ–™", expanded=False):
        search_kw = st.text_input("è¼¸å…¥é—œéµå­—", placeholder="æœå°‹ Ref_No æˆ–å…§å®¹...")
        if search_kw:
            results = []
            for ref, item in st.session_state.sentences.items():
                if (search_kw.lower() in ref.lower() or 
                    search_kw.lower() in item.get('original', '').lower()):
                    results.append(f"â€¢ **{ref}** ({item.get('date_added', '')})")
            if results:
                st.write(f"æ‰¾åˆ° {len(results)} ç­†ï¼š")
                for r in results:
                    st.markdown(r)
            else:
                st.info("ç„¡ç¬¦åˆè³‡æ–™")

    # åº•éƒ¨çµ±è¨ˆ
    st.divider()
    total_count = len(st.session_state.get('sentences', {}))
    st.caption(f"ğŸ’¾ è³‡æ–™åº«ï¼š{total_count} ç­† | å„²å­˜ä½ç½®ï¼šæœ¬åœ° + Google Sheets")
    if st.session_state.get('sentences', {}):
        json_str = json.dumps(st.session_state.sentences, ensure_ascii=False, indent=2)
        st.download_button("â¬‡ï¸ å‚™ä»½ JSON", json_str,
                          file_name=f"backup_{dt.datetime.now().strftime('%m%d_%H%M')}.json",
                          mime="application/json", use_container_width=True)
