# ===================================================================
# 0. å¥—ä»¶ & å…¨åŸŸå‡½å¼ï¼ˆä¸€å®šæ”¾æœ€é ‚ï¼‰
# ===================================================================
import streamlit as st
import subprocess, sys, os, datetime as dt, pandas as pd, io, json, re, tomli, tomli_w
from streamlit_calendar import calendar

# ========== é™¤éŒ¯æ¸¬è©¦ ==========
st.sidebar.markdown("## ğŸ”§ é™¤éŒ¯è³‡è¨Š")

api_key = os.getenv("GEMINI_API_KEY")

if api_key:
    st.sidebar.success("âœ… GEMINI_API_KEY å·²è¨­å®š")
    st.sidebar.write(f"é•·åº¦: {len(api_key)} å­—å…ƒ")
else:
    st.sidebar.error("âŒ GEMINI_API_KEY æœªè¨­å®š")
    st.sidebar.info("è«‹åˆ° Settings â†’ Secrets è¨­å®š")
    
# ---------- å…¨åŸŸå·¥å…·å‡½å¼ ----------
def save_analysis_result(result, input_text):
    if "analysis_history" not in st.session_state:
        st.session_state.analysis_history = []
    st.session_state.analysis_history.append({
        "date": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
        "input_preview": input_text[:50] + "..." if len(input_text) > 50 else input_text,
        "result": result
    })
    if len(st.session_state.analysis_history) > 10:
        st.session_state.analysis_history.pop(0)

def to_excel(result: dict) -> bytes:
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        for sheet, key in [("Words", "words"), ("Phrases", "phrases"), ("Grammar", "grammar")]:
            if key in result and result[key]:
                pd.DataFrame(result[key]).to_excel(writer, sheet_name=sheet, index=False)
        stats = pd.DataFrame({
            "é …ç›®": ["ç¸½å­—å½™æ•¸", "ç¸½ç‰‡èªæ•¸", "æ–‡æ³•é»æ•¸", "åˆ†ææ—¥æœŸ"],
            "æ•¸å€¼": [
                len(result.get("words", [])),
                len(result.get("phrases", [])),
                len(result.get("grammar", [])),
                dt.date.today().strftime("%Y-%m-%d")
            ]
        })
        stats.to_excel(writer, sheet_name="çµ±è¨ˆ", index=False)
    buffer.seek(0)
    return buffer.getvalue()

# ===================================================================
# 1. å´é‚Šæ¬„ï¼ˆä¸€æ¬¡ 4 é€£çµï¼Œç„¡é‡è¤‡ï¼‰
# ===================================================================
with st.sidebar:
    st.divider()
    c1, c2 = st.columns(2)
    c1.link_button("âœ¨ Google AI", "https://gemini.google.com/ ")
    c2.link_button("ğŸ¤– Kimi K2",   "https://kimi.moonshot.cn/ ")
    c3, c4 = st.columns(2)
    c3.link_button("ESV Bible", "https://wd.bible/bible/gen.1.cunps?parallel=esv.klb.jcb ")
    c4.link_button("THSV11",    "https://www.bible.com/zh-TW/bible/174/GEN.1.THSV11 ")

# ===================================================================
# 2. é é¢é…ç½® & Session åˆå€¼ï¼ˆåªç•™å…¨åŸŸæœƒç”¨åˆ°çš„ï¼‰
# ===================================================================
st.set_page_config(layout="wide", page_title="Bible Study AI App 2026")

# é€™äº›è®Šæ•¸åªæœ‰ TAB2 æœƒç”¨åˆ°ï¼Œä½†ç‚ºäº†é¿å…å¾ŒçºŒ TAB å¼•ç”¨å‡ºéŒ¯ï¼Œå…ˆçµ¦ç©ºå€¼
if 'analysis_history' not in st.session_state: st.session_state.analysis_history = []

# ---------- CSS ----------
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Gamja+Flower&display=swap ');
.cute-korean { font-family: 'Gamja Flower', cursive; font-size: 20px; color: #FF8C00; text-align: center; }
.small-font { font-size: 13px; color: #555555; margin-top: 5px !important; }
.grammar-box-container {
    background-color: #f8f9fa; border-radius: 8px; padding: 12px;
    border-left: 5px solid #FF8C00; text-align: left; margin-top: 0px;
}
.fc-daygrid-day-frame:hover {background-color: #FFF3CD !important; cursor: pointer; transform: scale(1.03); transition: .2s}
.fc-daygrid-day-frame:active {transform: scale(0.98); background-color: #FFE69C !important}
</style>
""", unsafe_allow_html=True)

# ---------- åœ–ç‰‡ & ç¾æˆ TAB ----------
IMG_URLS = {
    "A": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/183ebb183330643.Y3JvcCw4MDgsNjMyLDAsMA.jpg ",
    "B": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/f364bd220887627.67cae1bd07457.jpg ",
    "C": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/68254faebaafed9dafb41918f74c202e.jpg ",
    "M1": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro1.jpg ",
    "M2": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro2.jpg ",
    "M3": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro3.jpg ",
    "M4": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro4.jpg "
}
with st.sidebar:
    st.markdown('<p class="cute-korean">ë‹¹ì‹ ì€ í•˜ë‚˜ë‹˜ì˜ ì†Œì¤‘í•œ ë³´ë¬¼ì…ë‹ˆë‹¤</p>', unsafe_allow_html=True)
    st.image(IMG_URLS["M3"], width=250)
    st.divider()

tabs = st.tabs(["ğŸ  æ›¸æ¡Œ", "ğŸ““ ç­†è¨˜", "âœï¸ æŒ‘æˆ°", "ğŸ“‚ è³‡æ–™åº«"])

# ===================================================================
# 3. TAB1 â”€ æ›¸æ¡Œï¼ˆå–®ç´”ç¶“æ–‡èˆ‡ä¾‹å¥ï¼Œç„¡æœˆæ›†ï¼‰
# ===================================================================
with tabs[0]:
    col_content, col_m1 = st.columns([0.65, 0.35])
    with col_content:
        st.info("**Becoming** / ğŸ‡¯ğŸ‡µ ãµã•ã‚ã—ã„ | ğŸ‡°ğŸ‡· ì–´ìš¸ë¦¬ëŠ” | ğŸ‡¹ğŸ‡­ à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ | ğŸ‡¨ğŸ‡³ ç›¸ç¨±")
        st.success("""
            ğŸŒŸ **Pro 17:07** Fine speech is not becoming to a fool; still less is false speech to a prince.   
            ğŸ‡¯ğŸ‡µ ã™ãã‚ŒãŸè¨€è‘‰ã¯æ„šã‹è€…ã«ã¯ãµã•ã‚ã—ããªã„ã€‚å½ã‚Šã®è¨€è‘‰ã¯å›ä¸»ã«ã¯ãªãŠã•ã‚‰ãµã•ã‚ã—ããªã„ã€‚   
            ğŸ‡¨ğŸ‡³ æ„šé ‘äººèªªç¾è¨€æœ¬ä¸ç›¸ç¨±ï¼Œä½•æ³å›ç‹èªªè¬Šè©±å‘¢ï¼Ÿ
            """, icon="ğŸ“–")
    with col_m1:
        st.markdown(f"""
            <div style="display:flex;flex-direction:column;justify-content:space-between;height:100%;min-height:250px;text-align:center;">
                <div style="flex-grow:1;display:flex;align-items:center;justify-content:center;">
                    <img src="{IMG_URLS['M1']}" style="width:200px;margin-bottom:10px;">
                </div>
                <div class="grammar-box-container" style="margin-top:auto;">
                    <p style="margin:2px 0;font-size:14px;font-weight:bold;color:#333;">æ™‚æ…‹: ç¾åœ¨ç°¡å–®å¼</p>
                    <p style="margin:2px 0;font-size:14px;font-weight:bold;color:#333;">æ ¸å¿ƒç‰‡èª:</p>
                    <ul style="margin:0;padding-left:18px;font-size:13px;line-height:1.4;color:#555;">
                        <li>Fine speech (å„ªç¾è¨€è¾­)</li>
                        <li>Becoming to (ç›¸ç¨±)</li>
                        <li>Still less (ä½•æ³)</li>
                        <li>False speech (è™›å‡è¨€è¾­)</li>
                    </ul>
                </div>
            </div>
        """, unsafe_allow_html=True)
    st.divider()
    st.markdown("### âœï¸ æ–‡æ³•é‹ç”¨ä¾‹å¥")
    cl1, cl2 = st.columns(2)
    with cl1:
        st.markdown("**Ex 1:** *Casual attire is not becoming to a CEO; still less is unprofessional language.* <p class='small-font'>ä¾¿æœå°åŸ·è¡Œé•·ä¸ç›¸ç¨±ï¼›æ›´ä¸ç”¨èªªä¸å°ˆæ¥­çš„è¨€èªäº†ã€‚</p>", unsafe_allow_html=True)
    with cl2:
        st.markdown("**Ex 2:** *Wealth is not becoming to a man without virtue; still less is power.* <p class='small-font'>è²¡å¯Œå°æ–¼ç„¡å¾·ä¹‹äººä¸ç›¸ç¨±ï¼›æ›´ä¸ç”¨èªªæ¬ŠåŠ›äº†ã€‚</p>", unsafe_allow_html=True)

# ===================================================================
# 4. TAB2 â”€ æœˆæ›†å¾…è¾¦ï¼ˆç©©å®šæœ€çµ‚ç‰ˆï¼‰
# ===================================================================
with tabs[1]:
    import datetime as dt, re, os, json
    from streamlit_calendar import calendar

    # ---------- èƒŒæ™¯åœ–ï¼ˆåƒ… TAB2ï¼Œæ·¡åŒ–ï¼‰ ----------
    st.markdown("""
    <style>
    section[data-testid="stSidebar"] + div [data-testid="stVerticalBlock"] {
        background-image: url("assets/68254faebaafed9dafb41918f74c202e.jpg");
        background-size: cover;
        background-position: center;
        background-repeat: no-repeat;
    }
    section[data-testid="stSidebar"] + div [data-testid="stVerticalBlock"]::before {
        content: "";
        position: fixed;
        inset: 0;
        background: rgba(255,255,255,0.82);
        z-index: -1;
    }
    </style>
    """, unsafe_allow_html=True)

    # ---------- 0. æª”æ¡ˆæŒä¹…åŒ– ----------
    TODO_FILE = "todos.json"

    def load_todos():
        if os.path.exists(TODO_FILE):
            try:
                with open(TODO_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except:
                pass
        return {}

    def save_todos():
        with open(TODO_FILE, "w", encoding="utf-8") as f:
            json.dump(st.session_state.todo, f, ensure_ascii=False, indent=2)

    # ---------- 1. åˆå§‹åŒ– ----------
    if "todo" not in st.session_state:
        st.session_state.todo = load_todos()
    if "sel_date" not in st.session_state:
        st.session_state.sel_date = str(dt.date.today())
    if "cal_key" not in st.session_state:
        st.session_state.cal_key = 0
    if "active_del_id" not in st.session_state:
        st.session_state.active_del_id = None

    # ---------- 2. Emoji å·¥å…· ----------
    _EMOJI_RE = re.compile(
        r'[\U0001F300-\U0001FAFF\U00002700-\U000027BF]+', flags=re.UNICODE
    )
    def first_emoji(text: str) -> str:
        m = _EMOJI_RE.search(text)
        return m.group(0) if m else ""

    # ---------- 3. æœˆæ›†äº‹ä»¶ï¼ˆæ ¼å­åªé¡¯ç¤ºæ–‡å­— + Emojiï¼‰ ----------
    def build_events():
        ev = []
        for d, items in st.session_state.todo.items():
            if not isinstance(items, list):
                continue
            for t in items:
                ev.append({
                    "title": f"{t.get('emoji','')}{t['title']}",
                    "start": f"{d}T{t.get('time','00:00:00')}",
                    "backgroundColor": "#FFE4E1",
                    "borderColor": "#FFE4E1",
                    "textColor": "#333"
                })
        return ev

    # ---------- 4. æœˆæ›†ï¼ˆæŠ˜ç–Šæ¬„ï¼‰ ----------
    with st.expander("ğŸ“… è–ç¶“å­¸ç¿’ç”Ÿæ´»æœˆæ›†", expanded=True):
        cal_options = {
            "headerToolbar": {
                "left": "prev,next today",
                "center": "title",
                "right": ""
            },
            "initialView": "dayGridMonth",
            "displayEventTime": False,
            "height": "auto"
        }

        state = calendar(
            events=build_events(),
            options=cal_options,
            key=f"calendar_{st.session_state.cal_key}"
        )

        if state.get("dateClick"):
            st.session_state.sel_date = state["dateClick"]["date"][:10]
            st.rerun()

    # ---------- 5. ä¸‹æ–¹ä¸‰æ—¥æ¸…å–®ï¼ˆğŸ’Ÿ â†’ ğŸ—‘ï¸ï¼‰ ----------
    st.markdown("##### ğŸ“‹ å¾…è¾¦äº‹é …")

    try:
        base_date = dt.datetime.strptime(
            st.session_state.sel_date, "%Y-%m-%d"
        ).date()
    except:
        base_date = dt.date.today()

    for offset in range(3):
        d_obj = base_date + dt.timedelta(days=offset)
        d_str = str(d_obj)
        if d_str in st.session_state.todo:
            for idx, item in enumerate(st.session_state.todo[d_str]):
                item_id = f"{d_str}_{idx}"

                c1, c2, c3 = st.columns([1, 7, 2], vertical_alignment="top")

                with c1:
                    if st.button("ğŸ’Ÿ", key=f"h_{item_id}"):
                        st.session_state.active_del_id = (
                            None if st.session_state.active_del_id == item_id else item_id
                        )
                        st.rerun()

                with c2:
                    st.write(
                        f"{d_obj.month}/{d_obj.day} "
                        f"{item['time'][:5]} "
                        f"{item.get('emoji','')}{item['title']}"
                    )

                with c3:
                    if st.session_state.active_del_id == item_id:
                        if st.button("ğŸ—‘ï¸", key=f"d_{item_id}"):
                            st.session_state.todo[d_str].pop(idx)
                            save_todos()
                            st.session_state.cal_key += 1
                            st.session_state.active_del_id = None
                            st.rerun()

    # ---------- 6. æ–°å¢å¾…è¾¦ ----------
    st.divider()
    with st.expander("â• æ–°å¢å¾…è¾¦", expanded=True):
        with st.form("todo_form", clear_on_submit=True):
            col1, col2 = st.columns(2)
            with col1:
                in_date = st.date_input("æ—¥æœŸ", base_date)
            with col2:
                in_time = st.time_input("æ™‚é–“", dt.time(9, 0))

            in_title = st.text_input("å¾…è¾¦äº‹é …ï¼ˆå¯å« Emojiï¼‰")

            if st.form_submit_button("ğŸ’¾ å„²å­˜"):
                if in_title:
                    k = str(in_date)
                    if k not in st.session_state.todo:
                        st.session_state.todo[k] = []
                    st.session_state.todo[k].append({
                        "title": in_title,
                        "time": str(in_time),
                        "emoji": first_emoji(in_title)
                    })
                    save_todos()
                    st.session_state.cal_key += 1
                    st.rerun()

# ===================================================================
# 5. TAB3 â”€ æŒ‘æˆ°ï¼ˆå–®ç´”ç¿»è­¯é¡Œï¼Œç„¡æœˆæ›†ï¼‰
# ===================================================================
with tabs[2]:
    col_challenge, col_deco = st.columns([0.7, 0.3])
    with col_challenge:
        st.subheader("ğŸ“ ç¿»è­¯æŒ‘æˆ°")
        st.write("é¡Œç›® 1: æ„šé ‘äººèªªç¾è¨€æœ¬ä¸ç›¸ç¨±...")
        st.text_input("è«‹è¼¸å…¥è‹±æ–‡ç¿»è­¯", key="ans_1_final", placeholder="Type your translation here...")
    with col_deco:
        st.image(IMG_URLS.get("B"), width=150, caption="Keep Going!")

# ===================================================================
# 6. TAB4 â”€ AI æ§åˆ¶å°ï¼ˆå–®ä¸€è¼¸å…¥æ¡† + å¤–éƒ¨ AI é€£çµ + Excel å¼ç®¡ç†ï¼‰
# ===================================================================
with tabs[3]:
    import os, json, datetime as dt, pandas as pd, urllib.parse
    
    SENTENCES_FILE = "sentences.json"
    
    # ---------- è³‡æ–™åº«æŒä¹…åŒ– ----------
    def load_sentences():
        if os.path.exists(SENTENCES_FILE):
            try:
                with open(SENTENCES_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except:
                pass
        return {}
    
    def save_sentences(data):
        with open(SENTENCES_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    # åˆå§‹åŒ–
    if 'sentences' not in st.session_state:
        st.session_state.sentences = load_sentences()
    if 'search_results' not in st.session_state:
        st.session_state.search_results = []
    if 'selected_for_delete' not in st.session_state:
        st.session_state.selected_for_delete = []

    # ---------- ä¸Šæ–¹åŠŸèƒ½åˆ—ï¼ˆAI é€£çµ + å„²å­˜ï¼‰----------
    st.markdown("### ğŸ¤– AI åˆ†æé€£çµ")
    c1, c2, c3, c4 = st.columns([1, 1, 1, 1])
    
    # å–å¾—ç•¶å‰è¼¸å…¥å…§å®¹ç”Ÿæˆ Prompt
    current_input = st.session_state.get("main_input", "")
    
    # é è¨­åˆ†ææŒ‡ä»¤ Prompt
    ai_prompt = f"""è«‹åˆ†æä»¥ä¸‹è–ç¶“ç¶“æ–‡ï¼Œä»¥ JSON æ ¼å¼å›å‚³ï¼ˆä¸è¦ markdown æ ¼å¼ï¼‰ï¼š
{{
  "ref_no": "ç¶“æ–‡ç·¨è™Ÿï¼ˆå¦‚ï¼š2Ti 3:10ï¼‰",
  "ref_article": "å®Œæ•´è‹±æ–‡ç¶“æ–‡",
  "zh_translation": "ä¸­æ–‡ç¿»è­¯",
  "words": [
    {{"word": "å–®å­—", "meaning": "ä¸­æ–‡è§£é‡‹", "level": "é›£åº¦ç­‰ç´š"}}
  ],
  "phrases": [
    {{"phrase": "ç‰‡èª", "meaning": "ä¸­æ–‡è§£é‡‹", "usage": "ä¾‹å¥"}}
  ],
  "grammar": [
    {{"grammar_point": "æ–‡æ³•é»", "explanation": "è©³ç´°èªªæ˜"}}
  ]
}}

å¾…åˆ†æç¶“æ–‡ï¼š
{current_input}"""
    
    encoded_prompt = urllib.parse.quote(ai_prompt)
    
    with c1:
        st.link_button("ğŸ’¬ ChatGPT ğŸ”—", f"https://chat.openai.com/?q={encoded_prompt}", 
                       use_container_width=True, help="é–‹å•Ÿ ChatGPT ä¸¦è‡ªå‹•å¸¶å…¥åˆ†ææŒ‡ä»¤")
    with c2:
        # Kimi ç¶²é ç‰ˆé€£çµï¼ˆä½¿ç”¨ query åƒæ•¸ï¼‰
        st.link_button("ğŸŒ™ Kimi K2 ğŸ”—", f"https://kimi.com/?q={encoded_prompt}", 
                       use_container_width=True, help="é–‹å•Ÿ Kimi ä¸¦è‡ªå‹•å¸¶å…¥åˆ†ææŒ‡ä»¤")
    with c3:
        # Google Gemini é€£çµ
        st.link_button("ğŸ” Google ğŸ”—", f"https://gemini.google.com/app?q={encoded_prompt}", 
                       use_container_width=True, help="é–‹å•Ÿ Gemini ä¸¦è‡ªå‹•å¸¶å…¥åˆ†ææŒ‡ä»¤")
    with c4:
        # å„²å­˜éµï¼šæ”¯æ´ JSON æ ¼å¼ AI çµæœæˆ–ç´”æ–‡å­—
        if st.button("ğŸ’¾ å„²å­˜", type="primary", use_container_width=True):
            if not current_input.strip():
                st.error("âš ï¸ è«‹å…ˆè¼¸å…¥å…§å®¹")
            else:
                try:
                    # å˜—è©¦è§£æç‚º JSONï¼ˆAI åˆ†æçµæœï¼‰
                    data = json.loads(current_input)
                    ref = data.get("ref_no") or data.get("ref") or f"REF_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    
                    st.session_state.sentences[ref] = {
                        "ref": ref,
                        "en": data.get("ref_article", data.get("en", "")),
                        "zh": data.get("zh_translation", data.get("zh", "")),
                        "words": data.get("words", []),
                        "phrases": data.get("phrases", []),
                        "grammar": data.get("grammar", []),
                        "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M")
                    }
                    save_sentences(st.session_state.sentences)
                    st.success(f"âœ… å·²å„²å­˜ï¼š{ref}")
                    
                    # æ¸…ç©ºè¼¸å…¥æ¡†ä¸¦é‡æ–°è¼‰å…¥
                    st.session_state["main_input"] = ""
                    st.session_state["search_results"] = []
                    st.rerun()
                    
                except json.JSONDecodeError:
                    # è¦–ç‚ºç´”æ–‡å­—ç­†è¨˜å„²å­˜
                    ref = f"NOTE_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    st.session_state.sentences[ref] = {
                        "ref": ref,
                        "en": current_input,
                        "zh": "",
                        "words": [],
                        "phrases": [],
                        "grammar": [],
                        "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M")
                    }
                    save_sentences(st.session_state.sentences)
                    st.success(f"âœ… å·²å„²å­˜ç‚ºæ–‡å­—ç­†è¨˜ï¼š{ref}")
                    st.session_state["main_input"] = ""
                    st.rerun()

    # ---------- æ ¸å¿ƒï¼šå–®ä¸€å¤šåŠŸèƒ½è¼¸å…¥æ¡† ----------
    st.markdown("### ğŸ“ å¤šåŠŸèƒ½è¼¸å…¥å€")
    input_text = st.text_area(
        "",
        height=350,
        key="main_input",
        placeholder="""ğŸ“‹ ä½¿ç”¨èªªæ˜ï¼š
1. è²¼ä¸Šç¶“æ–‡ â†’ é»ä¸Šæ–¹ AI é€£çµé€²è¡Œåˆ†æ â†’ è¤‡è£½ AI çµæœ â†’ å›è²¼è‡³æ­¤ â†’ æŒ‰å„²å­˜
2. è¼¸å…¥ Ref. æˆ–é—œéµå­— â†’ é»ä¸‹æ–¹ã€Œæœå°‹ã€æŸ¥è©¢è³‡æ–™åº«
3. ç®¡ç†è³‡æ–™ï¼šæœå°‹å¾Œå‹¾é¸é …ç›® â†’ é»ã€Œåˆªé™¤ã€ç§»é™¤""",
        label_visibility="collapsed"
    )

    # ---------- ä¸‹æ–¹æ“ä½œåˆ—ï¼ˆæœå°‹ + åˆªé™¤ï¼‰----------
    st.markdown("### ğŸ” è³‡æ–™æª¢ç´¢èˆ‡ç®¡ç†")
    col1, col2 = st.columns([1, 1])
    
    with col1:
        if st.button("ğŸ” æœå°‹è³‡æ–™åº«", use_container_width=True, type="primary"):
            if not input_text.strip():
                st.warning("è«‹å…ˆåœ¨ä¸Šæ–¹è¼¸å…¥æ¡†è¼¸å…¥æœå°‹æ¢ä»¶ï¼ˆRef. ç·¨è™Ÿæˆ–é—œéµå­—ï¼‰")
                st.session_state.search_results = []
            else:
                keyword = input_text.lower()
                results = []
                
                for k, v in st.session_state.sentences.items():
                    # æœå°‹ç¯„åœï¼šRefã€è‹±æ–‡ã€ä¸­æ–‡ã€æ—¥æœŸ
                    searchable = f"{v.get('ref','')} {v.get('en','')} {v.get('zh','')} {v.get('date_added','')}".lower()
                    
                    if keyword in searchable or keyword in k.lower():
                        results.append({
                            "key": k,
                            "å‹¾é¸": False,  # ç”¨æ–¼åˆªé™¤å‹¾é¸
                            "Ref.": v.get("ref", k),
                            "å…§å®¹é è¦½": (v.get("en", "")[:80] + "...") if len(v.get("en","")) > 80 else v.get("en", ""),
                            "ä¸­æ–‡": (v.get("zh", "")[:40] + "...") if len(v.get("zh","")) > 40 else v.get("zh", ""),
                            "æ—¥æœŸ": v.get("date_added", "")
                        })
                
                st.session_state.search_results = results
                if not results:
                    st.info("ğŸ“­ æ‰¾ä¸åˆ°ç¬¦åˆæ¢ä»¶çš„è³‡æ–™")

    with col2:
        if st.button("ğŸ—‘ï¸ åˆªé™¤å‹¾é¸é …ç›®", use_container_width=True, type="secondary"):
            if not st.session_state.get("selected_rows"):
                st.warning("è«‹å…ˆåœ¨ä¸‹æ–¹è¡¨æ ¼å‹¾é¸è¦åˆªé™¤çš„é …ç›®")
            else:
                deleted_count = 0
                for key in st.session_state.selected_rows:
                    if key in st.session_state.sentences:
                        del st.session_state.sentences[key]
                        deleted_count += 1
                
                if deleted_count > 0:
                    save_sentences(st.session_state.sentences)
                    st.success(f"âœ… å·²æˆåŠŸåˆªé™¤ {deleted_count} ç­†è³‡æ–™")
                    st.session_state.selected_rows = []
                    # é‡æ–°åŸ·è¡Œæœå°‹ä»¥æ›´æ–°åˆ—è¡¨
                    st.rerun()
                else:
                    st.error("åˆªé™¤å¤±æ•—")

    # ---------- æœå°‹çµæœé¡¯ç¤ºå€ï¼ˆExcel å¼è¡¨æ ¼ + å‹¾é¸ï¼‰----------
    if st.session_state.search_results:
        st.markdown(f"#### ğŸ“Š æœå°‹çµæœï¼ˆå…± {len(st.session_state.search_results)} ç­†ï¼‰")
        
        # ä½¿ç”¨ Data Editor å¯¦ç¾å‹¾é¸åŠŸèƒ½
        df = pd.DataFrame(st.session_state.search_results)
        
        edited_df = st.data_editor(
            df,
            column_config={
                "å‹¾é¸": st.column_config.CheckboxColumn(
                    "é¸æ“‡",
                    help="å‹¾é¸å¾ŒæŒ‰ä¸Šæ–¹ã€Œåˆªé™¤å‹¾é¸é …ç›®ã€",
                    default=False,
                    width="small"
                ),
                "key": None,  # éš±è— key æ¬„ä½ï¼ˆå…§éƒ¨ä½¿ç”¨ï¼‰
                "Ref.": st.column_config.TextColumn("ç¶“æ–‡ç·¨è™Ÿ", width="medium"),
                "å…§å®¹é è¦½": st.column_config.TextColumn("è‹±æ–‡å…§å®¹é è¦½", width="large"),
                "ä¸­æ–‡": st.column_config.TextColumn("ä¸­æ–‡", width="medium"),
                "æ—¥æœŸ": st.column_config.TextColumn("å„²å­˜æ—¥æœŸ", width="small")
            },
            hide_index=True,
            use_container_width=True,
            height=min(400, len(df) * 35 + 40),  # å‹•æ…‹é«˜åº¦
            key="result_editor"
        )
        
        # æ›´æ–°é¸å–ç‹€æ…‹
        selected = edited_df[edited_df["å‹¾é¸"] == True]["key"].tolist()
        st.session_state.selected_rows = selected
        
        if selected:
            st.caption(f"å·²é¸å– {len(selected)} ç­†è³‡æ–™å¾…åˆªé™¤")
        
        # è©³ç´°å…§å®¹å±•é–‹ï¼ˆåƒ…é¡¯ç¤ºå‰ 3 ç­†é¿å…ç•«é¢éé•·ï¼Œé»æ“Šå¯å±•é–‹å…¨éƒ¨ï¼‰
        st.markdown("#### ğŸ“– è©³ç´°å…§å®¹æª¢è¦–")
        for i, row in enumerate(st.session_state.search_results[:5]):
            full_data = st.session_state.sentences.get(row["key"], {})
            
            with st.expander(f"ğŸ“Œ {row['Ref.']} | {row['æ—¥æœŸ']}"):
                col_content, col_analysis = st.columns([2, 1])
                
                with col_content:
                    st.markdown("**ğŸ“ è‹±æ–‡å…§å®¹ï¼š**")
                    st.text(full_data.get("en", "ç„¡"))
                    st.markdown("**ğŸˆº ä¸­æ–‡ï¼š**")
                    st.text(full_data.get("zh", "ç„¡"))
                
                with col_analysis:
                    if full_data.get("words"):
                        st.markdown("**ğŸ“š å–®å­—é‡é»ï¼š**")
                        for w in full_data["words"][:3]:
                            st.caption(f"â€¢ {w.get('word','')}ï¼š{w.get('meaning','')}")
                    
                    if full_data.get("phrases"):
                        st.markdown("**ğŸ”— ç‰‡èªï¼š**")
                        for p in full_data["phrases"][:2]:
                            st.caption(f"â€¢ {p.get('phrase','')}ï¼š{p.get('meaning','')}")
                    
                    if full_data.get("grammar"):
                        st.markdown("**âš™ï¸ æ–‡æ³•é»ï¼š**")
                        for g in full_data["grammar"][:2]:
                            st.caption(f"â€¢ {g.get('grammar_point','')}")

    # ---------- åº•éƒ¨çµ±è¨ˆèˆ‡åŒ¯å‡º ----------
    st.divider()
    stat_col1, stat_col2, stat_col3 = st.columns([2, 2, 2])
    
    with stat_col1:
        st.caption(f"ğŸ“¦ è³‡æ–™åº«ç¸½æ•¸ï¼š{len(st.session_state.sentences)} ç­†")
    
    with stat_col2:
        # ä¸€éµåŒ¯å‡º JSON
        if st.session_state.sentences:
            json_str = json.dumps(st.session_state.sentences, ensure_ascii=False, indent=2)
            st.download_button(
                "â¬‡ï¸ åŒ¯å‡º JSON å‚™ä»½",
                data=json_str,
                file_name=f"sentences_backup_{dt.datetime.now().strftime('%Y%m%d')}.json",
                mime="application/json",
                use_container_width=True
            )
    
    with stat_col3:
        # æ¸…ç©ºè³‡æ–™åº«ï¼ˆå±éšªæ“ä½œï¼Œéœ€ç¢ºèªï¼‰
        if st.button("âš ï¸ æ¸…ç©ºå…¨éƒ¨è³‡æ–™", type="secondary", use_container_width=True):
            st.session_state.show_confirm_clear = True
    
    if st.session_state.get("show_confirm_clear"):
        st.error("âš ï¸ ç¢ºå®šè¦åˆªé™¤æ‰€æœ‰è³‡æ–™å—ï¼Ÿæ­¤å‹•ä½œç„¡æ³•å¾©åŸï¼")
        conf_col1, conf_col2 = st.columns([1, 1])
        with conf_col1:
            if st.button("âœ… ç¢ºèªæ¸…ç©º", type="primary"):
                st.session_state.sentences = {}
                save_sentences({})
                st.session_state.search_results = []
                st.session_state.show_confirm_clear = False
                st.success("è³‡æ–™åº«å·²æ¸…ç©º")
                st.rerun()
        with conf_col2:
            if st.button("âŒ å–æ¶ˆ"):
                st.session_state.show_confirm_clear = False
                st.rerun()
