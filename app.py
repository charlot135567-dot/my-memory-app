# ===================================================================
# 3. TAB1 â”€ æ›¸æ¡Œ (è¼ªæµé¡¯ç¤ºç‰ˆ - æ”¯æ´CSVå’ŒMarkdowné›™æ ¼å¼)
# ===================================================================
with tabs[0]:
    import csv, random, re, datetime as dt
    from io import StringIO

    # --- Session State åˆå§‹åŒ–ï¼ˆç¢ºä¿æ¯æ¬¡éƒ½æœ‰å€¼ï¼‰---
    if "tab1_vocab_index" not in st.session_state:
        st.session_state.tab1_vocab_index = 0
    if "tab1_phrase_index" not in st.session_state:
        st.session_state.tab1_phrase_index = 15  # ç‰‡èªå¾ç¬¬16å€‹é–‹å§‹(ç´¢å¼•15)
    if "tab1_grammar_index" not in st.session_state:
        st.session_state.tab1_grammar_index = 0
    if "tab1_verse_index" not in st.session_state:
        st.session_state.tab1_verse_index = 0
    if "tab1_last_update" not in st.session_state:
        st.session_state.tab1_last_update = dt.datetime.now()

    # æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¶…é1å°æ™‚ï¼‰
    current_time = dt.datetime.now()
    time_diff = (current_time - st.session_state.tab1_last_update).total_seconds()
    
    if time_diff > 3600:
        st.session_state.tab1_last_update = current_time
        st.session_state.tab1_vocab_index += 1
        st.session_state.tab1_phrase_index += 4
        st.session_state.tab1_grammar_index += 1
        st.session_state.tab1_verse_index += 1
        st.rerun()
    
    sentences = st.session_state.get('sentences', {})
    
    if not sentences:
        st.warning("è³‡æ–™åº«ç‚ºç©ºï¼Œè«‹å…ˆåœ¨ TAB4 è¼‰å…¥è³‡æ–™")
    else:
        # ä¿®æ­£ï¼šæ›´ç©©å¥çš„è§£æå‡½å¼ï¼Œæ”¯æ´ \t åˆ†éš”
        def parse_csv(content):
            """è§£æCSVæ ¼å¼ï¼ˆæ”¯æ´ \t åˆ†éš”ï¼‰"""
            if not content or not content.strip(): 
                return []
            try:
                # æª¢æŸ¥æ˜¯å¦ç‚ºMarkdownè¡¨æ ¼
                if '|' in content and '\n' in content and content.strip().startswith('|'):
                    return []  # äº¤çµ¦parse_markdownè™•ç†
                
                # ä½¿ç”¨ \t ä½œç‚ºåˆ†éš”ç¬¦
                from io import StringIO
                reader = csv.DictReader(StringIO(content.strip()), delimiter='\t')
                rows = list(reader)
                return [row for row in rows if any(v.strip() for v in row.values())]
            except Exception as e:
                st.write(f"CSVè§£æéŒ¯èª¤: {e}")
                return []

        def parse_markdown_table(content):
            """è§£æMarkdownè¡¨æ ¼æ ¼å¼"""
            if not content or not content.strip():
                return []
            
            lines = content.strip().split('\n')
            rows = []
            
            # æ‰¾åˆ°è¡¨æ ¼é–‹å§‹è¡Œï¼ˆä»¥|é–‹é ­ï¼‰
            table_lines = []
            for line in lines:
                line = line.strip()
                if line.startswith('|'):
                    table_lines.append(line)
            
            if len(table_lines) < 2:  # éœ€è¦æ¨™é¡Œè¡Œå’Œåˆ†éš”è¡Œ
                return []
            
            # è§£ææ¨™é¡Œè¡Œ
            header_line = table_lines[0]
            headers = [h.strip() for h in header_line.split('|')[1:-1]]  # å»æ‰é¦–å°¾ç©ºå­—ä¸²
            
            # è·³éåˆ†éš”è¡Œï¼ˆç¬¬2è¡Œï¼Œé€šå¸¸æ˜¯ |---|---| é€™ç¨®ï¼‰
            data_lines = table_lines[2:]
            
            for line in data_lines:
                if not line.strip() or line.strip().replace('|', '').strip() == '':
                    continue
                    
                # è§£æè³‡æ–™è¡Œ
                cells = [c.strip() for c in line.split('|')[1:-1]]
                
                # ç¢ºä¿æ¬„ä½æ•¸é‡ä¸€è‡´
                while len(cells) < len(headers):
                    cells.append('')
                
                row_dict = {}
                for i, header in enumerate(headers):
                    # æ¸…ç†Markdownæ¨™è¨˜ï¼ˆ**ç²—é«”**ï¼‰
                    cell_value = cells[i] if i < len(cells) else ''
                    # ç§»é™¤ ** æ¨™è¨˜ä½†ä¿ç•™å…§å®¹
                    cell_value = re.sub(r'\*\*(.*?)\*\*', r'\1', cell_value)
                    row_dict[header] = cell_value
                
                # åªåŠ å…¥æœ‰è³‡æ–™çš„è¡Œ
                if any(v.strip() for v in row_dict.values()):
                    rows.append(row_dict)
            
            return rows

        # ============================================================
        # é—œéµä¿®æ­£ï¼šåˆ†é›¢æ¨¡å¼Aå’Œæ¨¡å¼Bçš„è³‡æ–™ï¼Œæ”¯æ´é›™æ ¼å¼
        # ============================================================
        
        # æ”¶é›†æ‰€æœ‰æ¨¡å¼Aè³‡æ–™ï¼ˆæœ‰V1çš„ï¼‰å’Œæ¨¡å¼Bè³‡æ–™ï¼ˆæœ‰W Sheetä½†ç„¡V1çš„ï¼‰
        all_mode_a = []  # å–®å­—ã€é‡‘å¥ä¾†æº
        all_mode_b = []  # ç‰‡èªä¾†æº
        all_grammar_sources = []  # æ–‡æ³•ä¾†æºï¼ˆAæˆ–Béƒ½å¯ä»¥ï¼‰
        
        for ref, data in sentences.items():
            v1_content = data.get('v1_content', '')
            v2_content = data.get('v2_content', '')
            w_content = data.get('w_sheet', '')
            g_content = data.get('grammar_list', '')
            
            # å˜—è©¦CSVæ ¼å¼ï¼ˆ\tåˆ†éš”ï¼‰ï¼Œå¤±æ•—å‰‡å˜—è©¦Markdownæ ¼å¼
            v1_rows = parse_csv(v1_content) or parse_markdown_table(v1_content)
            v2_rows = parse_csv(v2_content) or parse_markdown_table(v2_content)
            w_rows = parse_csv(w_content) or parse_markdown_table(w_content)
            g_rows = parse_csv(g_content) or parse_markdown_table(g_content)
            
            # æ¨¡å¼Aï¼šæœ‰V1è³‡æ–™ â†’ ç”¨æ–¼å–®å­—ã€é‡‘å¥
            if v1_rows:
                all_mode_a.append({
                    'ref': ref,
                    'v1': v1_rows,
                    'v2': v2_rows,
                    'v1_count': len(v1_rows)
                })
                # æ–‡æ³•ä¹Ÿå¯ä»¥ä¾†è‡ªV1
                for i, row in enumerate(v1_rows):
                    all_grammar_sources.append({
                        'type': 'A',
                        'ref': ref,
                        'row': row,
                        'v2_row': v2_rows[i] if i < len(v2_rows) else {},
                        'index': i,
                        'total_in_file': len(v1_rows)
                    })
            
            # æ¨¡å¼Bï¼šæœ‰W Sheet â†’ ç”¨æ–¼ç‰‡èªï¼ˆä¿®æ­£ï¼šåªè¦æœ‰W Sheetå°±åŠ å…¥ï¼‰
            if w_rows and len(w_rows) > 0:
                all_mode_b.append({
                    'ref': ref,
                    'w': w_rows,
                    'w_count': len(w_rows)
                })
            
            # Grammar Listï¼ˆæ¨¡å¼Bçš„æ–‡æ³•ï¼‰
            if g_rows:
                for i, row in enumerate(g_rows):
                    all_grammar_sources.append({
                        'type': 'B',
                        'ref': ref,
                        'row': row,
                        'v2_row': {},
                        'index': i,
                        'total_in_file': len(g_rows)
                    })
        
        # ============================================================
        # 1) å–®å­—ï¼šV1 Syn/Ant + V2 Syn/Ant + THSV11 + å¤šèªè¨€
        # ============================================================
        vocab_display = []
        current_vocab_ref = "N/A"
        
        if all_mode_a:
            # è¼ªæµé¸æ“‡å“ªå€‹æ¨¡å¼Aæª”æ¡ˆ
            total_vocab_items = sum(f['v1_count'] for f in all_mode_a)
            if total_vocab_items > 0:
                vocab_counter = st.session_state.tab1_vocab_index % total_vocab_items
                # æ‰¾åˆ°å°æ‡‰çš„æª”æ¡ˆå’Œè¡Œ
                cumulative = 0
                vocab_file = None
                row_idx = 0
                for f in all_mode_a:
                    if cumulative + f['v1_count'] > vocab_counter:
                        vocab_file = f
                        row_idx = vocab_counter - cumulative
                        break
                    cumulative += f['v1_count']
                
                if vocab_file:
                    v1_row = vocab_file['v1'][row_idx]
                    v2_row = vocab_file['v2'][row_idx % len(vocab_file['v2'])] if vocab_file['v2'] else {}
                    
                    current_vocab_ref = v1_row.get('Ref.', vocab_file['ref'])
                    
                    # ä¿®æ­£ï¼šå®Œæ•´æå– V1 Syn/Ant
                    v1_syn_ant = v1_row.get('Syn/Ant', '')
                    v1_syn_list = []
                    v1_ant_list = []
                    
                    if v1_syn_ant:
                        # è§£æ Syn/Ant æ ¼å¼
                        if 'Syn:' in v1_syn_ant or 'Ant:' in v1_syn_ant:
                            syn_match = re.search(r'Syn:\s*([^/;]+)', v1_syn_ant)
                            ant_match = re.search(r'Ant:\s*([^/;]+)', v1_syn_ant)
                            if syn_match:
                                v1_syn_list = [s.strip() for s in syn_match.group(1).split(',') if s.strip()]
                            if ant_match:
                                v1_ant_list = [a.strip() for a in ant_match.group(1).split(',') if a.strip()]
                        else:
                            # å˜—è©¦ç”¨ / æˆ– | åˆ†éš”
                            parts = re.split(r'[/|]', v1_syn_ant)
                            if len(parts) >= 2:
                                v1_syn_list = [p.strip() for p in parts[0].split(',') if p.strip()]
                                v1_ant_list = [p.strip() for p in parts[1].split(',') if p.strip()]
                            else:
                                v1_syn_list = [v1_syn_ant.strip()]
                    
                    # ä¿®æ­£ï¼šå®Œæ•´æå– V2 å¤šèªè¨€è³‡æ–™
                    v2_syn_ant = v2_row.get('Syn/Ant', '') if v2_row else ''
                    v2_th = v2_row.get('THSV11', '') if v2_row else ''
                    v2_kr = v2_row.get('KRF', '') if v2_row else ''  # éŸ“æ–‡ç¶“æ–‡
                    v2_jp = v2_row.get('å£èªè¨³', '') if v2_row else ''  # æ—¥æ–‡
                    
                    # ä¿®æ­£ï¼šçµ„åˆå–®å­—é¡¯ç¤ºï¼ˆåŒ…å«æ‰€æœ‰èªè¨€ï¼‰
                    vocab_items = []
                    
                    # V1 Synï¼ˆè‹±æ–‡åŒç¾©è©ï¼‰
                    if v1_syn_list:
                        vocab_items.append(f"<span style='color:#2E8B57;'>âœ¨{', '.join(v1_syn_list)}</span>")
                    
                    # V1 Antï¼ˆè‹±æ–‡åç¾©è©ï¼‰
                    if v1_ant_list:
                        vocab_items.append(f"<span style='color:#CD5C5C;'>â„ï¸{', '.join(v1_ant_list)}</span>")
                    
                    # V2 éŸ“æ–‡ Syn/Ant
                    if v2_syn_ant:
                        vocab_items.append(f"<span style='color:#4682B4;'>ğŸ‡°ğŸ‡· {v2_syn_ant}</span>")
                    
                    # V2 æ³°æ–‡ (THSV11)
                    if v2_th:
                        vocab_items.append(f"<span style='color:#9932CC;'>ğŸ‡¹ğŸ‡­ {v2_th}</span>")
                    
                    # V2 æ—¥æ–‡ (å£èªè¨³)
                    if v2_jp:
                        vocab_items.append(f"<span style='color:#FF6347;'>ğŸ‡¯ğŸ‡µ {v2_jp}</span>")
                    
                    vocab_display = vocab_items
        
        # ============================================================
        # 2) ç‰‡èªï¼šåªå¾æ¨¡å¼Bçš„W Sheetè¼ªæµï¼ˆç¬¬16å€‹é–‹å§‹ï¼Œç´¢å¼•15ï¼‰
        # ============================================================
        w_phrases = []
        current_phrase_ref = "N/A"
        
        # æ”¶é›†æ‰€æœ‰å¯ç”¨çš„ç‰‡èªï¼ˆå¾ç¬¬16å€‹é–‹å§‹ï¼Œç´¢å¼•15ï¼‰
        all_available_phrases = []
        
        for mb in all_mode_b:
            w_rows = mb.get('w', [])
            w_count = len(w_rows)
            
            # åªæœ‰è¶…é15ç­†çš„æª”æ¡ˆæ‰åŠ å…¥ï¼ˆå¾ç¬¬16å€‹é–‹å§‹ï¼‰
            if w_count > 15:
                for idx in range(15, w_count):
                    all_available_phrases.append({
                        'data': w_rows[idx],
                        'ref': mb['ref'],
                        'original_idx': idx + 1  # 1-based for display
                    })
        
        # è¼ªæµé¡¯ç¤º4å€‹ç‰‡èª
        if len(all_available_phrases) > 0:
            total_available = len(all_available_phrases)
            # ç¢ºä¿ç´¢å¼•åœ¨ç¯„åœå…§
            start_idx = st.session_state.tab1_phrase_index % total_available
            
            # å–4å€‹ç‰‡èªï¼ˆå¾ªç’°ï¼‰
            for i in range(4):
                idx = (start_idx + i) % total_available
                item = all_available_phrases[idx]
                w_phrases.append(item['data'])
                # è¨˜éŒ„ç¬¬ä¸€å€‹çš„refä½œç‚ºé¡¯ç¤ºç”¨
                if i == 0:
                    current_phrase_ref = f"{item['ref']} #{item['original_idx']}"
        
        # ============================================================
        # 3) é‡‘å¥ï¼šå¾æ¨¡å¼Açš„V1 Sheetè¼ªæµï¼ˆèˆ‡å–®å­—éŒ¯é–‹6å¥ï¼‰
        # ============================================================
        verse_lines = []
        current_verse_ref = "N/A"
        
        if all_mode_a:
            total_verse_items = sum(f['v1_count'] for f in all_mode_a)
            if total_verse_items > 0:
                # é—œéµä¿®æ”¹ï¼šé‡‘å¥ç´¢å¼• = ç•¶å‰ç´¢å¼• + 6ï¼Œèˆ‡å–®å­—éŒ¯é–‹
                verse_counter = (st.session_state.tab1_verse_index + 6) % total_verse_items
                cumulative = 0
                verse_file = None
                row_idx = 0
                
                for f in all_mode_a:
                    if cumulative + f['v1_count'] > verse_counter:
                        verse_file = f
                        row_idx = verse_counter - cumulative
                        break
                    cumulative += f['v1_count']
                
                if verse_file:
                    v1_verse = verse_file['v1'][row_idx]
                    v2_verse = verse_file['v2'][row_idx % len(verse_file['v2'])] if verse_file['v2'] else {}
                    
                    current_verse_ref = v1_verse.get('Ref.', verse_file['ref'])
                    
                    # ä¿®æ­£ï¼šå®Œæ•´æå–æ‰€æœ‰èªè¨€ç‰ˆæœ¬
                    en_text = v1_verse.get('English (ESV)', '')
                    cn_text = v1_verse.get('Chinese', '')
                    jp_text = v2_verse.get('å£èªè¨³', '') if v2_verse else ''
                    kr_text = v2_verse.get('KRF', '') if v2_verse else ''  # éŸ“æ–‡ç¶“æ–‡
                    th_text = v2_verse.get('THSV11', '') if v2_verse else ''
                    
                    # çµ„åˆé‡‘å¥é¡¯ç¤ºï¼ˆå¤šèªè¨€ï¼‰
                    verse_lines = []
                    if en_text:
                        verse_text = f"ğŸ‡¬ğŸ‡§ <b>{current_verse_ref}</b> {en_text}"
                        verse_lines.append(verse_text)
                    if jp_text:
                        verse_lines.append(f"ğŸ‡¯ğŸ‡µ {jp_text}")
                    if kr_text:
                        verse_lines.append(f"ğŸ‡°ğŸ‡· {kr_text}")
                    if th_text:
                        verse_lines.append(f"ğŸ‡¹ğŸ‡­ {th_text}")
                    if cn_text:
                        verse_lines.append(f"ğŸ‡¨ğŸ‡³ {cn_text}")
        
        # ============================================================
        # 4) æ–‡æ³•è§£æï¼šå®Œæ•´é¡¯ç¤º Syn/Ant + å¤šèªè¨€
        # ============================================================
        grammar_html = "ç­‰å¾…è³‡æ–™ä¸­..."
        current_grammar_ref = "N/A"
        
        if all_grammar_sources:
            g_idx = st.session_state.tab1_grammar_index % len(all_grammar_sources)
            g_source = all_grammar_sources[g_idx]
            g_row = g_source['row']
            v2_row = g_source.get('v2_row', {})
            current_grammar_ref = f"{g_source['ref']}-{g_source['index']+1}"
            
            all_grammar = []
            
            if g_source['type'] == 'A':
                # æ¨¡å¼Aæ–‡æ³•ï¼ˆä¾†è‡ªV1 Grammaræ¬„ä½ï¼‰
                g_ref = g_row.get('Ref.', '')
                g_en = g_row.get('English (ESV)', '')
                g_cn = g_row.get('Chinese', '')
                g_syn = g_row.get('Syn/Ant', '')
                g_grammar = g_row.get('Grammar', '')
                
                # ä¿®æ­£ï¼šç¶“æ–‡æ¨™é¡Œè¡Œï¼ˆRefç·Šè²¼è‹±æ–‡ï¼‰
                if g_ref and g_en:
                    all_grammar.append(f"<b>{g_ref}</b>{g_en}")
                elif g_en:
                    all_grammar.append(g_en)
                
                # ä¸­æ–‡
                if g_cn:
                    all_grammar.append(g_cn)
                
                # ä¿®æ­£ï¼šSyn/Ant åŒä¸€è¡Œé¡¯ç¤ºï¼ˆç¢ºä¿å…©è€…éƒ½é¡¯ç¤ºï¼‰
                if g_syn:
                    syn_ant_html = ""
                    # è§£æ Syn å’Œ Ant
                    syn_text = ""
                    ant_text = ""
                    
                    # å˜—è©¦å¤šç¨®æ ¼å¼è§£æ
                    if 'Syn:' in g_syn or 'Ant:' in g_syn:
                        syn_match = re.search(r'Syn:\s*([^/;]+?)(?=\s*Ant:|$)', g_syn)
                        ant_match = re.search(r'Ant:\s*([^/;]+)', g_syn)
                        if syn_match:
                            syn_text = syn_match.group(1).strip()
                        if ant_match:
                            ant_text = ant_match.group(1).strip()
                    else:
                        # å˜—è©¦ç”¨ / æˆ– | åˆ†éš”
                        parts = re.split(r'[/|]', g_syn)
                        if len(parts) >= 2:
                            syn_text = parts[0].strip()
                            ant_text = parts[1].strip()
                        else:
                            syn_text = g_syn.strip()
                    
                    # çµ„åˆé¡¯ç¤º
                    if syn_text:
                        syn_ant_html += f'<span style="color:#2E8B57;">âœ¨Syn:{syn_text}</span>'
                    if ant_text:
                        if syn_text:
                            syn_ant_html += ' '
                        syn_ant_html += f'<span style="color:#CD5C5C;">â„ï¸Ant:{ant_text}</span>'
                    
                    if syn_ant_html:
                        all_grammar.append(syn_ant_html)
                
                # Grammarè§£æï¼ˆç¸®æ’å°é½Šï¼‰
                if g_grammar:
                    # è™•ç† 1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£4ï¸âƒ£ æ¨™è¨˜
                    text = str(g_grammar)
                    text = text.replace('1ï¸âƒ£[', '1ï¸âƒ£[')
                    text = text.replace('2ï¸âƒ£[', '<br>2ï¸âƒ£[')
                    text = text.replace('3ï¸âƒ£[', '<br>3ï¸âƒ£[')
                    text = text.replace('4ï¸âƒ£[', '<br>4ï¸âƒ£[')
                    all_grammar.append(text)
                
                # ä¿®æ­£ï¼šV2è³‡æ–™å®Œæ•´é¡¯ç¤ºï¼ˆå£èªè¨³ + Grammar + Note + Korean + THSV11ï¼‰
                v2_jp = v2_row.get('å£èªè¨³', '') if v2_row else ''
                v2_grammar = v2_row.get('Grammar', '') if v2_row else ''
                v2_note = v2_row.get('Note', '') if v2_row else ''
                v2_kr = v2_row.get('KRF', '') if v2_row else ''
                v2_kr_syn = v2_row.get('Korean Syn/Ant', '') if v2_row else ''
                v2_th = v2_row.get('THSV11', '') if v2_row else ''
                
                if v2_jp or v2_grammar or v2_note or v2_kr or v2_kr_syn or v2_th:
                    v2_parts = ["<br>"]  # åˆ†éš”ç·š
                    v2_ref = v2_row.get('Ref.', g_ref) if v2_row else g_ref
                    
                    if v2_jp:
                        v2_parts.append(f"<b>{v2_ref}</b>{v2_jp}")
                    
                    if v2_grammar:
                        v2_parts.append(f'<span style="color:#4682B4;">æ–‡æ³•ï¼š</span>{v2_grammar}')
                    if v2_note:
                        v2_parts.append(f'<span style="color:#D2691E;">å‚™è¨»ï¼š</span>{v2_note}')
                    if v2_kr:
                        v2_parts.append(f'<span style="color:#32CD32;">ğŸ‡°ğŸ‡· {v2_kr}</span>')
                    if v2_kr_syn:
                        v2_parts.append(f'<span style="color:#4682B4;">ğŸ‡°ğŸ‡· Syn/Ant: {v2_kr_syn}</span>')
                    if v2_th:
                        v2_parts.append(f'<span style="color:#9932CC;">ğŸ‡¹ğŸ‡­ {v2_th}</span>')
                    
                    all_grammar.append("<br>".join(v2_parts))
                    
            else:
                # æ¨¡å¼Bæ–‡æ³•ï¼ˆä¾†è‡ªGrammar Listï¼‰
                orig = (g_row.get('Original Sentence (from text)', '') or 
                        g_row.get('Original Sentence', ''))
                rule = g_row.get('Grammar Rule', '')
                analysis = (g_row.get('Analysis & Example (1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£4ï¸âƒ£)', '') or
                           g_row.get('Analysis & Example', '') or
                           g_row.get('Analysis', ''))
                
                html_parts = []
                
                # 1) ç¶“æ–‡ï¼šé»ƒè‰²å­—é«”ï¼ŒåŠ å¤§
                if orig:
                    html_parts.append(
                        f'<div style="margin-bottom:2px; color:#FFD700; font-size:15px; font-weight:bold;">'
                        f'{orig}</div>'
                    )
                
                # 2) è¦å‰‡+è§£æ
                if analysis:
                    af = str(analysis).strip()
                    
                    if rule:
                        af = af.replace('1ï¸âƒ£', f'ğŸ“Œ {rule}<br>1ï¸âƒ£', 1)
                    
                    # 1-4æ¨™é¡Œå‘ˆç¶ è‰²
                    af = af.replace(
                        '1ï¸âƒ£**[åˆ†æ®µè§£æ+èªæ³•æ¨™ç±¤]**ï¼š',
                        '<div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">1ï¸âƒ£[åˆ†æ®µè§£æ+èªæ³•æ¨™ç±¤]ï¼š</span>'
                    )
                    af = af.replace(
                        '2ï¸âƒ£**[è©æ€§è¾¨æ]**ï¼š',
                        '</div><div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">2ï¸âƒ£[è©æ€§è¾¨æ]ï¼š</span>'
                    )
                    af = af.replace(
                        '3ï¸âƒ£**[ä¿®è¾­èˆ‡çµæ§‹]**ï¼š',
                        '</div><div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">3ï¸âƒ£[ä¿®è¾­èˆ‡çµæ§‹]ï¼š</span>'
                    )
                    af = af.replace(
                        '4ï¸âƒ£**[èªæ„è§£é‡‹]**ï¼š',
                        '</div><div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">4ï¸âƒ£[èªæ„è§£é‡‹]ï¼š</span>'
                    )
                    
                    # å¦‚æœä¸Šé¢çš„æ²’åŒ¹é…åˆ°ï¼Œè©¦è©¦çœ‹æ²’æœ‰ ** çš„ç‰ˆæœ¬
                    af = af.replace(
                        '1ï¸âƒ£[åˆ†æ®µè§£æ+èªæ³•æ¨™ç±¤]ï¼š',
                        '<div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">1ï¸âƒ£[åˆ†æ®µè§£æ+èªæ³•æ¨™ç±¤]ï¼š</span>'
                    )
                    af = af.replace(
                        '2ï¸âƒ£[è©æ€§è¾¨æ]ï¼š',
                        '</div><div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">2ï¸âƒ£[è©æ€§è¾¨æ]ï¼š</span>'
                    )
                    af = af.replace(
                        '3ï¸âƒ£[ä¿®è¾­èˆ‡çµæ§‹]ï¼š',
                        '</div><div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">3ï¸âƒ£[ä¿®è¾­èˆ‡çµæ§‹]ï¼š</span>'
                    )
                    af = af.replace(
                        '4ï¸âƒ£[èªæ„è§£é‡‹]ï¼š',
                        '</div><div style="margin-top:2px; line-height:1.2;">'
                        '<span style="color:#2E8B57; font-weight:bold;">4ï¸âƒ£[èªæ„è§£é‡‹]ï¼š</span>'
                    )
                    
                    af = af + '</div>'
                    
                    html_parts.append(af)
                
                all_grammar = html_parts
                
            if all_grammar:
                grammar_html = "<br>".join(all_grammar)        
        # ============================================================
        # æ¸²æŸ“ç•«é¢
        # ============================================================
        col_left, col_right = st.columns([0.67, 0.33])
        
        with col_left:
            # å–®å­—å€å¡Š
            if vocab_display:
                st.markdown(
                    "<div style='margin-bottom:4px; line-height:1.6;'>" + 
                    " ; ".join(vocab_display) + 
                    "</div>", 
                    unsafe_allow_html=True
                )
            else:
                st.caption("ç„¡å–®å­—è³‡æ–™ï¼ˆè«‹ç¢ºèªæœ‰æ¨¡å¼Aè³‡æ–™ï¼‰")
            
            st.markdown("<hr style='margin:6px 0;'>", unsafe_allow_html=True)

            # ç‰‡èªå€å¡Š
            if w_phrases:
                for i, row in enumerate(w_phrases):
                    # å˜—è©¦å¤šç¨®å¯èƒ½çš„æ¬„ä½åç¨±ï¼ˆæ”¯æ´Markdownå’ŒCSVçš„æ¬„ä½åç¨±å·®ç•°ï¼‰
                    p = (row.get('Word/Phrase', '') or 
                         row.get('Word/phrase', '') or 
                         row.get('words/phrases', '') or 
                         row.get('Word', '') or
                         row.get('No', ''))
                    
                    c = (row.get('Chinese', '') or 
                         row.get('Chinese Meaning', '') or
                         row.get('Meaning', ''))
                    
                    s = (row.get('Synonym+ä¸­æ–‡å°ç…§', '') or 
                         row.get('Synonym', '') or 
                         row.get('Syn', ''))
                    
                    a = (row.get('Antonym+ä¸­æ–‡å°ç…§', '') or 
                         row.get('Antonym', '') or 
                         row.get('Ant', ''))
                    
                    bible_ex = (row.get('å…¨å¥è–ç¶“ä¸­è‹±å°ç…§ä¾‹å¥', '') or 
                               row.get('Bible Example', '') or 
                               row.get('Example', '') or
                               row.get('å…¨å¥è–ç¶“ä¸­è‹±å°ç…§ä¾‹å¥ ', ''))
                    
                    if p and p != str(i+16):  # ç¢ºä¿ä¸æ˜¯åªé¡¯ç¤ºç·¨è™Ÿ
                        parts = [f"ğŸ”¤ **{p}**"]
                        if c: 
                            parts.append(f"<span style='color:#666;'>{c}</span>")
                        if s or a:
                            sa_parts = []
                            if s: 
                                sa_parts.append(f"<span style='color:#2E8B57;'>âœ¨{s}</span>")
                            if a: 
                                sa_parts.append(f"<span style='color:#CD5C5C;'>â„ï¸{a}</span>")
                            parts.append("<span style='font-size:0.9em;'>" + " | ".join(sa_parts) + "</span>")
                        
                        st.markdown(
                            "<div style='margin-bottom:2px;'>" + " ".join(parts) + "</div>", 
                            unsafe_allow_html=True
                        )
                        
                        if bible_ex:
                            match = re.match(r'([^(]+)(\([^)]+\))?$', bible_ex)
                            if match:
                                eng_part = match.group(1).strip()
                                cn_part = match.group(2) if match.group(2) else ""
                                bible_html = f"<span style='font-size:1.15em; font-weight:500;'>{eng_part}</span> <span style='font-size:0.9em; color:#666;'>{cn_part}</span>"
                            else:
                                bible_html = f"<span style='font-size:1.15em;'>{bible_ex}</span>"
                            
                            st.markdown(
                                f"<div style='margin-bottom:4px; margin-left:20px;'>ğŸ“– {bible_html}</div>", 
                                unsafe_allow_html=True
                            )
                        
                        if i < len(w_phrases) - 1:
                            st.markdown("<div style='margin:4px 0;'></div>", unsafe_allow_html=True)
            else:
                st.caption(f"ç„¡ç‰‡èªè³‡æ–™ï¼ˆæ¨¡å¼B={len(all_mode_b)}å€‹ï¼‰")

            st.markdown("<hr style='margin:6px 0;'>", unsafe_allow_html=True)

            # é‡‘å¥å€å¡Š
            if verse_lines:
                st.markdown(f"<div style='margin-bottom:4px;'>{verse_lines[0]}</div>", unsafe_allow_html=True)
                for v in verse_lines[1:]:
                    st.markdown(f"<div style='margin-bottom:2px;'>{v}</div>", unsafe_allow_html=True)
            else:
                st.caption("ğŸ“– ç„¡é‡‘å¥è³‡æ–™ï¼ˆè«‹ç¢ºèªæœ‰æ¨¡å¼Aè³‡æ–™ï¼‰")

        with col_right:
            # æ–‡æ³•å€å¡Š
            st.markdown(f"""
                <div style="background-color:#1E1E1E; color:#FFFFFF; padding:10px; border-radius:8px; 
                            border-left:4px solid #FF8C00; font-size:13px; line-height:1.5; 
                            min-height:100%; display:flex; flex-direction:column;">
                    {grammar_html}
                </div>
                """, unsafe_allow_html=True)
            
            minutes_left = max(0, (3600 - time_diff) / 60)
            st.caption(f"å–®å­—:{current_vocab_ref} | ç‰‡èª:{current_phrase_ref} | é‡‘å¥:{current_verse_ref}")
            st.caption(f"æ–‡æ³•:{current_grammar_ref} | {minutes_left:.0f}åˆ†å¾Œæ›´æ–°")
            st.caption(f"è³‡æ–™çµ±è¨ˆ: A={len(all_mode_a)}å€‹, B={len(all_mode_b)}å€‹, æ–‡æ³•={len(all_grammar_sources)}å€‹")
