# ===================================================================
# 0. å¥—ä»¶ & å…¨åŸŸå‡½å¼ï¼ˆä¸€å®šæ”¾æœ€é ‚ï¼‰
# ===================================================================
import streamlit as st
import subprocess, sys, os, datetime as dt, pandas as pd, io, json

# ---------- å…¨åŸŸå·¥å…·å‡½å¼ ----------
def save_analysis_result(result, input_text):
    if "analysis_history" not in st.session_state:
        st.session_state.analysis_history = []
    st.session_state.analysis_history.append({
        "date": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
        "input_preview": input_text[:50] + "..." if len(input_text) > 50 else input_text,
        "result": result
    })
    if len(st.session_state.analysis_history) > 10:
        st.session_state.analysis_history.pop(0)

def to_excel(result: dict) -> bytes:
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        for sheet, key in [("Words", "words"), ("Phrases", "phrases"), ("Grammar", "grammar")]:
            if key in result and result[key]:
                pd.DataFrame(result[key]).to_excel(writer, sheet_name=sheet, index=False)
        stats = pd.DataFrame({
            "é …ç›®": ["ç¸½å­—å½™æ•¸", "ç¸½ç‰‡èªæ•¸", "æ–‡æ³•é»æ•¸", "åˆ†ææ—¥æœŸ"],
            "æ•¸å€¼": [
                len(result.get("words", [])),
                len(result.get("phrases", [])),
                len(result.get("grammar", [])),
                dt.date.today().strftime("%Y-%m-%d")
            ]
        })
        stats.to_excel(writer, sheet_name="çµ±è¨ˆ", index=False)
    buffer.seek(0)
    return buffer.getvalue()

# ===================================================================
# 1. å´é‚Šæ¬„ï¼ˆä¸€æ¬¡ 4 é€£çµï¼Œç„¡é‡è¤‡ï¼‰
# ===================================================================
with st.sidebar:
    st.divider()
    c1, c2 = st.columns(2)
    c1.link_button("âœ¨ Google AI", "https://gemini.google.com/")
    c2.link_button("ğŸ¤– Kimi K2",   "https://kimi.moonshot.cn/")
    c3, c4 = st.columns(2)
    c3.link_button("ESV Bible", "https://wd.bible/bible/gen.1.cunps?parallel=esv.klb.jcb")
    c4.link_button("THSV11",    "https://www.bible.com/zh-TW/bible/174/GEN.1.THSV11")

# ===================================================================
# 2. é é¢é…ç½® & Session åˆå€¼
# ===================================================================
st.set_page_config(layout="wide", page_title="Bible Study AI App 2026")

if 'events'   not in st.session_state: st.session_state.events   = []
if 'notes'    not in st.session_state: st.session_state.notes    = {}
if 'todo'     not in st.session_state: st.session_state.todo     = {}
if 'custom_emojis' not in st.session_state: st.session_state.custom_emojis = ["ğŸ¾", "ğŸ°", "ğŸ¥°", "âœ¨", "ğŸ¥•", "ğŸŒŸ"]
if 'sel_date' not in st.session_state: st.session_state.sel_date = str(dt.date.today())
if 'modal'    not in st.session_state: st.session_state.modal    = None
if 'analysis_history' not in st.session_state: st.session_state.analysis_history = []

# ---------- CSS ----------
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Gamja+Flower&display=swap');
.cute-korean { font-family: 'Gamja Flower', cursive; font-size: 20px; color: #FF8C00; text-align: center; }
.small-font { font-size: 13px; color: #555555; margin-top: 5px !important; }
.grammar-box-container {
    background-color: #f8f9fa; border-radius: 8px; padding: 12px; 
    border-left: 5px solid #FF8C00; text-align: left; margin-top: 0px;
}
.fc-daygrid-day-frame:hover {background-color: #FFF3CD !important; cursor: pointer; transform: scale(1.03); transition: .2s}
.fc-daygrid-day-frame:active {transform: scale(0.98); background-color: #FFE69C !important}
</style>
""", unsafe_allow_html=True)

# ---------- åœ–ç‰‡ & ç¾æˆ TAB ----------
IMG_URLS = {
    "A": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/183ebb183330643.Y3JvcCw4MDgsNjMyLDAsMA.jpg",
    "B": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/f364bd220887627.67cae1bd07457.jpg",
    "C": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/68254faebaafed9dafb41918f74c202e.jpg",
    "M1": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro1.jpg",
    "M2": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro2.jpg",
    "M3": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro3.jpg",
    "M4": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro4.jpg"
}
with st.sidebar:
    st.markdown('<p class="cute-korean">ë‹¹ì‹ ì€ í•˜ë‚˜ë‹˜ì˜ ì†Œì¤‘í•œ ë³´ë¬¼ì…ë‹ˆë‹¤</p>', unsafe_allow_html=True)
    st.image(IMG_URLS["M3"], width=250)
    st.divider()

tabs = st.tabs(["ğŸ  æ›¸æ¡Œ", "ğŸ““ ç­†è¨˜", "âœï¸ æŒ‘æˆ°", "ğŸ“‚ è³‡æ–™åº«"])

# ===================================================================
# 3. TAB1 â”€ æ›¸æ¡Œï¼ˆåŸå…§å®¹ï¼Œæœªå‹•ï¼‰
# ===================================================================
with tabs[0]:
    col_content, col_m1 = st.columns([0.65, 0.35])
    with col_content:
        st.info("**Becoming** / ğŸ‡¯ğŸ‡µ ãµã•ã‚ã—ã„ | ğŸ‡°ğŸ‡· ì–´ìš¸ë¦¬ëŠ” | ğŸ‡¹ğŸ‡­ à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ | ğŸ‡¨ğŸ‡³ ç›¸ç¨±")
        st.success("""
            ğŸŒŸ **Pro 17:07** Fine speech is not becoming to a fool; still less is false speech to a prince.   
            ğŸ‡¯ğŸ‡µ ã™ãã‚ŒãŸè¨€è‘‰ã¯æ„šã‹è€…ã«ã¯ãµã•ã‚ã—ããªã„ã€‚å½ã‚Šã®è¨€è‘‰ã¯å›ä¸»ã«ã¯ãªãŠã•ã‚‰ãµã•ã‚ã—ããªã„ã€‚   
            ğŸ‡¨ğŸ‡³ æ„šé ‘äººèªªç¾è¨€æœ¬ä¸ç›¸ç¨±ï¼Œä½•æ³å›ç‹èªªè¬Šè©±å‘¢ï¼Ÿ
            """, icon="ğŸ“–")
    with col_m1:
        st.markdown(f"""
            <div style="display:flex;flex-direction:column;justify-content:space-between;height:100%;min-height:250px;text-align:center;">
                <div style="flex-grow:1;display:flex;align-items:center;justify-content:center;">
                    <img src="{IMG_URLS['M1']}" style="width:200px;margin-bottom:10px;">
                </div>
                <div class="grammar-box-container" style="margin-top:auto;">
                    <p style="margin:2px 0;font-size:14px;font-weight:bold;color:#333;">æ™‚æ…‹: ç¾åœ¨ç°¡å–®å¼</p>
                    <p style="margin:2px 0;font-size:14px;font-weight:bold;color:#333;">æ ¸å¿ƒç‰‡èª:</p>
                    <ul style="margin:0;padding-left:18px;font-size:13px;line-height:1.4;color:#555;">
                        <li>Fine speech (å„ªç¾è¨€è¾­)</li>
                        <li>Becoming to (ç›¸ç¨±)</li>
                        <li>Still less (ä½•æ³)</li>
                        <li>False speech (è™›å‡è¨€è¾­)</li>
                    </ul>
                </div>
            </div>
        """, unsafe_allow_html=True)
    st.divider()
    st.markdown("### âœï¸ æ–‡æ³•é‹ç”¨ä¾‹å¥")
    cl1, cl2 = st.columns(2)
    with cl1:
        st.markdown("**Ex 1:** *Casual attire is not becoming to a CEO; still less is unprofessional language.* <p class='small-font'>ä¾¿æœå°åŸ·è¡Œé•·ä¸ç›¸ç¨±ï¼›æ›´ä¸ç”¨èªªä¸å°ˆæ¥­çš„è¨€èªäº†ã€‚</p>", unsafe_allow_html=True)
    with cl2:
        st.markdown("**Ex 2:** *Wealth is not becoming to a man without virtue; still less is power.* <p class='small-font'>è²¡å¯Œå°æ–¼ç„¡å¾·ä¹‹äººä¸ç›¸ç¨±ï¼›æ›´ä¸ç”¨èªªæ¬ŠåŠ›äº†ã€‚</p>", unsafe_allow_html=True)

# ===================================================================
# TAB2 â”€ é‡‘å¥é›†ï¼ˆ5-5-4 ç¾¤æŠ˜ç–Šï¼Œçµæ§‹ä¸€è‡´ï¼‰
# ===================================================================
with tabs[1]:
    import datetime as dt

    today = dt.date.today()
    # ---- 14 å¥ï¼š5-5-4 ç¾¤ï¼Œçµæ§‹ä¸€è‡´ ----
    VERSES = [
        # ç¬¬ 1 ç¾¤ï¼ˆ5 å¥ï¼‰
        {"ref": "2Ti 3:10-11", "en": "You, however, have followed my teaching, my conduct, my aim in life, my faith, my patience, my love, my steadfastness, my persecutions and sufferings that happened to me at Antioch, at Iconium, and at Lystraâ€”which persecutions I endured; yet from them all the Lord rescued me.",
         "zh": "ä½†ä½ å·²ç¶“è¿½éš¨äº†æˆ‘çš„æ•™å°ã€å“è¡Œã€å¿—å‘ã€ä¿¡å¿ƒã€å¯¬å®¹ã€æ„›å¿ƒã€å¿è€ï¼Œä»¥åŠæˆ‘åœ¨å®‰æé˜¿ã€ä»¥å“¥å¿µã€å‘‚æ–¯ç‰¹æ‹‰æ‰€é­é‡çš„é€¼è¿«å’Œè‹¦é›£ï¼›æˆ‘æ‰€å¿å—çš„æ˜¯ä½•ç­‰çš„é€¼è¿«ï¼ä½†å¾é€™ä¸€åˆ‡ç•¶ä¸­ï¼Œä¸»éƒ½æŠŠæˆ‘æ•‘äº†å‡ºä¾†ã€‚"},
        {"ref": "2Ti 3:12", "en": "Indeed, all who desire to live a godly life in Christ Jesus will be persecuted,",
         "zh": "ä¸ä½†å¦‚æ­¤ï¼Œå‡¡ç«‹å¿—åœ¨åŸºç£è€¶ç©Œè£¡æ•¬è™”åº¦æ—¥çš„ï¼Œä¹Ÿéƒ½è¦å—é€¼è¿«ã€‚"},
        {"ref": "2Ti 3:13", "en": "while evil people and impostors will go on from bad to worse, deceiving and being deceived.",
         "zh": "ä½†æƒ¡äººå’Œé¨™å­å¿…è®Šæœ¬åŠ å²ï¼Œè¿·æƒ‘äººä¹Ÿå—è¿·æƒ‘ã€‚"},
        {"ref": "2Ti 3:14", "en": "But as for you, continue in what you have learned and have firmly believed, knowing from whom you learned it",
         "zh": "è‡³æ–¼ä½ ï¼Œè¦æŒå®ˆä½ æ‰€å­¸ç¿’çš„ã€æ‰€ç¢ºä¿¡çš„ï¼Œå› ç‚ºä½ çŸ¥é“æ˜¯è·Ÿèª°å­¸çš„ã€‚"},
        {"ref": "2Ti 3:15", "en": "and how from childhood you have been acquainted with the sacred writings, which are able to make you wise for salvation through faith in Christ Jesus.",
         "zh": "ä¸¦ä¸”ä½ å¾å°å°±æ˜ç™½è–ç¶“ï¼Œé€™è–ç¶“èƒ½ä½¿ä½ å› ä¿¡åŸºç£è€¶ç©Œè€Œæœ‰å¾—æ•‘çš„æ™ºæ…§ã€‚"},
        # ç¬¬ 2 ç¾¤ï¼ˆ5 å¥ï¼‰
        {"ref": "2Ti 3:16", "en": "All Scripture is breathed out by God and profitable for teaching, for reproof, for correction, and for training in righteousness,",
         "zh": "è–ç¶“éƒ½æ˜¯ç¥æ‰€é»˜ç¤ºçš„ï¼Œæ–¼æ•™è¨“ã€ç£è²¬ã€ä½¿äººæ­¸æ­£ã€æ•™å°äººå­¸ç¾©éƒ½æ˜¯æœ‰ç›Šçš„ã€‚"},
        {"ref": "2Ti 3:17", "en": "that the man of God may be complete, equipped for every good work.",
         "zh": "å«å±¬ç¥çš„äººå¾—ä»¥å®Œå…¨ï¼Œé å‚™è¡Œå„æ¨£çš„å–„äº‹ã€‚"},
        {"ref": "2Ti 3:10-11", "en": "High-Word: Conduct (å“è¡Œ) / Persecution (é€¼è¿«) / Steadfastness (å …å¿)",
         "zh": "é«˜éšè©å½™ï¼šå“è¡Œã€é€¼è¿«ã€å …å¿ â€”â€” ä½ å·²è¿½éš¨äº†æˆ‘çš„æ•™å°èˆ‡å“è¡Œï¼›æˆ‘æ‰€å¿å—çš„é€¼è¿«ï¼Œä¸»éƒ½æ•‘æˆ‘è„«é›¢ã€‚"},
        {"ref": "2Ti 3:12-13", "en": "High-Word: Godly (æ•¬è™”) / Impostors (é¨™å­)",
         "zh": "é«˜éšè©å½™ï¼šæ•¬è™”ã€é¨™å­ â€”â€” å‡¡ç«‹å¿—éæ•¬è™”ç”Ÿæ´»çš„éƒ½è¦å—é€¼è¿«ï¼›æƒ¡äººèˆ‡é¨™å­è®Šæœ¬åŠ å²ã€‚"},
        {"ref": "2Ti 3:14-15", "en": "High-Word: Acquainted (ç†Ÿæ‚‰) / Salvation (æ•‘æ©)",
         "zh": "é«˜éšè©å½™ï¼šç†Ÿæ‚‰ã€æ•‘æ© â€”â€” å¾å°ç†Ÿæ‚‰è–ç¶“ï¼Œä½¿ä½ å› ä¿¡åŸºç£è€Œæœ‰å¾—æ•‘æ™ºæ…§ã€‚"},
        # ç¬¬ 3 ç¾¤ï¼ˆ4 å¥ï¼‰
        {"ref": "2Ti 3:16-17", "en": "High-Word: Breathed out (é»˜ç¤º) / Equipped (è£å‚™)",
         "zh": "é«˜éšè©å½™ï¼šé»˜ç¤ºã€è£å‚™ â€”â€” è–ç¶“çš†ç¥æ‰€é»˜ç¤ºï¼Œä½¿å±¬ç¥ä¹‹äººå¾—ä»¥å®Œå…¨ï¼Œè£å‚™è¡Œå–„ã€‚"},
        {"ref": "2Ti 3:16", "en": "High-Word: Profitable (æœ‰ç›Š) / Reproof (è²¬å‚™) / Righteousness (å…¬ç¾©)",
         "zh": "é«˜éšè©å½™ï¼šæœ‰ç›Šã€è²¬å‚™ã€å…¬ç¾© â€”â€” è–ç¶“æ–¼æ•™è¨“ã€ç£è²¬ã€ä½¿äººæ­¸æ­£ã€æ•™å°äººå­¸ç¾©çš†æœ‰ç›Šã€‚"},
        {"ref": "2Ti 3:17", "en": "High-Word: Complete (å®Œå…¨) / Equipped (è£å‚™)",
         "zh": "é«˜éšè©å½™ï¼šå®Œå…¨ã€è£å‚™ â€”â€” ä½¿å±¬ç¥çš„äººå¾—ä»¥å®Œå…¨ï¼Œç‚ºå„æ¨£å–„äº‹é å‚™é½Šå…¨ã€‚"},
        {"ref": "2Ti 3:10-17", "en": "High-Word: Vitality (ç”Ÿå‘½åŠ›) / Aligned (å°é½Š) / Infrastructure (åŸºç¤æ¶æ§‹)",
         "zh": "é«˜éšè©å½™ï¼šç”Ÿå‘½åŠ›ã€å°é½Šã€åŸºç¤æ¶æ§‹ â€”â€” è©±èªå¸¶ä¾†ç”Ÿå‘½åŠ›ï¼Œä½¿äººç”Ÿèˆ‡ç¥å°é½Šï¼Œä¿¡å¿ƒç‚ºéˆé­‚æ ¹åŸºã€‚"}
    ]

    # åªè¼‰ä¸€æ¬¡ï¼Œç•¶æ°¸ä¹…åº«
    if "sentences" not in st.session_state:
        st.session_state.sentences = {str(dt.date.today() - dt.timedelta(days=i)): VERSES[i] for i in range(14)}

    # ---- ä¸€æ¬¡å‘ˆç¾ 14 å¥ï¼šä¸­æ–‡æ•´å¥ + è‹±æ–‡ 3 ç¾¤æŠ˜ç–Šï¼ˆ5-5-4ï¼‰ ----
    st.subheader("ğŸ“’ é‡‘å¥é›†")
    # ---------- è‹±æ–‡ 3 ç¾¤æŠ˜ç–Šï¼ˆ5-5-4ï¼‰ ----
    group_size = [5, 5, 4]
    start = 0
    for g, size in enumerate(group_size, 1):
        with st.expander(f"ğŸ“‘ è‹±æ–‡è§£ç­” ç¬¬ {g} çµ„ï¼ˆé»æˆ‘çœ‹ï¼‰"):
            for i in range(start, start + size):
                v = st.session_state.sentences[str(dt.date.today() - dt.timedelta(days=i))]
                st.markdown(f"**{v.get('ref', '')}**  \n{v['en']}")
                st.markdown('<div style="line-height:0.5;font-size:1px;">&nbsp;</div>', unsafe_allow_html=True)
            start += size

    # ---------- ä¸­æ–‡æ•´å¥ç›´æ¥é¡¯ç¤ºï¼ˆç•¶é¡Œç›®ï¼‰ ----
    for i in range(14):
        d = str(dt.date.today() - dt.timedelta(days=i))
        v = st.session_state.sentences[d]
        st.markdown(f"**{d[-5:]}**ï½œ{v.get('ref', '')}  \n{v['zh']}")
        st.markdown('<div style="line-height:0.5;font-size:1px;">&nbsp;</div>', unsafe_allow_html=True)

    # ---- å…¶é¤˜åŸåŠŸèƒ½ï¼šæ–°å¢ã€åŒ¯å‡º ----
    with st.expander("âœ¨ æ–°å¢é‡‘å¥", expanded=True):
        new_sentence = st.text_input("ä¸­è‹±ä¸¦åˆ—", key="new_sentence")
        if st.button("å„²å­˜", type="primary"):
            if new_sentence:
                st.session_state.sentences[str(dt.date.today())] = new_sentence
                st.success("å·²å„²å­˜ï¼")
            else:
                st.error("è«‹è¼¸å…¥å…§å®¹")
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºåº«"):
                st.session_state.sentences.clear()
                st.success("å·²æ¸…ç©ºï¼")
          
    if st.button("ğŸ“‹ åŒ¯å‡ºé‡‘å¥åº«"):
        export = "\n".join([f"{k}  {v['ref']}  {v['en']}  {v['zh']}" for k, v in st.session_state.sentences.items()])
        st.code(export, language="text")

# ===================================================================
# 5. TAB3 â”€ æŒ‘æˆ°ï¼ˆåŸç¢¼ï¼Œæœªå‹•ï¼‰
# ===================================================================
with tabs[2]:
    col_challenge, col_deco = st.columns([0.7, 0.3])
    with col_challenge:
        st.subheader("ğŸ“ ç¿»è­¯æŒ‘æˆ°")
        st.write("é¡Œç›® 1: æ„šé ‘äººèªªç¾è¨€æœ¬ä¸ç›¸ç¨±...")
        st.text_input("è«‹è¼¸å…¥è‹±æ–‡ç¿»è­¯", key="ans_1_final", placeholder="Type your translation here...")
    with col_deco:
        st.image(IMG_URLS.get("B"), width=150, caption="Keep Going!")

# ===================================================================
# TAB4 â”€ AI æ§åˆ¶å°ï¼ˆæœ€çµ‚æ¸…æƒåŒ…ï¼š800 ç­†æç¤º + åˆªèªªæ˜ + ç¶“æ–‡å¯æœ + ç„¡æ¨™é¡Œ + åœ–ç¤ºæœ€å‰ï¼‰
# ===================================================================
with tabs[3]:
    import os, datetime as dt, json, subprocess, sys, pandas as pd, io

    # â‘  é›²ç«¯é‡‘é‘°
    API_KEY = os.getenv("GEMINI_API_KEY") or os.getenv("KIMI_API_KEY")
    if not API_KEY:
        st.warning("âš ï¸ å°šæœªè¨­å®š GEMINI_API_KEY æˆ– KIMI_API_KEYï¼Œè«‹è‡³ Streamlit-Secrets åŠ å…¥é‡‘é‘°å¾Œé‡æ–°å•Ÿå‹•ã€‚")
        st.stop()

    # â‘¡ æœ€å¤§å…±ç”¨æ¬„ä½ï¼šAI åˆ†æ + å·¨é‡åˆªé™¤ ä¸‰åˆä¸€ï¼ˆåœ–ç¤ºæ”¾æœ€å‰ï¼Œå¾Œæ–¹æ–‡å­—åˆªé™¤ï¼‰
    with st.expander("ğŸ“šâ‘  è²¼ç¶“æ–‡/è¬›ç¨¿ â†’ â‘¡ ä¸€éµåˆ†æ â†’ â‘¢ ç›´æ¥æª¢è¦– â†’ â‘£ é›¢ç·šä½¿ç”¨", expanded=True):
        input_text = st.text_area("", height=300, key="input_text")   # ç„¡æ¨™é¡Œï¼ŒçœŸæ­£æœ€å¤§ç•«é¢

        # ä¸‰åˆä¸€æ“ä½œåˆ—ï¼ˆåŒä¸€æ’ï¼‰
        col_op1, col_op2, col_op3 = st.columns([2, 2, 1])
        with col_op1:
            search_type = st.selectbox("æ“ä½œ", ["AI åˆ†æ", "Ref. åˆªé™¤", "é—œéµå­—åˆªé™¤"])
        with col_op2:
            if search_type == "Ref. åˆªé™¤":
                ref_query = st.text_input("è¼¸å…¥ Ref.ï¼ˆä¾‹ï¼š2Ti 3:10ï¼‰", key="ref_del")
            elif search_type == "é—œéµå­—åˆªé™¤":
                kw_query = st.text_input("è¼¸å…¥é—œéµå­—", key="kw_del")
        with col_op3:
            if st.button("ğŸ—‘ï¸ å·¨é‡åˆªé™¤", type="primary"):
                # å…±ç”¨åŒä¸€å€‹æœå°‹é‚è¼¯ï¼ˆå«ç¶“ç¯€ï¼‰
                hits = []
                for d, v in st.session_state.sentences.items():
                    txt = f"{v.get('ref', '')} {v.get('en', '')} {v.get('zh', '')}".lower()
                    if search_type == "Ref. åˆªé™¤" and ref_query.lower() in v.get('ref', '').lower():
                        hits.append((d, v))
                    elif search_type == "é—œéµå­—åˆªé™¤" and kw_query.lower() in txt:
                        hits.append((d, v))
                if hits:
                    st.write(f"å…± {len(hits)} ç­†ï¼ˆå«è–ç¶“ç¶“ç¯€ï¼‰")
                    selected_keys = st.multiselect("å‹¾é¸è¦åˆªé™¤çš„é …ç›®", [d for d, _ in hits])
                    if st.button("ç¢ºèªåˆªé™¤", type="secondary"):
                        for k in selected_keys:
                            st.session_state.sentences.pop(k, None)
                        st.success(f"å·²åˆªé™¤ {len(selected_keys)} ç­†ï¼")
                        st.experimental_rerun()
                else:
                    st.info("ç„¡ç¬¦åˆæ¢ä»¶")

        # â‘¢ AI åˆ†ææŒ‰éˆ•ï¼ˆèˆ‡ä¸Šæ–¹åŒä¸€æ’ï¼‰
        if search_type == "AI åˆ†æ":
            if st.button("ğŸ¤– AI åˆ†æ", type="primary"):
                if not input_text:
                    st.error("è«‹å…ˆè²¼ç¶“æ–‡")
                    st.stop()
                with st.spinner("AI åˆ†æä¸­ï¼Œç´„ 10 ç§’â€¦"):
                    try:
                        subprocess.run([sys.executable, "analyze_to_excel.py", "--file", "temp_input.txt"],
                                       check=True, timeout=30)
                        with open("temp_result.json", "r", encoding="utf-8") as f:
                            data = json.load(f)
                        save_analysis_result(data, input_text)
                        st.session_state["analysis"] = data
                        st.success("åˆ†æå®Œæˆï¼")
                        # 800 ç­†æç¤º
                        current_count = len(st.session_state.get("analysis_history", []))
                        if current_count >= 800:
                            st.warning("ğŸ”” åˆ†æç´€éŒ„å·²é” 800 ç­†ï¼Œå»ºè­°ä½¿ç”¨ã€Œå£“ç¸®èˆŠç´€éŒ„ã€åŠŸèƒ½ï¼Œé¿å…ç€è¦½å™¨å¡é “ï¼")
                        if st.checkbox("åˆ†æå®Œè‡ªå‹•å±•é–‹", value=True):
                            st.session_state["show_result"] = True
                    except Exception as e:
                        st.error(f"åˆ†æéç¨‹éŒ¯èª¤ï¼š{e}")

    # â‘£ çµæœå‘ˆç¾ï¼ˆæ»¿å¯¬ + å›æº¯åŸæ–‡ï¼‰
    if st.session_state.get("show_result", False):
        data = st.session_state["analysis"]

        # Ref. å…¨åŸŸç·¨è™Ÿ + åŸæ–‡è·³è½‰
        st.session_state["ref_no"] = data.get("ref_no", "")
        st.session_state["ref_article"] = data.get("ref_article", "")
        st.markdown(f"**Ref. No.** `{st.session_state['ref_no']}`")
        c_jump, c_copy = st.columns(2)
        with c_jump:
            if st.button("ğŸ“„ æª¢è¦–åŸæ–‡"):
                st.session_state["show_article"] = True
        with c_copy:
            ref_no = st.session_state.get("ref_no", "")
            if ref_no:
                st.code(ref_no)          # æ‰‹å‹•æ¡†é¸è¤‡è£½
            else:
                st.text("å°šç„¡ Ref.")

        if st.session_state.get("show_article", False):
            with st.expander("ğŸ“˜ ä¸­è‹±ç²¾ç…‰æ–‡ç« ", expanded=True):
                st.markdown(st.session_state["ref_article"])

        # è¡¨æ ¼å‘ˆç¾ï¼ˆå®¹éŒ¯ + å›æº¯åŸæ–‡ï¼‰
        col_w, col_p, col_g = st.tabs(["å–®å­—", "ç‰‡èª", "æ–‡æ³•"])
        with col_w:
            if data.get("words"):
                df = pd.DataFrame(data["words"])
                df.insert(0, "Ref.", data.get("ref_no", ""))
                df["ğŸ”"] = "ğŸ”"
                st.dataframe(df, use_container_width=True)
            else:
                st.info("æœ¬æ¬¡ç„¡å–®å­—åˆ†æ")
        with col_p:
            if data.get("phrases"):
                df = pd.DataFrame(data["phrases"])
                df.insert(0, "Ref.", data.get("ref_no", ""))
                df["ğŸ”"] = "ğŸ”"
                st.dataframe(df, use_container_width=True)
            else:
                st.info("æœ¬æ¬¡ç„¡ç‰‡èªåˆ†æ")
        with col_g:
            if data.get("grammar"):
                df = pd.DataFrame(data["grammar"])
                df.insert(0, "Ref.", data.get("ref_no", ""))
                df["ğŸ”"] = "ğŸ”"
                st.table(df)
            else:
                st.info("æœ¬æ¬¡ç„¡æ–‡æ³•é»")

    # â‘¤ å®¹é‡ç®¡ç†ï¼ˆç™½è©±èªªæ˜ + 800 ç­†æç¤ºï¼‰
    with st.expander("âš™ï¸ å®¹é‡ç®¡ç†", expanded=True):
        max_keep = st.number_input("æœ€å¤šä¿ç•™æœ€è¿‘å¹¾ç­†åˆ†æç´€éŒ„", min_value=10, max_value=1000, value=50)
        if st.button("âœ‚ï¸ å£“ç¸®èˆŠç´€éŒ„"):
            hist = st.session_state.get("analysis_history", [])
            if len(hist) > max_keep:
                st.session_state.analysis_history = hist[-max_keep:]
                st.success(f"å·²å£“ç¸®è‡³æœ€è¿‘ {max_keep} ç­†ï¼")
            else:
                st.info("æœªé”å£“ç¸®é–€æª»")

    # â‘¥ åŒ¯å‡ºï¼ˆå«å›æº¯æ¬„ä½ï¼‰
    if st.button("ğŸ“‹ åŒ¯å‡ºå«å›æº¯æ¬„ä½"):
        export = []
        for k, v in st.session_state.sentences.items():
            export.append(f"{k}\t{v.get('ref', '')}\t{v.get('en', '')}\t{v.get('zh', '')}")
        st.code("\n".join(export), language="text")
