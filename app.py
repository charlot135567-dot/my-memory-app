# ===================================================================
# 0. å¥—ä»¶ & å…¨åŸŸå‡½å¼ï¼ˆä¸€å®šæ”¾æœ€é ‚ï¼‰
# ===================================================================
import streamlit as st  
import subprocess, sys, os, datetime as dt, pandas as pd, io, json, re, tomli, tomli_w
from streamlit_calendar import calendar
import streamlit.components.v1 as components
import requests

# åœ¨æ–‡ä»¶æœ€é–‹å§‹åˆå§‹åŒ–æ‰€æœ‰ session state è®Šé‡
def init_session_state():
    defaults = {
        "is_prompt_generated": False,
        # å…¶ä»–è®Šé‡...
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

init_session_state()

# ---------- å…¨åŸŸå·¥å…·å‡½å¼ ----------
def save_analysis_result(result, input_text):
    if "analysis_history" not in st.session_state:
        st.session_state.analysis_history = []
    st.session_state.analysis_history.append({
        "date": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
        "input_preview": input_text[:50] + "..." if len(input_text) > 50 else input_text,
        "result": result
    })
    if len(st.session_state.analysis_history) > 10:
        st.session_state.analysis_history.pop(0)

def to_excel(result: dict) -> bytes:
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        for sheet, key in [("Words", "words"), ("Phrases", "phrases"), ("Grammar", "grammar")]:
            if key in result and result[key]:
                pd.DataFrame(result[key]).to_excel(writer, sheet_name=sheet, index=False)
        stats = pd.DataFrame({
            "é …ç›®": ["ç¸½å­—å½™æ•¸", "ç¸½ç‰‡èªæ•¸", "æ–‡æ³•é»æ•¸", "åˆ†ææ—¥æœŸ"],
            "æ•¸å€¼": [
                len(result.get("words", [])),
                len(result.get("phrases", [])),
                len(result.get("grammar", [])),
                dt.date.today().strftime("%Y-%m-%d")
            ]
        })
        stats.to_excel(writer, sheet_name="çµ±è¨ˆ", index=False)
    buffer.seek(0)
    return buffer.getvalue()

# ===================================================================
# 1. å´é‚Šæ¬„ï¼ˆä¸€æ¬¡ 4 é€£çµï¼Œç„¡é‡è¤‡ï¼‰
# ===================================================================
with st.sidebar:
    st.divider()
    c1, c2 = st.columns(2)
    c1.link_button("âœ¨ Google AI", "https://gemini.google.com/")
    c2.link_button("ğŸ¤– Kimi K2",   "https://kimi.moonshot.cn/")
    c3, c4 = st.columns(2)
    c3.link_button("ESV Bible", "https://wd.bible/bible/gen.1.cunps?parallel=esv.klb.jcb")
    c4.link_button("THSV11",    "https://www.bible.com/zh-TW/bible/174/GEN.1.THSV11")
    
    # âœ… åŠ åœ¨é€™è£¡ï¼ˆä»åœ¨ with st.sidebar: å…§éƒ¨ï¼‰
    st.divider()
    st.markdown("### ğŸ–¼ï¸ åº•éƒ¨èƒŒæ™¯è¨­å®š")
    
    bg_options = {
        "ğŸ¶ Snoopy": "Snoopy.jpg",
        "ğŸ° Mashimaro 1": "Mashimaro1.jpg",
        "ğŸ° Mashimaro 2": "Mashimaro2.jpg",
        "ğŸ° Mashimaro 3": "Mashimaro3.jpg",
        "ğŸ° Mashimaro 4": "Mashimaro4.jpg",
        "ğŸ° Mashimaro 5": "Mashimaro5.jpg",
        "ğŸ° Mashimaro 6": "Mashimaro6.jpg"
    }
    
    if 'selected_bg' not in st.session_state:
        st.session_state.selected_bg = list(bg_options.keys())[0]
    if 'bg_size' not in st.session_state:
        st.session_state.bg_size = 15
    if 'bg_bottom' not in st.session_state:
        st.session_state.bg_bottom = 30
    
    selected_bg = st.selectbox(
        "é¸æ“‡è§’è‰²", 
        list(bg_options.keys()), 
        index=list(bg_options.keys()).index(st.session_state.selected_bg),
        key="selected_bg"
    )
    
    col1, col2 = st.columns(2)
    with col1:
        bg_size = st.slider("åœ–ç‰‡å¤§å°", 5, 50, st.session_state.bg_size, format="%d%%", key="bg_size")
    with col2:
        bg_bottom = st.slider("åº•éƒ¨é–“è·", 0, 100, st.session_state.bg_bottom, format="%dpx", key="bg_bottom")

# âœ… æ³¨æ„é€™è£¡å·²ç¶“ä¸åœ¨ with st.sidebar: è£¡é¢äº†ï¼
# èƒŒæ™¯ CSS è¦æ”¾åœ¨é€™è£¡ï¼ˆsidebar å¤–é¢ï¼Œä½†åœ¨ tabs å‰é¢ï¼‰
selected_img_file = bg_options[st.session_state.selected_bg]
current_bg_size = st.session_state.bg_size
current_bg_bottom = st.session_state.bg_bottom

# ---------- èƒŒæ™¯åœ–ç‰‡å¥—ç”¨ï¼ˆè£œä¸Šé€™æ®µï¼ï¼‰----------
try:
    if os.path.exists(selected_img_file):
        with open(selected_img_file, "rb") as f:
            img_b64 = base64.b64encode(f.read()).decode()
        st.markdown(f"""
        <style>
        .stApp {{
            background-image: url("data:image/jpeg;base64,{img_b64}");
            background-size: {current_bg_size}% auto;
            background-position: center bottom {current_bg_bottom}px;
            background-attachment: fixed;
            background-repeat: no-repeat;
            z-index: 0;
        }}
        .main .block-container {{
            position: relative;
            z-index: 1;
            padding-bottom: {current_bg_bottom + 100}px;
        }}
        </style>
        """, unsafe_allow_html=True)
except:
    pass  # èƒŒæ™¯åœ–å¤±æ•—æ™‚éœé»˜è™•ç†

# ===================================================================
# 2. é é¢é…ç½® & Session åˆå€¼ï¼ˆåªç•™å…¨åŸŸæœƒç”¨åˆ°çš„ï¼‰
# ===================================================================
st.set_page_config(layout="wide", page_title="Bible Study AI App 2026")

# é€™äº›è®Šæ•¸åªæœ‰ TAB2 æœƒç”¨åˆ°ï¼Œä½†ç‚ºäº†é¿å…å¾ŒçºŒ TAB å¼•ç”¨å‡ºéŒ¯ï¼Œå…ˆçµ¦ç©ºå€¼
if 'analysis_history' not in st.session_state: st.session_state.analysis_history = []

# ---------- CSS ----------
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Gamja+Flower&display=swap ');
.cute-korean { font-family: 'Gamja Flower', cursive; font-size: 20px; color: #FF8C00; text-align: center; }
.small-font { font-size: 13px; color: #555555; margin-top: 5px !important; }
.grammar-box-container {
    background-color: #f8f9fa; border-radius: 8px; padding: 12px;
    border-left: 5px solid #FF8C00; text-align: left; margin-top: 0px;
}
.fc-daygrid-day-frame:hover {background-color: #FFF3CD !important; cursor: pointer; transform: scale(1.03); transition: .2s}
.fc-daygrid-day-frame:active {transform: scale(0.98); background-color: #FFE69C !important}
</style>
""", unsafe_allow_html=True)

# ---------- åœ–ç‰‡ & ç¾æˆ TAB ----------
IMG_URLS = {
    "A": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/183ebb183330643.Y3JvcCw4MDgsNjMyLDAsMA.jpg ",
    "B": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/f364bd220887627.67cae1bd07457.jpg ",
    "C": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/68254faebaafed9dafb41918f74c202e.jpg ",
    "M1": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro1.jpg ",
    "M2": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro2.jpg ",
    "M3": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro3.jpg ",
    "M4": "https://raw.githubusercontent.com/charlot135567-dot/my-memory-app/main/Mashimaro4.jpg "
}
with st.sidebar:
    st.markdown('<p class="cute-korean">ë‹¹ì‹ ì€ í•˜ë‚˜ë‹˜ì˜ ì†Œì¤‘í•œ ë³´ë¬¼ì…ë‹ˆë‹¤</p>', unsafe_allow_html=True)
    st.image(IMG_URLS["M3"], width=250)
    st.divider()

tabs = st.tabs(["ğŸ  æ›¸æ¡Œ", "ğŸ““ ç­†è¨˜", "âœï¸ æŒ‘æˆ°", "ğŸ“‚ è³‡æ–™åº«"])

# ===================================================================
# 3. TAB1 â”€ æ›¸æ¡Œ (è¼ªæµé¡¯ç¤ºç‰ˆ - è³‡æ–™åˆ†é›¢ä¿®æ­£ç‰ˆ)
# ===================================================================
with tabs[0]:
    import csv, random, re, datetime as dt
    from io import StringIO

    # --- Session State åˆå§‹åŒ–ï¼ˆç¢ºä¿æ¯æ¬¡éƒ½æœ‰å€¼ï¼‰---
    if "tab1_vocab_index" not in st.session_state:
        st.session_state.tab1_vocab_index = 0
    if "tab1_phrase_index" not in st.session_state:
        st.session_state.tab1_phrase_index = 15
    if "tab1_grammar_index" not in st.session_state:
        st.session_state.tab1_grammar_index = 0
    if "tab1_verse_index" not in st.session_state:
        st.session_state.tab1_verse_index = 0
    if "tab1_last_update" not in st.session_state:
        st.session_state.tab1_last_update = dt.datetime.now()

    # æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¶…é1å°æ™‚ï¼‰
    current_time = dt.datetime.now()
    time_diff = (current_time - st.session_state.tab1_last_update).total_seconds()
    
    if time_diff > 3600:
        st.session_state.tab1_last_update = current_time
        st.session_state.tab1_vocab_index += 1
        st.session_state.tab1_phrase_index += 4
        st.session_state.tab1_grammar_index += 1
        st.session_state.tab1_verse_index += 1
        st.rerun()
    
    sentences = st.session_state.get('sentences', {})
    
    if not sentences:
        st.warning("è³‡æ–™åº«ç‚ºç©ºï¼Œè«‹å…ˆåœ¨ TAB4 è¼‰å…¥ Notion è³‡æ–™")
    else:
        def parse_csv(content):
            if not content: 
                return []
            try:
                reader = csv.DictReader(StringIO(content.strip()))
                rows = list(reader)
                return [row for row in rows if any(v.strip() for v in row.values())]
            except:
                return []

        # ============================================================
        # é—œéµä¿®æ­£ï¼šåˆ†é›¢æ¨¡å¼Aå’Œæ¨¡å¼Bçš„è³‡æ–™
        # ============================================================
        
        # æ”¶é›†æ‰€æœ‰æ¨¡å¼Aè³‡æ–™ï¼ˆæœ‰V1çš„ï¼‰å’Œæ¨¡å¼Bè³‡æ–™ï¼ˆæœ‰W Sheetä½†ç„¡V1çš„ï¼‰
        all_mode_a = []  # å–®å­—ã€é‡‘å¥ä¾†æº
        all_mode_b = []  # ç‰‡èªä¾†æº
        all_grammar_sources = []  # æ–‡æ³•ä¾†æºï¼ˆAæˆ–Béƒ½å¯ä»¥ï¼‰
        
        for ref, data in sentences.items():
            v1_content = data.get('v1_content', '')
            w_content = data.get('w_sheet', '')
            g_content = data.get('grammar_list', '')
            
            v1_rows = parse_csv(v1_content)
            v2_rows = parse_csv(data.get('v2_content', ''))
            w_rows = parse_csv(w_content)
            g_rows = parse_csv(g_content)
            
            # æ¨¡å¼Aï¼šæœ‰V1è³‡æ–™ â†’ ç”¨æ–¼å–®å­—ã€é‡‘å¥
            if v1_rows:
                all_mode_a.append({
                    'ref': ref,
                    'v1': v1_rows,
                    'v2': v2_rows,
                    'v1_count': len(v1_rows)
                })
                # æ–‡æ³•ä¹Ÿå¯ä»¥ä¾†è‡ªV1
                for i, row in enumerate(v1_rows):
                    all_grammar_sources.append({
                        'type': 'A',
                        'ref': ref,
                        'row': row,
                        'v2_row': v2_rows[i] if i < len(v2_rows) else {},
                        'index': i,
                        'total_in_file': len(v1_rows)
                    })
            
            # æ¨¡å¼Bï¼šæœ‰W Sheet â†’ ç”¨æ–¼ç‰‡èªï¼ˆä¿®æ­£ï¼šåªè¦æœ‰W Sheetå°±åŠ å…¥ï¼‰
            if w_rows and len(w_rows) > 0:
                all_mode_b.append({
                    'ref': ref,
                    'w': w_rows,
                    'w_count': len(w_rows)
                })
            
            # Grammar Listï¼ˆæ¨¡å¼Bçš„æ–‡æ³•ï¼‰
            if g_rows:
                for i, row in enumerate(g_rows):
                    all_grammar_sources.append({
                        'type': 'B',
                        'ref': ref,
                        'row': row,
                        'v2_row': {},
                        'index': i,
                        'total_in_file': len(g_rows)
                    })
        
        # ============================================================
        # 1) å–®å­—ï¼šV1 Syn/Ant + V2 Syn/Ant + THSV11
        # ============================================================
        vocab_display = []
        current_vocab_ref = "N/A"
        
        if all_mode_a:
            # è¼ªæµé¸æ“‡å“ªå€‹æ¨¡å¼Aæª”æ¡ˆ
            total_vocab_items = sum(f['v1_count'] for f in all_mode_a)
            if total_vocab_items > 0:
                vocab_counter = st.session_state.tab1_vocab_index % total_vocab_items
                # æ‰¾åˆ°å°æ‡‰çš„æª”æ¡ˆå’Œè¡Œ
                cumulative = 0
                vocab_file = None
                row_idx = 0
                for f in all_mode_a:
                    if cumulative + f['v1_count'] > vocab_counter:
                        vocab_file = f
                        row_idx = vocab_counter - cumulative
                        break
                    cumulative += f['v1_count']
                
                if vocab_file:
                    v1_row = vocab_file['v1'][row_idx]
                    v2_row = vocab_file['v2'][row_idx % len(vocab_file['v2'])] if vocab_file['v2'] else {}
                    
                    current_vocab_ref = v1_row.get('Ref.', vocab_file['ref'])
                    
                    # V1 Syn/Ant - è§£æåŒç¾©è©å’Œåç¾©è©
                    v1_syn_ant = v1_row.get('Syn/Ant', '')
                    v1_syn_list = []
                    v1_ant_list = []
                    
                    if v1_syn_ant:
                        if 'Syn:' in v1_syn_ant or 'Ant:' in v1_syn_ant:
                            syn_match = re.search(r'Syn:\s*([^/;]+)', v1_syn_ant)
                            ant_match = re.search(r'Ant:\s*([^/;]+)', v1_syn_ant)
                            if syn_match:
                                v1_syn_list = [s.strip() for s in syn_match.group(1).split(',') if s.strip()]
                            if ant_match:
                                v1_ant_list = [a.strip() for a in ant_match.group(1).split(',') if a.strip()]
                        else:
                            parts = re.split(r'[/|]', v1_syn_ant)
                            if len(parts) >= 2:
                                v1_syn_list = [p.strip() for p in parts[0].split(',') if p.strip()]
                                v1_ant_list = [p.strip() for p in parts[1].split(',') if p.strip()]
                    
                    # V2 Syn/Ant (éŸ“æ–‡) + THSV11 (æ³°æ–‡)
                    v2_syn_ant = v2_row.get('Syn/Ant', '') if v2_row else ''
                    v2_th = v2_row.get('THSV11', '') if v2_row else ''
                    
                    vocab_items = []
                    if v1_syn_list:
                        vocab_items.append(f"<span style='color:#2E8B57;'>âœ¨{', '.join(v1_syn_list)}</span>")
                    if v1_ant_list:
                        vocab_items.append(f"<span style='color:#CD5C5C;'>â„ï¸{', '.join(v1_ant_list)}</span>")
                    if v2_syn_ant:
                        vocab_items.append(f"<span style='color:#4682B4;'>ğŸ‡°ğŸ‡· {v2_syn_ant}</span>")
                    if v2_th:
                        vocab_items.append(f"<span style='color:#9932CC;'>ğŸ‡¹ğŸ‡­ {v2_th}</span>")
                    
                    vocab_display = vocab_items
        
        # ============================================================
        # 2) ç‰‡èªï¼šåªå¾æ¨¡å¼Bçš„W Sheetè¼ªæµï¼ˆç¬¬16å€‹é–‹å§‹ï¼‰
        # ============================================================
        w_phrases = []
        current_phrase_ref = "N/A"
        
        # æ”¶é›†æ‰€æœ‰å¯ç”¨çš„ç‰‡èªï¼ˆå¾ç¬¬16å€‹é–‹å§‹ï¼Œç´¢å¼•15ï¼‰
        all_available_phrases = []
        
        for mb in all_mode_b:
            w_rows = mb.get('w', [])
            w_count = len(w_rows)
            
            # åªæœ‰è¶…é15ç­†çš„æª”æ¡ˆæ‰åŠ å…¥
            if w_count > 15:
                for idx in range(15, w_count):
                    all_available_phrases.append({
                        'data': w_rows[idx],
                        'ref': mb['ref'],
                        'original_idx': idx + 1  # 1-based for display
                    })
        
        # è¼ªæµé¡¯ç¤º4å€‹ç‰‡èª
        if len(all_available_phrases) > 0:
            total_available = len(all_available_phrases)
            # ç¢ºä¿ç´¢å¼•åœ¨ç¯„åœå…§
            start_idx = st.session_state.tab1_phrase_index % total_available
            
            # å–4å€‹ç‰‡èªï¼ˆå¾ªç’°ï¼‰
            for i in range(4):
                idx = (start_idx + i) % total_available
                item = all_available_phrases[idx]
                w_phrases.append(item['data'])
                # è¨˜éŒ„ç¬¬ä¸€å€‹çš„refä½œç‚ºé¡¯ç¤ºç”¨
                if i == 0:
                    current_phrase_ref = f"{item['ref']} #{item['original_idx']}"
        
        # ============================================================
        # 3) é‡‘å¥ï¼šå¾æ¨¡å¼Açš„V1 Sheetè¼ªæµ
        # ============================================================
        verse_lines = []
        current_verse_ref = "N/A"
        
        if all_mode_a:
            total_verse_items = sum(f['v1_count'] for f in all_mode_a)
            if total_verse_items > 0:
                verse_counter = st.session_state.tab1_verse_index % total_verse_items
                cumulative = 0
                verse_file = None
                row_idx = 0
                
                for f in all_mode_a:
                    if cumulative + f['v1_count'] > verse_counter:
                        verse_file = f
                        row_idx = verse_counter - cumulative
                        break
                    cumulative += f['v1_count']
                
                if verse_file:
                    v1_verse = verse_file['v1'][row_idx]
                    v2_verse = verse_file['v2'][row_idx % len(verse_file['v2'])] if verse_file['v2'] else {}
                    
                    current_verse_ref = v1_verse.get('Ref.', verse_file['ref'])
                    
                    en_text = v1_verse.get('English (ESV)', '')
                    cn_text = v1_verse.get('Chinese', '')
                    jp_text = v2_verse.get('å£èªè¨³', '') if v2_verse else ''
                    kr_text = v2_verse.get('KRF', '') if v2_verse else ''
                    th_text = v2_verse.get('THSV11', '') if v2_verse else ''
                    
                    if en_text:
                        verse_lines.append(f"ğŸ‡¬ğŸ‡§ **{current_verse_ref}** {en_text}")
                    if cn_text:
                        verse_lines.append(f"ğŸ‡¨ğŸ‡³ {cn_text}")
                    if jp_text:
                        verse_lines.append(f"ğŸ‡¯ğŸ‡µ {jp_text}")
                    if kr_text:
                        verse_lines.append(f"ğŸ‡°ğŸ‡· {kr_text}")
                    if th_text:
                        verse_lines.append(f"ğŸ‡¹ğŸ‡­ {th_text}")
        
        # ============================================================
        # 4) æ–‡æ³•ï¼šå¾å…©è™•ä¾†ï¼ŒåŠ å…¥V2å£èªè¨³+Grammar+Note
        # ============================================================
        grammar_html = "ç­‰å¾…è³‡æ–™ä¸­..."
        current_grammar_ref = "N/A"
        
        if all_grammar_sources:
            g_idx = st.session_state.tab1_grammar_index % len(all_grammar_sources)
            g_source = all_grammar_sources[g_idx]
            g_row = g_source['row']
            v2_row = g_source.get('v2_row', {})
            current_grammar_ref = f"{g_source['ref']}-{g_source['index']+1}"
            
            all_grammar = []
            
            if g_source['type'] == 'A':
                # æ¨¡å¼Aæ–‡æ³•ï¼ˆä¾†è‡ªV1 Grammaræ¬„ä½ï¼‰
                g_ref = g_row.get('Ref.', '')
                g_en = g_row.get('English (ESV)', '')
                g_cn = g_row.get('Chinese', '')
                g_syn = g_row.get('Syn/Ant', '')
                g_grammar = g_row.get('Grammar', '')
                
                # ç¶“æ–‡æ¨™é¡Œè¡Œï¼šRefç·Šè²¼è‹±æ–‡ï¼ˆç„¡ç©ºæ ¼ï¼‰
                if g_ref and g_en:
                    all_grammar.append(f"<b>{g_ref}</b>{g_en}")
                elif g_en:
                    all_grammar.append(g_en)
                
                # ä¸­æ–‡
                if g_cn:
                    all_grammar.append(g_cn)
                
                # Syn/Ant åŒä¸€è¡Œé¡¯ç¤ºï¼ˆä¿®æ­£ï¼šç¢ºä¿Synå’ŒAntéƒ½é¡¯ç¤ºï¼‰
                if g_syn:
                    syn_ant_html = ""
                    # è§£æ Syn å’Œ Ant
                    syn_text = ""
                    ant_text = ""
                    
                    # å˜—è©¦å¤šç¨®æ ¼å¼è§£æ
                    if 'Syn:' in g_syn or 'Ant:' in g_syn:
                        syn_match = re.search(r'Syn:\s*([^/;]+?)(?=\s*Ant:|$)', g_syn)
                        ant_match = re.search(r'Ant:\s*([^/;]+)', g_syn)
                        if syn_match:
                            syn_text = syn_match.group(1).strip()
                        if ant_match:
                            ant_text = ant_match.group(1).strip()
                    else:
                        # å˜—è©¦ç”¨ / æˆ– | åˆ†éš”
                        parts = re.split(r'[/|]', g_syn)
                        if len(parts) >= 2:
                            syn_text = parts[0].strip()
                            ant_text = parts[1].strip()
                        else:
                            syn_text = g_syn.strip()
                    
                    # çµ„åˆé¡¯ç¤º
                    if syn_text:
                        syn_ant_html += f'<span style="color:#2E8B57;">âœ¨Syn:{syn_text}</span>'
                    if ant_text:
                        if syn_text:
                            syn_ant_html += ' '
                        syn_ant_html += f'<span style="color:#CD5C5C;">â„ï¸Ant:{ant_text}</span>'
                    
                    if syn_ant_html:
                        all_grammar.append(syn_ant_html)
                
                # Grammarè§£æï¼ˆç¸®æ’å°é½Šï¼‰
                if g_grammar:
                    lines = []
                    text = str(g_grammar)
                    # è™•ç† 1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£4ï¸âƒ£ æ¨™è¨˜
                    text = text.replace('1ï¸âƒ£[', '1ï¸âƒ£[')
                    text = text.replace('2ï¸âƒ£[', '<br>2ï¸âƒ£[')
                    text = text.replace('3ï¸âƒ£[', '<br>3ï¸âƒ£[')
                    text = text.replace('4ï¸âƒ£[', '<br>4ï¸âƒ£[')
                    text = text.replace(']', ']')
                    all_grammar.append(text)
                
                # V2è³‡æ–™ï¼šå£èªè¨³ + Grammar + Note
                v2_jp = v2_row.get('å£èªè¨³', '') if v2_row else ''
                v2_grammar = v2_row.get('Grammar', '') if v2_row else ''
                v2_note = v2_row.get('Note', '') if v2_row else ''
                
                if v2_jp:
                    v2_parts = ["<br>"]
                    v2_ref = v2_row.get('Ref.', g_ref) if v2_row else g_ref
                    v2_parts.append(f"<b>{v2_ref}</b>{v2_jp}")
                    
                    if v2_grammar:
                        v2_parts.append(f'<span style="color:#4682B4;">æ–‡æ³•ï¼š</span>{v2_grammar}')
                    if v2_note:
                        v2_parts.append(f'<span style="color:#D2691E;">å‚™è¨»ï¼š</span>{v2_note}')
                    
                    all_grammar.append("<br>".join(v2_parts))
                    
            else:
                # æ¨¡å¼Bæ–‡æ³•ï¼ˆä¾†è‡ªGrammar Listï¼‰
                orig = g_row.get('Original Sentence', '')
                rule = g_row.get('Grammar Rule', '')
                analysis = g_row.get('Analysis & Example', '')
                
                if orig:
                    all_grammar.append(f"ğŸ“ <b>{orig}</b>")
                if rule:
                    all_grammar.append(f"ğŸ“Œ {rule}")
                if analysis:
                    af = str(analysis)
                    af = af.replace('1ï¸âƒ£', '<br>1ï¸âƒ£')
                    af = af.replace('2ï¸âƒ£', '<br>2ï¸âƒ£')
                    af = af.replace('3ï¸âƒ£', '<br>3ï¸âƒ£')
                    af = af.replace('4ï¸âƒ£', '<br>4ï¸âƒ£')
                    all_grammar.append(af)
            
            if all_grammar:
                grammar_html = "<br>".join(all_grammar)
        
        # ============================================================
        # æ¸²æŸ“ç•«é¢
        # ============================================================
        col_left, col_right = st.columns([0.67, 0.33])
        
        with col_left:
            # å–®å­—å€å¡Š
            if vocab_display:
                st.markdown(
                    "<div style='margin-bottom:4px; line-height:1.6;'>" + 
                    " ; ".join(vocab_display) + 
                    "</div>", 
                    unsafe_allow_html=True
                )
            else:
                st.caption("ç„¡å–®å­—è³‡æ–™ï¼ˆè«‹ç¢ºèªæœ‰æ¨¡å¼Aè³‡æ–™ï¼‰")
            
            st.markdown("<hr style='margin:6px 0;'>", unsafe_allow_html=True)

            # ç‰‡èªå€å¡Šï¼ˆä¿®æ­£ï¼šé¡¯ç¤ºèª¿è©¦è³‡è¨Šï¼‰
            if w_phrases:
                for i, row in enumerate(w_phrases):
                    # å˜—è©¦å¤šç¨®å¯èƒ½çš„æ¬„ä½åç¨±
                    p = (row.get('Word/Phrase', '') or 
                         row.get('Word/phrase', '') or 
                         row.get('words/phrases', '') or 
                         row.get('Word', ''))
                    c = row.get('Chinese', '')
                    s = (row.get('Synonym+ä¸­æ–‡å°ç…§', '') or 
                         row.get('Synonym', '') or 
                         row.get('Syn', ''))
                    a = (row.get('Antonym+ä¸­æ–‡å°ç…§', '') or 
                         row.get('Antonym', '') or 
                         row.get('Ant', ''))
                    bible_ex = (row.get('å…¨å¥è–ç¶“ä¸­è‹±å°ç…§ä¾‹å¥', '') or 
                               row.get('Bible Example', '') or 
                               row.get('Example', ''))
                    
                    if p:
                        parts = [f"ğŸ”¤ **{p}**"]
                        if c: 
                            parts.append(f"<span style='color:#666;'>{c}</span>")
                        if s or a:
                            sa_parts = []
                            if s: 
                                sa_parts.append(f"<span style='color:#2E8B57;'>âœ¨{s}</span>")
                            if a: 
                                sa_parts.append(f"<span style='color:#CD5C5C;'>â„ï¸{a}</span>")
                            parts.append("<span style='font-size:0.9em;'>" + " | ".join(sa_parts) + "</span>")
                        
                        st.markdown(
                            "<div style='margin-bottom:2px;'>" + " ".join(parts) + "</div>", 
                            unsafe_allow_html=True
                        )
                        
                        if bible_ex:
                            match = re.match(r'([^(]+)(\([^)]+\))?$', bible_ex)
                            if match:
                                eng_part = match.group(1).strip()
                                cn_part = match.group(2) if match.group(2) else ""
                                bible_html = f"<span style='font-size:1.15em; font-weight:500;'>{eng_part}</span> <span style='font-size:0.9em; color:#666;'>{cn_part}</span>"
                            else:
                                bible_html = f"<span style='font-size:1.15em;'>{bible_ex}</span>"
                            
                            st.markdown(
                                f"<div style='margin-bottom:4px; margin-left:20px;'>ğŸ“– {bible_html}</div>", 
                                unsafe_allow_html=True
                            )
                        
                        if i < len(w_phrases) - 1:
                            st.markdown("<div style='margin:4px 0;'></div>", unsafe_allow_html=True)
            else:
                # é¡¯ç¤ºèª¿è©¦è³‡è¨Š
                st.caption(f"ç„¡ç‰‡èªè³‡æ–™ï¼ˆæ¨¡å¼B={len(all_mode_b)}å€‹ï¼‰")
                if all_mode_b:
                    for mb in all_mode_b:
                        st.caption(f"  - {mb['ref']}: {mb['w_count']}ç­†")

            st.markdown("<hr style='margin:6px 0;'>", unsafe_allow_html=True)

            # é‡‘å¥å€å¡Š
            if verse_lines:
                st.markdown(f"<div style='margin-bottom:4px;'>{verse_lines[0]}</div>", unsafe_allow_html=True)
                for v in verse_lines[1:]:
                    st.markdown(f"<div style='margin-bottom:2px;'>{v}</div>", unsafe_allow_html=True)
            else:
                st.caption("ğŸ“– ç„¡é‡‘å¥è³‡æ–™ï¼ˆè«‹ç¢ºèªæœ‰æ¨¡å¼Aè³‡æ–™ï¼‰")

        with col_right:
            # æ–‡æ³•å€å¡Š
            st.markdown(f"""
                <div style="background-color:#1E1E1E; color:#FFFFFF; padding:10px; border-radius:8px; 
                            border-left:4px solid #FF8C00; font-size:13px; line-height:1.5; 
                            min-height:100%; display:flex; flex-direction:column;">
                    {grammar_html}
                </div>
                """, unsafe_allow_html=True)
            
            minutes_left = max(0, (3600 - time_diff) / 60)
            st.caption(f"å–®å­—:{current_vocab_ref} | ç‰‡èª:{current_phrase_ref} | é‡‘å¥:{current_verse_ref}")
            st.caption(f"æ–‡æ³•:{current_grammar_ref} | {minutes_left:.0f}åˆ†å¾Œæ›´æ–°")
            st.caption(f"è³‡æ–™çµ±è¨ˆ: A={len(all_mode_a)}å€‹, B={len(all_mode_b)}å€‹, æ–‡æ³•={len(all_grammar_sources)}å€‹")

# ===================================================================
# 4. TAB2 â”€ æœˆæ›†å¾…è¾¦ + æ™‚æ®µé‡‘å¥ + æ”¶è—é‡‘å¥ï¼ˆä¿®æ­£ç‰ˆï¼‰
# ===================================================================
with tabs[1]:
    import datetime as dt, re, os, json
    from streamlit_calendar import calendar
    from io import StringIO
    import csv

    # å…¨å±€CSSï¼šå£“ç¸®æ‰€æœ‰é–“è·
    st.markdown("""
        <style>
        /* å£“ç¸®æ‰€æœ‰å…ƒç´ é–“è· */
        div[data-testid="stVerticalBlock"] > div {padding: 0px !important; margin: 0px !important;}
        div[data-testid="stVerticalBlock"] > div > div {padding: 0px !important; margin: 0px !important;}
        p {margin: 0px !important; padding: 0px !important; line-height: 1.2 !important;}
        .stMarkdown {margin: 0px !important; padding: 0px !important;}
        /* å£“ç¸®æŒ‰éˆ• */
        .stButton button {padding: 0px 4px !important; min-height: 24px !important; font-size: 12px !important; margin: 0px !important;}
        /* å£“ç¸®åˆ†éš”ç·š */
        hr {margin: 2px 0 !important; padding: 0 !important;}
        /* å£“ç¸®expander */
        div[data-testid="stExpander"] {margin: 2px 0 !important;}
        div[data-testid="stExpander"] > div {padding: 0px 8px !important;}
        /* å£“ç¸®columnsé–“è· */
        div[data-testid="column"] {padding: 0px 2px !important;}
        </style>
    """, unsafe_allow_html=True)

    # ---------- 0. æª”æ¡ˆè¨­å®š ----------
    DATA_DIR = "data"
    os.makedirs(DATA_DIR, exist_ok=True)
    TODO_FILE = os.path.join(DATA_DIR, "todos.json")
    FAVORITE_FILE = os.path.join(DATA_DIR, "favorite_sentences.json")

    def load_todos():
        if os.path.exists(TODO_FILE):
            try:
                with open(TODO_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except:
                pass
        return {}

    def save_todos():
        with open(TODO_FILE, "w", encoding="utf-8") as f:
            json.dump(st.session_state.todo, f, ensure_ascii=False, indent=2)

    def load_favorites():
        if os.path.exists(FAVORITE_FILE):
            try:
                with open(FAVORITE_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except:
                pass
        return []

    def save_favorites():
        with open(FAVORITE_FILE, "w", encoding="utf-8") as f:
            json.dump(st.session_state.favorite_sentences, f, ensure_ascii=False, indent=2)

    # ---------- 1. Session State ----------
    if "todo" not in st.session_state:
        st.session_state.todo = load_todos()
    if "favorite_sentences" not in st.session_state:
        st.session_state.favorite_sentences = load_favorites()
    if "sel_date" not in st.session_state:
        st.session_state.sel_date = str(dt.date.today())
    if "cal_key" not in st.session_state:
        st.session_state.cal_key = 0
    if "active_del_id" not in st.session_state:
        st.session_state.active_del_id = None
    if "active_fav_del" not in st.session_state:
        st.session_state.active_fav_del = None

    # ---------- 2. æœˆæ›† ----------
    def build_events():
        ev = []
        for d, items in st.session_state.todo.items():
            if isinstance(items, list):
                for t in items:
                    ev.append({
                        "title": t.get("title", ""),
                        "start": f"{d}T{t.get('time','00:00:00')}",
                        "backgroundColor": "#FFE4E1",
                        "borderColor": "#FFE4E1",
                        "textColor": "#333"
                    })
        return ev

    with st.expander("ğŸ“… è–ç¶“å­¸ç¿’ç”Ÿæ´»æœˆæ›†", expanded=True):
        cal_options = {
            "headerToolbar": {"left": "prev,next today", "center": "title", "right": ""},
            "initialView": "dayGridMonth",
            "displayEventTime": False,
            "height": "auto"
        }
        state = calendar(events=build_events(), options=cal_options, key=f"cal_{st.session_state.cal_key}")
        if state.get("dateClick"):
            st.session_state.sel_date = state["dateClick"]["date"][:10]
            st.rerun()

    # ---------- 3. ä¸‰æ—¥æ¸…å–®ï¼ˆä¿®æ­£ï¼šé¡¯ç¤ºé¸ä¸­æ—¥æœŸçš„å‰å¾Œä¸€å¤©ï¼‰----------
    st.markdown('<p style="margin:0;padding:0;font-size:14px;font-weight:bold;">ğŸ“‹ å¾…è¾¦äº‹é …</p>', unsafe_allow_html=True)

    try:
        base_date = dt.datetime.strptime(st.session_state.sel_date, "%Y-%m-%d").date()
    except:
        base_date = dt.date.today()

    # é¡¯ç¤ºé¸ä¸­æ—¥æœŸåŠå…¶å‰å¾Œå„ä¸€å¤©ï¼ˆå…±3å¤©ï¼‰
    dates_to_show = [base_date - dt.timedelta(days=1), base_date, base_date + dt.timedelta(days=1)]
    
    has_todo = False
    for d_obj in dates_to_show:
        d_str = str(d_obj)
        
        if d_str in st.session_state.todo and st.session_state.todo[d_str]:
            has_todo = True
            
            for idx, item in enumerate(st.session_state.todo[d_str]):
                item_id = f"{d_str}_{idx}"
                title = item.get("title", "") if isinstance(item, dict) else str(item)
                time_str = item.get('time', '')[:5] if isinstance(item, dict) and item.get('time') else ""

                # æ¥µç·Šæ¹Šå¸ƒå±€
                c1, c2, c3 = st.columns([0.3, 8, 1.2])
                
                with c1:
                    if st.button("ğŸ’Ÿ", key=f"h_{item_id}"):
                        st.session_state.active_del_id = None if st.session_state.active_del_id == item_id else item_id
                        st.rerun()

                with c2:
                    # ä½¿ç”¨htmlå£“ç¸®è¡Œè·
                    st.markdown(f'<p style="margin:0;padding:0;line-height:1.2;font-size:13px;">{d_obj.month}/{d_obj.day} {time_str} {title}</p>', unsafe_allow_html=True)

                with c3:
                    if st.session_state.active_del_id == item_id:
                        if st.button("ğŸ—‘ï¸", key=f"d_{item_id}"):
                            st.session_state.todo[d_str].pop(idx)
                            if not st.session_state.todo[d_str]:
                                del st.session_state.todo[d_str]
                            save_todos()
                            st.session_state.cal_key += 1
                            st.session_state.active_del_id = None
                            st.rerun()
                # æ¯å€‹é …ç›®å¾Œæ¥µå°é–“è·
                st.markdown('<div style="height:1px;"></div>', unsafe_allow_html=True)
    
    if not has_todo:
        st.caption("å°šç„¡å¾…è¾¦äº‹é …")

    # ---------- 4. æ–°å¢å¾…è¾¦ ----------
    with st.expander("â• æ–°å¢å¾…è¾¦", expanded=False):
        with st.form("todo_form", clear_on_submit=True):
            c1, c2 = st.columns(2)
            with c1:
                in_date = st.date_input("æ—¥æœŸ", base_date)
            with c2:
                in_time = st.time_input("æ™‚é–“", dt.time(9, 0))
            in_title = st.text_input("å¾…è¾¦äº‹é …ï¼ˆå¯å« Emojiï¼‰")
            
            if st.form_submit_button("ğŸ’¾ å„²å­˜"):
                if in_title:
                    k = str(in_date)
                    if k not in st.session_state.todo:
                        st.session_state.todo[k] = []
                    st.session_state.todo[k].append({"title": in_title, "time": str(in_time)})
                    save_todos()
                    st.session_state.cal_key += 1
                    st.rerun()

    st.markdown('<hr style="margin:4px 0;">', unsafe_allow_html=True)
    
    # ---------- 5. æ™‚æ®µé‡‘å¥ ----------
    st.markdown('<p style="margin:0;padding:0;font-size:14px;font-weight:bold;">ğŸ“– ä»Šæ—¥æ™‚æ®µé‡‘å¥</p>', unsafe_allow_html=True)
    
    sentences = st.session_state.get('sentences', {})
    all_verses = []
    
    for ref, data in sentences.items():
        v1_content = data.get('v1_content', '')
        v2_content = data.get('v2_content', '')
        if v1_content:
            try:
                v1_rows = list(csv.DictReader(StringIO(v1_content.strip())))
                v2_rows = list(csv.DictReader(StringIO(v2_content.strip()))) if v2_content else []
                
                for i, row in enumerate(v1_rows):
                    v2_row = v2_rows[i] if i < len(v2_rows) else {}
                    verse_ref = row.get('Ref.', ref)
                    en = row.get('English (ESV)', '')
                    cn = row.get('Chinese', '')
                    jp = v2_row.get('å£èªè¨³ (1955)', '') if isinstance(v2_row, dict) else ''
                    kr = v2_row.get('KRF', '') if isinstance(v2_row, dict) else ''
                    th = v2_row.get('THSV11 (Key Phrases)', '') if isinstance(v2_row, dict) else ''
                    
                    verse_text = f"ğŸ‡¬ğŸ‡§ {verse_ref} {en}"
                    if jp:
                        verse_text += f"<br>ğŸ‡¯ğŸ‡µ {jp}"
                    if kr:
                        verse_text += f"<br>ğŸ‡°ğŸ‡· {kr}"
                    if th:
                        verse_text += f"<br>ğŸ‡¹ğŸ‡­ {th}"
                    if cn:
                        verse_text += f"<br>ğŸ‡¨ğŸ‡³ {cn}"
                    
                    all_verses.append(verse_text)
            except:
                pass

    hour = dt.datetime.now().hour
    
    if 7 <= hour < 11:
        period_name, period_idx = "æ—©æ™¨ 7-11", 0
    elif 11 <= hour < 15:
        period_name, period_idx = "åˆé–“ 11-15", 1
    elif 15 <= hour < 19:
        period_name, period_idx = "ä¸‹åˆ 15-19", 2
    elif 19 <= hour < 23:
        period_name, period_idx = "æ™šé–“ 19-23", 3
    else:
        period_name, period_idx = "æ·±å¤œ", -1

    st.markdown(f'<p style="margin:0;padding:0;font-size:11px;color:#FF8C00;">â° {period_name}</p>', unsafe_allow_html=True)

    if all_verses and period_idx >= 0:
        total = len(all_verses)
        start = (period_idx * 6) % total
        
        for i in range(6):
            idx = (start + i) % total
            st.markdown(f'<p style="margin:2px 0;padding:0;font-size:12px;line-height:1.3;"><b>{i+1}.</b> {all_verses[idx]}</p>', unsafe_allow_html=True)
            if i < 5:
                st.markdown('<hr style="margin:2px 0;border:none;border-top:1px solid #eee;">', unsafe_allow_html=True)
    else:
        st.caption("å°šç„¡é‡‘å¥è³‡æ–™")

    st.markdown('<hr style="margin:4px 0;">', unsafe_allow_html=True)

    # ---------- 6. æ”¶è—é‡‘å¥ ----------
    st.markdown('<p style="margin:0;padding:0;font-size:14px;font-weight:bold;">ğŸ”½ æ”¶è—é‡‘å¥</p>', unsafe_allow_html=True)

    for idx, fav in enumerate(st.session_state.favorite_sentences[:8]):
        fav_id = f"fav_{idx}"
        c1, c2, c3 = st.columns([0.3, 8.5, 1.2])
        
        with c1:
            if st.button("ğŸ’", key=f"favh_{fav_id}"):
                st.session_state.active_fav_del = None if st.session_state.active_fav_del == fav_id else fav_id
                st.rerun()
        
        with c2:
            st.markdown(f'<p style="margin:0;padding:0;font-size:12px;line-height:1.2;">{fav}</p>', unsafe_allow_html=True)
        
        with c3:
            if st.session_state.active_fav_del == fav_id:
                if st.button("ğŸ—‘ï¸", key=f"favd_{fav_id}"):
                    st.session_state.favorite_sentences.pop(idx)
                    save_favorites()
                    st.session_state.active_fav_del = None
                    st.rerun()
        st.markdown('<div style="height:1px;"></div>', unsafe_allow_html=True)

    if len(st.session_state.favorite_sentences) < 8:
        with st.form("add_fav", clear_on_submit=True):
            new_fav = st.text_area("æ–°å¢æ”¶è—", height=50)
            if st.form_submit_button("â• åŠ å…¥"):
                if new_fav:
                    st.session_state.favorite_sentences.append(new_fav)
                    save_favorites()
                    st.rerun()

    st.caption(f"æ”¶è—: {len(st.session_state.favorite_sentences)}/8")
    
# ===================================================================
# 5. TAB3 â”€ æŒ‘æˆ°ï¼ˆç°¡åŒ–ç‰ˆï¼šç›´æ¥çµ¦é¡Œç›®ï¼Œæœ€å¾Œçµ¦ç­”æ¡ˆï¼‰
# ===================================================================
with tabs[2]:
    import csv
    from io import StringIO
    import random
    
    if 'tab3_quiz_seed' not in st.session_state:
        st.session_state.tab3_quiz_seed = random.randint(1, 1000)
        st.session_state.tab3_show_answers = False
    
    sentences = st.session_state.get('sentences', {})
    
    if not sentences:
        st.warning("è³‡æ–™åº«ç‚ºç©ºï¼Œè«‹å…ˆåœ¨ TAB4 å„²å­˜è³‡æ–™")
    else:
        # æ’åºè³‡æ–™
        sorted_refs = sorted(sentences.keys(), 
                           key=lambda x: sentences[x].get('date_added', ''), 
                           reverse=True)
        total = len(sorted_refs)
        
        new_refs = sorted_refs[:int(total*0.6)] if total >= 5 else sorted_refs
        mid_refs = sorted_refs[int(total*0.6):int(total*0.9)] if total >= 10 else []
        old_refs = sorted_refs[int(total*0.9):] if total >= 10 else []
        
        weighted_pool = (new_refs * 6) + (mid_refs * 3) + (old_refs * 1)
        if not weighted_pool:
            weighted_pool = sorted_refs
        
        random.seed(st.session_state.tab3_quiz_seed)
        
        # æ”¶é›†æ‰€æœ‰ç¶“æ–‡è³‡æ–™
        all_verses = []
        for ref in weighted_pool[:10]:  # å–å‰10ç­†è³‡æ–™
            data = sentences[ref]
            v1_content = data.get('v1_content', '')
            if v1_content:
                try:
                    lines = v1_content.strip().split('\n')
                    if lines:
                        reader = csv.DictReader(lines)
                        for row in reader:
                            all_verses.append({
                                'ref': row.get('Ref.', ''),
                                'english': row.get('English (ESV)', ''),
                                'chinese': row.get('Chinese', '')
                            })
                except:
                    pass
        
        # éš¨æ©Ÿé¸6é¡Œï¼ˆ3é¡Œä¸­ç¿»è‹±ï¼Œ3é¡Œè‹±ç¿»ä¸­ï¼‰
        random.shuffle(all_verses)
        selected = all_verses[:6] if len(all_verses) >= 6 else all_verses
        
        # åˆ†é…é¡Œç›®
        zh_to_en = selected[:3]  # ä¸­ç¿»è‹±
        en_to_zh = selected[3:6] if len(selected) > 3 else []  # è‹±ç¿»ä¸­
        
        st.subheader("ğŸ“ ç¿»è­¯æŒ‘æˆ°")
        
        # ===== é¡Œç›® 1-3ï¼šä¸­ç¿»è‹± =====
        for i, q in enumerate(zh_to_en, 1):
            st.markdown(f"**{i}.** {q['chinese'][:60]}")
            st.text_input("", key=f"quiz_zh_en_{i}", placeholder="è«‹ç¿»è­¯æˆè‹±æ–‡...", label_visibility="collapsed")
            st.write("")
        
        # ===== é¡Œç›® 4-6ï¼šè‹±ç¿»ä¸­ =====
        for i, q in enumerate(en_to_zh, 4):
            st.markdown(f"**{i}.** {q['english'][:100]}")
            st.text_input("", key=f"quiz_en_zh_{i}", placeholder="è«‹ç¿»è­¯æˆä¸­æ–‡...", label_visibility="collapsed")
            st.write("")
        
        # ===== å–®å­—é¡Œï¼ˆ3é¡Œï¼‰=====
        # å¾ Syn/Ant æå–å–®å­—
        word_pool = []
        for ref in weighted_pool[:5]:
            data = sentences[ref]
            v1_content = data.get('v1_content', '')
            if v1_content:
                try:
                    lines = v1_content.strip().split('\n')
                    if lines:
                        reader = csv.DictReader(lines)
                        for row in reader:
                            syn_ant = row.get('Syn/Ant', '')
                            if '/' in syn_ant:
                                parts = syn_ant.split('/')
                                for p in parts:
                                    match = re.match(r'(.+?)\s*\((.+?)\)', p.strip())
                                    if match:
                                        word_pool.append({
                                            'en': match.group(1).strip(),
                                            'cn': match.group(2).strip()
                                        })
                except:
                    pass
        
        random.shuffle(word_pool)
        selected_words = word_pool[:3] if len(word_pool) >= 3 else word_pool
        
        for i, w in enumerate(selected_words, 7):
            st.markdown(f"**{i}.** {w['cn']}ï¼ˆè«‹å¯«å‡ºè‹±æ–‡ï¼‰")
            st.text_input("", key=f"quiz_word_{i}", placeholder="English word...", label_visibility="collapsed")
            st.write("")
        
        # ===== ç¿»çœ‹ç­”æ¡ˆæŒ‰ =====
        col_btn, col_answer = st.columns([1, 3])
        with col_btn:
            if st.button("ğŸ‘ï¸ ç¿»çœ‹æ­£ç¢ºç­”æ¡ˆ", use_container_width=True, type="primary"):
                st.session_state.tab3_show_answers = True
                st.rerun()
        
        with col_answer:
            if st.session_state.tab3_show_answers:
                with st.expander("ğŸ“– æ­£ç¢ºç­”æ¡ˆ", expanded=True):
                    # é¡¯ç¤ºä¸­ç¿»è‹±ç­”æ¡ˆ
                    st.markdown("**ä¸­ç¿»è‹±ï¼š**")
                    for i, q in enumerate(zh_to_en, 1):
                        st.caption(f"{i}. {q['english'][:100]}")
                    
                    # é¡¯ç¤ºè‹±ç¿»ä¸­ç­”æ¡ˆ
                    st.markdown("**è‹±ç¿»ä¸­ï¼š**")
                    for i, q in enumerate(en_to_zh, 4):
                        st.caption(f"{i}. {q['chinese'][:60]}")
                    
                    # é¡¯ç¤ºå–®å­—ç­”æ¡ˆ
                    st.markdown("**å–®å­—ï¼š**")
                    for i, w in enumerate(selected_words, 7):
                        st.caption(f"{i}. {w['en']}")
                             
                if st.button("ğŸ”„ æ›ä¸€æ‰¹é¡Œç›®", use_container_width=True):
                    st.session_state.tab3_quiz_seed = random.randint(1, 1000)
                    st.session_state.tab3_show_answers = False
                    st.rerun()
            
# ===================================================================
# 6. TAB4 â”€ AI æ§åˆ¶å° + Notion Database æ•´åˆï¼ˆæ”¯æ´å¤šå·¥ä½œè¡¨ï¼‰
# ===================================================================
with tabs[3]:
    import os, json, datetime as dt, pandas as pd, urllib.parse, base64, re, csv, requests
    from io import StringIO
    import streamlit.components.v1 as components

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ”’ NOTION è¨­å®šé›†ä¸­ç®¡ç†å€ï¼ˆæ›´æ–°æ™‚è«‹å‹¿ä¿®æ”¹æ­¤å€å¡Šçµæ§‹ï¼‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    NOTION_TOKEN = ""
    DATABASE_ID = ""
    
    try:
        if "notion" in st.secrets:
            notion_cfg = st.secrets["notion"]
            NOTION_TOKEN = notion_cfg.get("token", "")
            DATABASE_ID = notion_cfg.get("database_id", "2f910510e7fb80c4a67ff8735ea90cdf")
            
            if NOTION_TOKEN and DATABASE_ID:
                st.sidebar.success(f"âœ… Notion è¨­å®šè¼‰å…¥æˆåŠŸ")
            else:
                st.sidebar.warning(f"âš ï¸ Notion è¨­å®šä¸å®Œæ•´")
        else:
            st.sidebar.error("âŒ secrets.toml ç¼ºå°‘ [notion] å€æ®µ")
            DATABASE_ID = "2f910510e7fb80c4a67ff8735ea90cdf"
    except Exception as e:
        st.sidebar.error(f"âŒ è®€å– Notion è¨­å®šå¤±æ•—: {e}")
        DATABASE_ID = "2f910510e7fb80c4a67ff8735ea90cdf"
    
    NOTION_API_VERSION = "2022-06-28"
    NOTION_BASE_URL = "https://api.notion.com/v1"

    # ---------- èƒŒæ™¯åœ–ç‰‡å¥—ç”¨ ----------
    try:
        selected_img_file = bg_options.get(st.session_state.get('selected_bg', 'ğŸ¶ Snoopy'), 'Snoopy.jpg')
        current_bg_size = st.session_state.get('bg_size', 15)
        current_bg_bottom = st.session_state.get('bg_bottom', 30)
        
        if os.path.exists(selected_img_file):
            with open(selected_img_file, "rb") as f:
                img_b64 = base64.b64encode(f.read()).decode()
            st.markdown(f"""
            <style>
            .stApp {{
                background-image: url("data:image/jpeg;base64,{img_b64}");
                background-size: {current_bg_size}% auto;
                background-position: center bottom {current_bg_bottom}px;
                background-attachment: fixed;
                background-repeat: no-repeat;
                z-index: 0;
            }}
            .main .block-container {{
                position: relative;
                z-index: 1;
                padding-bottom: {current_bg_bottom + 100}px;
            }}
            </style>
            """, unsafe_allow_html=True)
    except:
        pass

    # ---------- Google Sheet é€£ç·šæª¢æŸ¥ ----------
    sheet_connected = False
    GCP_SA = None
    SHEET_ID = None
    try:
        import gspread
        from google.oauth2.service_account import Credentials
        GCP_SA = st.secrets.get("gcp_service_account", {})
        SHEET_ID = st.secrets.get("sheets", {}).get("spreadsheet_id", "")
        if GCP_SA and SHEET_ID:
            sheet_connected = True
    except:
        pass

    # ---------- è¼”åŠ©å‡½å¼ ----------
    def get_notion_text(prop_dict):
        rt = prop_dict.get("rich_text", [])
        if rt and len(rt) > 0:
            return rt[0].get("text", {}).get("content", "")
        return ""

    # ---------- Notion æ ¸å¿ƒå‡½å¼ ----------
    def load_from_notion():
        if not NOTION_TOKEN:
            st.sidebar.error("âŒ NOTION_TOKEN æœªè¨­å®š")
            return {}
        
        url = f"{NOTION_BASE_URL}/databases/{DATABASE_ID}/query"
        headers = {
            "Authorization": f"Bearer {NOTION_TOKEN}",
            "Notion-Version": NOTION_API_VERSION,
            "Content-Type": "application/json"
        }

        all_data = {}
        has_more = True
        start_cursor = None

        try:
            with st.spinner("â˜ï¸ æ­£åœ¨å¾ Notion è¼‰å…¥è³‡æ–™..."):
                while has_more:
                    payload = {"page_size": 100}
                    if start_cursor:
                        payload["start_cursor"] = start_cursor

                    response = requests.post(url, headers=headers, json=payload)
                    
                    if response.status_code != 200:
                        st.sidebar.error(f"ğŸš« Notion API éŒ¯èª¤ ({response.status_code})")
                        return {}

                    data = response.json()

                    for page in data.get("results", []):
                        props = page.get("properties", {})
                        ref = get_notion_text(props.get("Ref_No", {})) or "unknown"
                        translation = get_notion_text(props.get("Translation", {}))

                        v1_content = ""
                        v2_content = ""
                        w_sheet = ""
                        p_sheet = ""
                        grammar_list = ""
                        
                        if translation:
                            # è§£æå„å€‹å·¥ä½œè¡¨
                            if "ã€V1 Sheetã€‘" in translation:
                                parts = translation.split("ã€V2 Sheetã€‘")
                                v1_content = parts[0].split("ã€V1 Sheetã€‘")[-1].strip() if len(parts) > 0 else ""
                                rest = parts[1] if len(parts) > 1 else ""
                                
                                if "ã€W Sheetã€‘" in rest:
                                    v2_parts = rest.split("ã€W Sheetã€‘")
                                    v2_content = v2_parts[0].replace("ã€å…¶ä»–å·¥ä½œè¡¨ã€‘", "").strip()
                                    w_rest = v2_parts[1] if len(v2_parts) > 1 else ""
                                    
                                    if "ã€P Sheetã€‘" in w_rest:
                                        w_parts = w_rest.split("ã€P Sheetã€‘")
                                        w_sheet = w_parts[0].strip()
                                        p_rest = w_parts[1] if len(w_parts) > 1 else ""
                                        
                                        if "ã€Grammar Listã€‘" in p_rest:
                                            p_parts = p_rest.split("ã€Grammar Listã€‘")
                                            p_sheet = p_parts[0].strip()
                                            grammar_list = p_parts[1].split("ã€å…¶ä»–è£œå……ã€‘")[0].strip() if len(p_parts) > 1 else ""
                                    else:
                                        w_sheet = w_rest.split("ã€å…¶ä»–è£œå……ã€‘")[0].strip() if "ã€å…¶ä»–è£œå……ã€‘" in w_rest else w_rest.strip()
                                else:
                                    v2_content = rest.split("ã€å…¶ä»–å·¥ä½œè¡¨ã€‘")[0].strip() if "ã€å…¶ä»–å·¥ä½œè¡¨ã€‘" in rest else rest.strip()

                        title_list = props.get("Content", {}).get("title", [])
                        original = title_list[0].get("text", {}).get("content", "") if title_list else ""

                        all_data[ref] = {
                            "ref": ref,
                            "original": original,
                            "v1_content": v1_content,
                            "v2_content": v2_content,
                            "w_sheet": w_sheet,
                            "p_sheet": p_sheet,
                            "grammar_list": grammar_list,
                            "other": "",
                            "ai_result": translation,
                            "type": props.get("Type", {}).get("select", {}).get("name", "Scripture"),
                            "mode": props.get("Source_Mode", {}).get("select", {}).get("name", "Mode A"),
                            "date_added": props.get("Date_Added", {}).get("date", {}).get("start", "") if props.get("Date_Added", {}).get("date") else "",
                            "notion_page_id": page.get("id"),
                            "notion_synced": True,
                            "saved_sheets": []
                        }
                        
                        # æ¨™è¨˜å·²å„²å­˜çš„å·¥ä½œè¡¨
                        if v1_content:
                            all_data[ref]["saved_sheets"].append("V1 Sheet")
                        if v2_content:
                            all_data[ref]["saved_sheets"].append("V2 Sheet")
                        if w_sheet:
                            all_data[ref]["saved_sheets"].append("W Sheet")
                        if p_sheet:
                            all_data[ref]["saved_sheets"].append("P Sheet")
                        if grammar_list:
                            all_data[ref]["saved_sheets"].append("Grammar List")

                    has_more = data.get("has_more", False)
                    start_cursor = data.get("next_cursor")

            if all_data:
                st.sidebar.success(f"âœ… å·²å¾ Notion è¼‰å…¥ {len(all_data)} ç­†è³‡æ–™")
            return all_data

        except Exception as e:
            st.sidebar.error(f"âŒ è¼‰å…¥å¤±æ•—ï¼š{e}")
            return {}

    def save_to_notion(data_dict):
        if not NOTION_TOKEN:
            return False, "NOTION_TOKEN æœªè¨­å®š", None

        url = f"{NOTION_BASE_URL}/pages"
        headers = {
            "Authorization": f"Bearer {NOTION_TOKEN}",
            "Content-Type": "application/json",
            "Notion-Version": NOTION_API_VERSION
        }

        # çµ„åˆæ‰€æœ‰å·¥ä½œè¡¨å…§å®¹
        full_content = f"""ã€V1 Sheetã€‘
{data_dict.get('v1_content', 'ç„¡')}

ã€V2 Sheetã€‘
{data_dict.get('v2_content', 'ç„¡')}

ã€W Sheetã€‘
{data_dict.get('w_sheet', 'ç„¡')}

ã€P Sheetã€‘
{data_dict.get('p_sheet', 'ç„¡')}

ã€Grammar Listã€‘
{data_dict.get('grammar_list', 'ç„¡')}

ã€å…¶ä»–è£œå……ã€‘
{data_dict.get('other', 'ç„¡')}
"""

        properties = {
            "Content": {"title": [{"text": {"content": data_dict.get('original', 'ç©ºç™½è³‡æ–™')[:100]}}]},
            "Translation": {"rich_text": [{"text": {"content": full_content[:2000]}}]},
            "Ref_No": {"rich_text": [{"text": {"content": data_dict.get("ref", "BLANK")}}]},
            "Source_Mode": {"select": {"name": data_dict.get("mode", "Mode A")}},
            "Type": {"select": {"name": data_dict.get("type", "Blank")}},
            "Date_Added": {"date": {"start": dt.datetime.now().isoformat()}}
        }

        try:
            response = requests.post(url, headers=headers, json={
                "parent": {"database_id": DATABASE_ID},
                "properties": properties
            })
            if response.status_code == 200:
                page_id = response.json().get("id")
                return True, "æˆåŠŸ", page_id
            else:
                return False, f"API Error: {response.text}", None
        except Exception as e:
            return False, str(e), None

    # ---------- æœ¬åœ°è³‡æ–™åº« ----------
    SENTENCES_FILE = "sentences.json"

    def load_sentences():
        if os.path.exists(SENTENCES_FILE):
            try:
                with open(SENTENCES_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except:
                pass
        return {}

    def save_sentences(data):
        with open(SENTENCES_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    # ---------- Session State åˆå§‹åŒ– ----------
    if 'sentences' not in st.session_state:
        st.session_state.sentences = load_sentences()
    if 'search_results' not in st.session_state:
        st.session_state.search_results = []
    if 'is_prompt_generated' not in st.session_state:
        st.session_state.is_prompt_generated = False
    if 'main_input_value' not in st.session_state:
        st.session_state.main_input_value = ""
    if 'original_text' not in st.session_state:
        st.session_state.original_text = ""
    if 'content_mode' not in st.session_state:
        st.session_state.content_mode = ""
    if 'raw_input_value' not in st.session_state:
        st.session_state.raw_input_value = ""
    if 'ref_number' not in st.session_state:
        st.session_state.ref_number = ""
    if 'current_entry' not in st.session_state:
        st.session_state.current_entry = {
            'v1': '', 'v2': '', 'w_sheet': '', 
            'p_sheet': '', 'grammar_list': '', 'other': ''
        }
    if 'saved_entries' not in st.session_state:
        st.session_state.saved_entries = []
    # æ–°å¢ï¼šç·¨è¼¯æ¨¡å¼ç›¸é—œ
    if 'edit_mode' not in st.session_state:
        st.session_state.edit_mode = False
    if 'edit_ref' not in st.session_state:
        st.session_state.edit_ref = None

    # é¡¯ç¤ºé€£ç·šç‹€æ…‹ï¼ˆSidebarï¼‰
    with st.sidebar:
        st.divider()
        st.subheader("â˜ï¸ é€£ç·šç‹€æ…‹")
        if NOTION_TOKEN:
            st.success("âœ… Notion Token å·²è¨­å®š")
        else:
            st.error("âŒ Notion Token æœªè¨­å®š")
        
        if sheet_connected:
            st.success("âœ… Google Sheet å·²é€£ç·š")
        else:
            st.error("âŒ Google Sheet æœªé€£ç·š")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ†• æ–°å¢ï¼šå¿«é€ŸåŠŸèƒ½å€ï¼ˆç©ºç™½è³‡æ–™å»ºç«‹å™¨ + ç·¨è¼¯ç¾æœ‰è³‡æ–™ï¼‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    st.markdown("<h6>âš¡ å¿«é€ŸåŠŸèƒ½</h6>", unsafe_allow_html=True)
    
    quick_cols = st.columns([1, 1, 2])
    
    with quick_cols[0]:
        # ç©ºç™½è³‡æ–™å»ºç«‹å™¨
        with st.expander("â• å»ºç«‹ç©ºç™½è³‡æ–™", expanded=False):
            blank_mode = st.selectbox("é¸æ“‡æ¨¡å¼", ["Mode A (ç¶“æ–‡)", "Mode B (æ–‡ç¨¿)"], key="blank_mode")
            blank_ref = st.text_input("åƒè€ƒç·¨è™Ÿ", value=f"BLANK_{dt.datetime.now().strftime('%m%d%H%M')}", key="blank_ref")
            
            if st.button("ğŸ†• å»ºç«‹ç©ºç™½è³‡æ–™çµæ§‹", use_container_width=True):
                # å»ºç«‹ç©ºç™½å·¥ä½œè¡¨çµæ§‹
                if "Mode A" in blank_mode:
                    blank_structure = {
                        "ref": blank_ref,
                        "original": "[ç©ºç™½è³‡æ–™-å¾…å¡«å…¥ç¶“æ–‡]",
                        "v1_content": "Ref.\tEnglish (ESV)\tChinese\tSyn/Ant\tGrammar\n",
                        "v2_content": "Ref.\tå£èªè¨³\tGrammar\tNote\tKRF\tSyn/Ant\tTHSV11\n",
                        "w_sheet": "",
                        "p_sheet": "",
                        "grammar_list": "",
                        "other": "",
                        "saved_sheets": ["V1 Sheet", "V2 Sheet"],
                        "type": "Scripture",
                        "mode": "A",
                        "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
                        "blank_template": True
                    }
                else:
                    blank_structure = {
                        "ref": blank_ref,
                        "original": "[ç©ºç™½è³‡æ–™-å¾…å¡«å…¥æ–‡ç¨¿]",
                        "v1_content": "",
                        "v2_content": "",
                        "w_sheet": "No\tWord/Phrase\tChinese\tSynonym+ä¸­æ–‡å°ç…§\tAntonym+ä¸­æ–‡å°ç…§\tå…¨å¥è–ç¶“ä¸­è‹±å°ç…§ä¾‹å¥\n",
                        "p_sheet": "Paragraph\tEnglish Refinement\tä¸­è‹±å¤¾é›œè¬›ç« \n",
                        "grammar_list": "No\tOriginal Sentence\tGrammar Rule\tAnalysis & Example\n",
                        "other": "",
                        "saved_sheets": ["W Sheet", "P Sheet", "Grammar List"],
                        "type": "Document",
                        "mode": "B",
                        "date_added": dt.datetime.now().strftime("%Y-%m-%d %H:%M"),
                        "blank_template": True
                    }
                
                # å­˜å…¥ session_state
                st.session_state.sentences[blank_ref] = blank_structure
                save_sentences(st.session_state.sentences)
                
                # è‡ªå‹•é€²å…¥ç·¨è¼¯æ¨¡å¼
                st.session_state.edit_mode = True
                st.session_state.edit_ref = blank_ref
                st.session_state.current_entry = {
                    'v1': blank_structure['v1_content'],
                    'v2': blank_structure['v2_content'],
                    'w_sheet': blank_structure['w_sheet'],
                    'p_sheet': blank_structure['p_sheet'],
                    'grammar_list': blank_structure['grammar_list'],
                    'other': ''
                }
                st.success(f"âœ… å·²å»ºç«‹ç©ºç™½è³‡æ–™ï¼š{blank_ref}")
                st.rerun()
    
    with quick_cols[1]:
        # ç·¨è¼¯ç¾æœ‰è³‡æ–™
        with st.expander("âœï¸ ç·¨è¼¯ç¾æœ‰è³‡æ–™", expanded=False):
            if st.session_state.sentences:
                edit_select = st.selectbox(
                    "é¸æ“‡è¦ç·¨è¼¯çš„è³‡æ–™",
                    list(st.session_state.sentences.keys()),
                    format_func=lambda x: f"{x} ({st.session_state.sentences[x].get('type', 'Unknown')})",
                    key="edit_select"
                )
                
                if st.button("ğŸ“ è¼‰å…¥ç·¨è¼¯", use_container_width=True):
                    item = st.session_state.sentences[edit_select]
                    st.session_state.edit_mode = True
                    st.session_state.edit_ref = edit_select
                    st.session_state.current_entry = {
                        'v1': item.get('v1_content', ''),
                        'v2': item.get('v2_content', ''),
                        'w_sheet': item.get('w_sheet', ''),
                        'p_sheet': item.get('p_sheet', ''),
                        'grammar_list': item.get('grammar_list', ''),
                        'other': item.get('other', '')
                    }
                    st.session_state.saved_entries = item.get('saved_sheets', [])
                    st.rerun()
            else:
                st.info("å°šç„¡è³‡æ–™å¯ç·¨è¼¯")
    
    with quick_cols[2]:
        # é¡¯ç¤ºç›®å‰ç‹€æ…‹
        if st.session_state.edit_mode and st.session_state.edit_ref:
            st.info(f"ğŸ“ ç›®å‰æ­£åœ¨ç·¨è¼¯ï¼š**{st.session_state.edit_ref}**")
            if st.button("âŒ çµæŸç·¨è¼¯æ¨¡å¼", use_container_width=True):
                st.session_state.edit_mode = False
                st.session_state.edit_ref = None
                st.session_state.saved_entries = []
                st.session_state.current_entry = {
                    'v1': '', 'v2': '', 'w_sheet': '', 
                    'p_sheet': '', 'grammar_list': '', 'other': ''
                }
                st.rerun()
        else:
            st.caption("ğŸ’¡ ä½¿ç”¨å·¦å´æŒ‰éˆ•å¿«é€Ÿå»ºç«‹æˆ–ç·¨è¼¯è³‡æ–™")

    st.divider()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ†• æ–°å¢ï¼šç·¨è¼¯æ¨¡å¼ä»‹é¢ï¼ˆç•¶ edit_mode = True æ™‚é¡¯ç¤ºï¼‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if st.session_state.edit_mode and st.session_state.edit_ref:
        st.markdown(f"<h6>âœï¸ ç·¨è¼¯æ¨¡å¼ï¼š{st.session_state.edit_ref}</h6>", unsafe_allow_html=True)
        
        item = st.session_state.sentences.get(st.session_state.edit_ref, {})
        current_mode = item.get('mode', 'A')
        
        # æ ¹æ“šæ¨¡å¼é¡¯ç¤ºå°æ‡‰çš„å·¥ä½œè¡¨ç·¨è¼¯å€
        if current_mode == 'A':
            edit_tabs = st.tabs(["V1 Sheet", "V2 Sheet", "å…¶ä»–è£œå……", "å„²å­˜"])
            
            with edit_tabs[0]:
                new_v1 = st.text_area(
                    "V1 Sheet å…§å®¹",
                    value=st.session_state.current_entry['v1'],
                    height=300,
                    key="edit_v1"
                )
                st.session_state.current_entry['v1'] = new_v1
            
            with edit_tabs[1]:
                new_v2 = st.text_area(
                    "V2 Sheet å…§å®¹",
                    value=st.session_state.current_entry['v2'],
                    height=300,
                    key="edit_v2"
                )
                st.session_state.current_entry['v2'] = new_v2
            
            with edit_tabs[2]:
                new_other = st.text_area(
                    "å…¶ä»–è£œå……",
                    value=st.session_state.current_entry['other'],
                    height=200,
                    key="edit_other"
                )
                st.session_state.current_entry['other'] = new_other
            
            with edit_tabs[3]:
                st.write("ç¢ºèªä¿®æ”¹å¾Œå„²å­˜ï¼š")
                save_cols = st.columns(4)
                
                with save_cols[0]:
                    if st.button("ğŸ’¾ å­˜åˆ°æœ¬åœ°", use_container_width=True):
                        st.session_state.sentences[st.session_state.edit_ref].update({
                            'v1_content': st.session_state.current_entry['v1'],
                            'v2_content': st.session_state.current_entry['v2'],
                            'other': st.session_state.current_entry['other'],
                            'saved_sheets': ['V1 Sheet', 'V2 Sheet'] if st.session_state.current_entry['v1'] else [],
                            'date_added': dt.datetime.now().strftime("%Y-%m-%d %H:%M")
                        })
                        save_sentences(st.session_state.sentences)
                        st.success("âœ… å·²æ›´æ–°æœ¬åœ°è³‡æ–™ï¼")
                
                with save_cols[1]:
                    if NOTION_TOKEN:
                        if st.button("ğŸš€ åŒæ­¥ Notion", use_container_width=True, type="primary"):
                            data = {
                                "original": item.get('original', ''),
                                "v1_content": st.session_state.current_entry['v1'],
                                "v2_content": st.session_state.current_entry['v2'],
                                "w_sheet": "",
                                "p_sheet": "",
                                "grammar_list": "",
                                "other": st.session_state.current_entry['other'],
                                "ref": st.session_state.edit_ref,
                                "mode": f"Mode {current_mode}",
                                "type": item.get('type', 'Scripture')
                            }
                            success, msg, page_id = save_to_notion(data)
                            if success:
                                st.session_state.sentences[st.session_state.edit_ref]['notion_synced'] = True
                                st.session_state.sentences[st.session_state.edit_ref]['notion_page_id'] = page_id
                                save_sentences(st.session_state.sentences)
                                st.success("âœ… å·²åŒæ­¥ Notionï¼")
                            else:
                                st.error(f"âŒ åŒæ­¥å¤±æ•—ï¼š{msg}")
                    else:
                        st.button("ğŸš€ Notion", disabled=True, use_container_width=True)
                
                with save_cols[2]:
                    st.button("ğŸ“Š Google", disabled=True, use_container_width=True)
                
                with save_cols[3]:
                    if st.button("ğŸ’¾ğŸš€ æœ¬åœ°+Notion", use_container_width=True):
                        # æœ¬åœ°
                        st.session_state.sentences[st.session_state.edit_ref].update({
                            'v1_content': st.session_state.current_entry['v1'],
                            'v2_content': st.session_state.current_entry['v2'],
                            'other': st.session_state.current_entry['other'],
                            'saved_sheets': ['V1 Sheet', 'V2 Sheet'] if st.session_state.current_entry['v1'] else [],
                            'date_added': dt.datetime.now().strftime("%Y-%m-%d %H:%M")
                        })
                        save_sentences(st.session_state.sentences)
                        
                        # Notion
                        if NOTION_TOKEN:
                            data = {
                                "original": item.get('original', ''),
                                "v1_content": st.session_state.current_entry['v1'],
                                "v2_content": st.session_state.current_entry['v2'],
                                "w_sheet": "",
                                "p_sheet": "",
                                "grammar_list": "",
                                "other": st.session_state.current_entry['other'],
                                "ref": st.session_state.edit_ref,
                                "mode": f"Mode {current_mode}",
                                "type": item.get('type', 'Scripture')
                            }
                            success, msg, page_id = save_to_notion(data)
                            if success:
                                st.session_state.sentences[st.session_state.edit_ref]['notion_synced'] = True
                                st.session_state.sentences[st.session_state.edit_ref]['notion_page_id'] = page_id
                                save_sentences(st.session_state.sentences)
                        
                        st.success("âœ… å·²åŒæ­¥æœ¬åœ°èˆ‡ Notionï¼")
        
        else:  # Mode B
            edit_tabs = st.tabs(["W Sheet", "P Sheet", "Grammar List", "å…¶ä»–è£œå……", "å„²å­˜"])
            
            with edit_tabs[0]:
                new_w = st.text_area(
                    "W Sheet å…§å®¹",
                    value=st.session_state.current_entry['w_sheet'],
                    height=300,
                    key="edit_w"
                )
                st.session_state.current_entry['w_sheet'] = new_w
            
            with edit_tabs[1]:
                new_p = st.text_area(
                    "P Sheet å…§å®¹",
                    value=st.session_state.current_entry['p_sheet'],
                    height=300,
                    key="edit_p"
                )
                st.session_state.current_entry['p_sheet'] = new_p
            
            with edit_tabs[2]:
                new_g = st.text_area(
                    "Grammar List å…§å®¹",
                    value=st.session_state.current_entry['grammar_list'],
                    height=300,
                    key="edit_g"
                )
                st.session_state.current_entry['grammar_list'] = new_g
            
            with edit_tabs[3]:
                new_other = st.text_area(
                    "å…¶ä»–è£œå……",
                    value=st.session_state.current_entry['other'],
                    height=200,
                    key="edit_other_b"
                )
                st.session_state.current_entry['other'] = new_other
            
            with edit_tabs[4]:
                st.write("ç¢ºèªä¿®æ”¹å¾Œå„²å­˜ï¼š")
                save_cols = st.columns(4)
                
                with save_cols[0]:
                    if st.button("ğŸ’¾ å­˜åˆ°æœ¬åœ°", use_container_width=True):
                        st.session_state.sentences[st.session_state.edit_ref].update({
                            'w_sheet': st.session_state.current_entry['w_sheet'],
                            'p_sheet': st.session_state.current_entry['p_sheet'],
                            'grammar_list': st.session_state.current_entry['grammar_list'],
                            'other': st.session_state.current_entry['other'],
                            'saved_sheets': ['W Sheet', 'P Sheet', 'Grammar List'],
                            'date_added': dt.datetime.now().strftime("%Y-%m-%d %H:%M")
                        })
                        save_sentences(st.session_state.sentences)
                        st.success("âœ… å·²æ›´æ–°æœ¬åœ°è³‡æ–™ï¼")
                
                with save_cols[1]:
                    if NOTION_TOKEN:
                        if st.button("ğŸš€ åŒæ­¥ Notion", use_container_width=True, type="primary"):
                            data = {
                                "original": item.get('original', ''),
                                "v1_content": "",
                                "v2_content": "",
                                "w_sheet": st.session_state.current_entry['w_sheet'],
                                "p_sheet": st.session_state.current_entry['p_sheet'],
                                "grammar_list": st.session_state.current_entry['grammar_list'],
                                "other": st.session_state.current_entry['other'],
                                "ref": st.session_state.edit_ref,
                                "mode": f"Mode {current_mode}",
                                "type": item.get('type', 'Document')
                            }
                            success, msg, page_id = save_to_notion(data)
                            if success:
                                st.session_state.sentences[st.session_state.edit_ref]['notion_synced'] = True
                                st.session_state.sentences[st.session_state.edit_ref]['notion_page_id'] = page_id
                                save_sentences(st.session_state.sentences)
                                st.success("âœ… å·²åŒæ­¥ Notionï¼")
                            else:
                                st.error(f"âŒ åŒæ­¥å¤±æ•—ï¼š{msg}")
                    else:
                        st.button("ğŸš€ Notion", disabled=True, use_container_width=True)
                
                with save_cols[2]:
                    st.button("ğŸ“Š Google", disabled=True, use_container_width=True)
                
                with save_cols[3]:
                    if st.button("ğŸ’¾ğŸš€ æœ¬åœ°+Notion", use_container_width=True):
                        st.session_state.sentences[st.session_state.edit_ref].update({
                            'w_sheet': st.session_state.current_entry['w_sheet'],
                            'p_sheet': st.session_state.current_entry['p_sheet'],
                            'grammar_list': st.session_state.current_entry['grammar_list'],
                            'other': st.session_state.current_entry['other'],
                            'saved_sheets': ['W Sheet', 'P Sheet', 'Grammar List'],
                            'date_added': dt.datetime.now().strftime("%Y-%m-%d %H:%M")
                        })
                        save_sentences(st.session_state.sentences)
                        
                        if NOTION_TOKEN:
                            data = {
                                "original": item.get('original', ''),
                                "v1_content": "",
                                "v2_content": "",
                                "w_sheet": st.session_state.current_entry['w_sheet'],
                                "p_sheet": st.session_state.current_entry['p_sheet'],
                                "grammar_list": st.session_state.current_entry['grammar_list'],
                                "other": st.session_state.current_entry['other'],
                                "ref": st.session_state.edit_ref,
                                "mode": f"Mode {current_mode}",
                                "type": item.get('type', 'Document')
                            }
                            success, msg, page_id = save_to_notion(data)
                            if success:
                                st.session_state.sentences[st.session_state.edit_ref]['notion_synced'] = True
                                st.session_state.sentences[st.session_state.edit_ref]['notion_page_id'] = page_id
                                save_sentences(st.session_state.sentences)
                        
                        st.success("âœ… å·²åŒæ­¥æœ¬åœ°èˆ‡ Notionï¼")
        
        st.divider()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # åŸæœ‰çš„ AI åˆ†æå·¥ä½œæµç¨‹ï¼ˆåªåœ¨éç·¨è¼¯æ¨¡å¼æ™‚é¡¯ç¤ºï¼‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if not st.session_state.edit_mode:
        st.markdown("<h6>ğŸ“ AI åˆ†æå·¥ä½œæµç¨‹</h6>", unsafe_allow_html=True)
        
        # ... [åŸæœ‰çš„ STEP 1-4 ç¨‹å¼ç¢¼ä¿æŒä¸è®Š] ...
        # === STEP 1: è¼¸å…¥å€ ===
        with st.expander("æ­¥é©Ÿ 1ï¼šè¼¸å…¥ç¶“æ–‡æˆ–æ–‡ç¨¿", expanded=not st.session_state.is_prompt_generated):
            raw_input = st.text_area(
                "åŸå§‹è¼¸å…¥",
                height=200,
                value=st.session_state.get('raw_input_value', ''),
                placeholder="è«‹åœ¨æ­¤è²¼ä¸Šå…§å®¹ï¼š\nâ€¢ ç¶“æ–‡æ ¼å¼ï¼š31:6 å¯ä»¥æŠŠæ¿ƒé…’çµ¦å°‡äº¡çš„äººå–...\nâ€¢ æ–‡ç¨¿æ ¼å¼ï¼šç›´æ¥è²¼ä¸Šè‹±æ–‡è¬›ç¨¿",
                label_visibility="collapsed",
                key="raw_input_temp"
            )
            
            if not st.session_state.is_prompt_generated:
                if st.button("âš¡ ç”¢ç”Ÿå®Œæ•´åˆ†ææŒ‡ä»¤", use_container_width=True, type="primary"):
                    # generate_full_prompt() å‡½æ•¸ä¿æŒä¸è®Š
                    raw_text = st.session_state.get("raw_input_temp", "").strip()
                    if raw_text:
                        mode = "A" if re.search(r'[\u4e00-\u9fa5]', raw_text) else "B"
                        # ... [åŸæœ‰çš„ prompt ç”¢ç”Ÿé‚è¼¯] ...
                        st.session_state.content_mode = mode
                        st.session_state.original_text = raw_text
                        st.session_state.is_prompt_generated = True
                        st.session_state.ref_number = f"REF_{dt.datetime.now().strftime('%m%d%H%M')}"
                        st.rerun()

        # ... [åŸæœ‰çš„ STEP 2-4 ç¨‹å¼ç¢¼] ...

    # ---------- åº•éƒ¨çµ±è¨ˆ ----------
    st.divider()
    total_count = len(st.session_state.get('sentences', {}))
    st.caption(f"ğŸ’¾ è³‡æ–™åº«ï¼š{total_count} ç­†")

